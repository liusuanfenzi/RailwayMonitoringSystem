# #!/usr/bin/env python3
# """
# èƒŒæ™¯å‡é™¤å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•
# æ¯”è¾ƒä¸‰ç§ç­–ç•¥åœ¨åˆ—è½¦è¿›ç«™è§†é¢‘ä¸Šçš„æ•ˆæœï¼š
# 1. ä¸åŠ é¢„å¤„ç†ä¸åå¤„ç†
# 2. åªåŠ åå¤„ç†
# 3. åŠ é¢„å¤„ç†ä¸åå¤„ç†
# """

# import cv2
# import numpy as np
# from pathlib import Path

# class GMMBackgroundSubtractor:
#     """GMMèƒŒæ™¯å‡é™¤å™¨ - æ”¯æŒä¸åŒå¤„ç†ç­–ç•¥"""
    
#     def __init__(self, algorithm: str = 'MOG2', **kwargs):
#         self.algorithm = algorithm.upper()
#         self.roi_manager = ROIManager()

#         if self.algorithm == 'MOG2':
#             self.back_sub = cv2.createBackgroundSubtractorMOG2(
#                 history=kwargs.get('history', 500),
#                 varThreshold=kwargs.get('varThreshold', 16),
#                 detectShadows=kwargs.get('detectShadows', False)
#             )
#         else:
#             self.back_sub = cv2.createBackgroundSubtractorKNN(
#                 history=kwargs.get('history', 500),
#                 dist2Threshold=kwargs.get('dist2Threshold', 400),
#                 detectShadows=kwargs.get('detectShadows', False)
#             )
        
#         print(f"âœ… {self.algorithm}èƒŒæ™¯å‡é™¤å™¨åˆå§‹åŒ–æˆåŠŸ")

#     def setup_single_roi(self, points: list, roi_name: str = 'detection_region'):
#         """è®¾ç½®å•ä¸ªROIåŒºåŸŸ"""
#         if len(points) != 2:
#             raise ValueError("ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")
#         self.roi_manager.add_roi(roi_name, points)
#         print(f"ğŸ¯ è®¾ç½®ROIåŒºåŸŸ {roi_name}: {points}")

#     def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
#         """é¢„å¤„ç†å¸§ - é™ä½å»å™ªå¼ºåº¦"""
#         if frame is None:
#             raise ValueError("è¾“å…¥å¸§ä¸èƒ½ä¸ºNone")

#         # è½¬æ¢ä¸ºç°åº¦å›¾
#         if len(frame.shape) == 3:
#             gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#         else:
#             gray_frame = frame.copy()

#         # åº”ç”¨ROIæ©è†œ
#         if self.roi_manager.rois:
#             mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
#             for points in self.roi_manager.rois.values():
#                 cv2.rectangle(mask, points[0], points[1], 255, -1)
#             gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

#         # è½»å¾®é«˜æ–¯æ¨¡ç³Šé™å™ª
#         blurred_frame = cv2.GaussianBlur(gray_frame, (3, 3), 0.5)
#         return blurred_frame

#     def _postprocess_mask(self, fg_mask: np.ndarray) -> np.ndarray:
#         """åå¤„ç†å‰æ™¯æ©ç  - é™ä½å»å™ªå¼ºåº¦"""
#         # é™ä½äºŒå€¼åŒ–é˜ˆå€¼
#         _, binary_mask = cv2.threshold(fg_mask, 50, 255, cv2.THRESH_BINARY)

#         # å‡å°‘å½¢æ€å­¦å¼€è¿ç®—çš„å¼ºåº¦
#         kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
#         opened_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_open, iterations=2)

#         # ä½¿ç”¨æ›´å°çš„ä¸­å€¼æ»¤æ³¢æ ¸
#         filtered_mask = cv2.medianBlur(opened_mask, 3)
#         return filtered_mask

#     def apply_no_processing(self, frame: np.ndarray, learning_rate: float = 0.005) -> dict:
#         """
#         ç­–ç•¥1: ä¸åŠ é¢„å¤„ç†ä¸åå¤„ç†
#         """
#         # ç›´æ¥åº”ç”¨èƒŒæ™¯å‡é™¤ï¼Œä¸åšä»»ä½•å¤„ç†
#         fg_mask = self.back_sub.apply(frame, learningRate=learning_rate)
        
#         # è®¡ç®—ROIåŒºåŸŸç»Ÿè®¡
#         return self._analyze_results(frame, fg_mask, "no_preprocess + no_postprocess")

#     def apply_postprocessing_only(self, frame: np.ndarray, learning_rate: float = 0.005) -> dict:
#         """
#         ç­–ç•¥2: åªåŠ åå¤„ç†
#         """
#         # ç›´æ¥åº”ç”¨èƒŒæ™¯å‡é™¤
#         fg_mask = self.back_sub.apply(frame, learningRate=learning_rate)
        
#         # åªè¿›è¡Œåå¤„ç†
#         processed_mask = self._postprocess_mask(fg_mask)
        
#         return self._analyze_results(frame, processed_mask, "no_preprocess + postprocess")

#     def apply_full_processing(self, frame: np.ndarray, learning_rate: float = 0.005) -> dict:
#         """
#         ç­–ç•¥3: åŠ é¢„å¤„ç†ä¸åå¤„ç†
#         """
#         # è¿›è¡Œé¢„å¤„ç†
#         preprocessed_frame = self._preprocess_frame(frame)
        
#         # åº”ç”¨èƒŒæ™¯å‡é™¤
#         fg_mask = self.back_sub.apply(preprocessed_frame, learningRate=learning_rate)
        
#         # è¿›è¡Œåå¤„ç†
#         processed_mask = self._postprocess_mask(fg_mask)
        
#         return self._analyze_results(frame, processed_mask, "npreproces + postprocess")

#     def _analyze_results(self, original_frame: np.ndarray, fg_mask: np.ndarray, strategy_name: str) -> dict:
#         """åˆ†æç»“æœå¹¶è¿”å›ç»Ÿè®¡ä¿¡æ¯"""
#         # è®¡ç®—å®Œæ•´å¸§ç»Ÿè®¡
#         full_foreground_pixels = np.sum(fg_mask > 0)
#         full_foreground_ratio = full_foreground_pixels / fg_mask.size

#         results = {
#             'strategy': strategy_name,
#             'full_frame': {
#                 'mask': fg_mask,
#                 'foreground_pixels': full_foreground_pixels,
#                 'foreground_ratio': full_foreground_ratio
#             },
#             'roi_data': {}
#         }

#         # è®¡ç®—ROIåŒºåŸŸçš„ç»Ÿè®¡
#         if self.roi_manager.rois:
#             roi_name = list(self.roi_manager.rois.keys())[0]
#             try:
#                 roi_mask = self.roi_manager.crop_roi(fg_mask, roi_name)
#                 roi_original = self.roi_manager.crop_roi(original_frame, roi_name)
                
#                 roi_size = roi_mask.shape[0] * roi_mask.shape[1]
#                 roi_foreground_pixels = np.sum(roi_mask > 0)
#                 roi_foreground_ratio = roi_foreground_pixels / roi_size if roi_size > 0 else 0

#                 results['roi_data'] = {
#                     'mask': roi_mask,
#                     'original': roi_original,
#                     'foreground_pixels': roi_foreground_pixels,
#                     'foreground_ratio': roi_foreground_ratio,
#                     'roi_size': roi_size,
#                     'roi_name': roi_name
#                 }
#             except Exception as e:
#                 print(f"âš ï¸ ROIåˆ†æå¤±è´¥ {roi_name}: {e}")

#         return results

# class ROIManager:
#     """ROIç®¡ç†å™¨"""
    
#     def __init__(self):
#         self.rois = {}
    
#     def add_roi(self, roi_name: str, points: list):
#         self.rois = {roi_name: points}
    
#     def crop_roi(self, image: np.ndarray, roi_name: str) -> np.ndarray:
#         if roi_name not in self.rois:
#             raise ValueError(f"ROI {roi_name} ä¸å­˜åœ¨")
        
#         points = self.rois[roi_name]
#         x1, y1 = points[0]
#         x2, y2 = points[1]
        
#         h, w = image.shape[:2]
#         x1, y1 = max(0, x1), max(0, y1)
#         x2, y2 = min(w, x2), min(h, y2)
        
#         return image[y1:y2, x1:x2]

# def create_original_display_frame(original_frame: np.ndarray, roi_points: list) -> np.ndarray:
#     """åˆ›å»ºåŸå›¾æ˜¾ç¤ºå¸§ï¼ŒåŒ…å«ROIåŒºåŸŸæ ‡æ³¨"""
#     display_frame = original_frame.copy()
    
#     # åœ¨åŸå›¾ä¸Šç»˜åˆ¶ROIåŒºåŸŸ
#     if roi_points and len(roi_points) == 2:
#         cv2.rectangle(display_frame, roi_points[0], roi_points[1], (0, 255, 0), 2)
        
#         # æ·»åŠ ROIæ ‡ç­¾
#         label = "Detection ROI"
#         text_x = roi_points[0][0]
#         text_y = roi_points[0][1] - 10
#         if text_y < 20:
#             text_y = roi_points[0][1] + 25
        
#         cv2.putText(display_frame, label, (text_x, text_y),
#                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
#     # æ·»åŠ çª—å£æ ‡é¢˜
#     cv2.putText(display_frame, "Original Frame with ROI", (10, 30),
#                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
#     return display_frame

# def create_roi_mask_display_frame(results: dict, strategy_name: str) -> np.ndarray:
#     """åˆ›å»ºROIæ©ç æ˜¾ç¤ºå¸§ï¼Œåªæ˜¾ç¤ºROIåŒºåŸŸçš„å‰æ™¯æ©ç """
#     # åˆ›å»ºæ˜¾ç¤ºç”»å¸ƒ
#     display_height = 400
#     display_width = 600
    
#     # åˆ›å»ºé»‘è‰²èƒŒæ™¯
#     display_frame = np.zeros((display_height, display_width, 3), dtype=np.uint8)
    
#     # è·å–ROIæ•°æ®
#     roi_data = results.get('roi_data', {})
    
#     if roi_data and 'mask' in roi_data:
#         roi_mask = roi_data['mask']
#         foreground_ratio = roi_data.get('foreground_ratio', 0)
        
#         # è°ƒæ•´æ©ç å¤§å°ä»¥é€‚åˆæ˜¾ç¤ºçª—å£
#         if len(roi_mask.shape) == 2:
#             # ç°åº¦å›¾è½¬å½©è‰²
#             roi_mask_color = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR)
#         else:
#             roi_mask_color = roi_mask
        
#         # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒå®½é«˜æ¯”
#         h, w = roi_mask_color.shape[:2]
#         scale = min(500 / w, 300 / h)  # æœ€å¤§æ˜¾ç¤ºå°ºå¯¸ 500x300
#         new_w = int(w * scale)
#         new_h = int(h * scale)
        
#         mask_resized = cv2.resize(roi_mask_color, (new_w, new_h))
        
#         # å±…ä¸­æ˜¾ç¤ºæ©ç 
#         x_offset = (display_width - new_w) // 2
#         y_offset = (display_height - new_h) // 2
#         display_frame[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = mask_resized
        
#         # æ·»åŠ ç­–ç•¥åç§°å’Œç»Ÿè®¡ä¿¡æ¯
#         cv2.putText(display_frame, f"Strategy: {strategy_name}", 
#                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
#         cv2.putText(display_frame, f"ROI FG Ratio: {foreground_ratio:.4f}", 
#                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
#         # æ·»åŠ å®Œæ•´å¸§ç»Ÿè®¡
#         full_frame_data = results.get('full_frame', {})
#         full_ratio = full_frame_data.get('foreground_ratio', 0)
#         cv2.putText(display_frame, f"Full Frame FG Ratio: {full_ratio:.4f}", 
#                    (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
#         # æ˜¾ç¤ºROIå°ºå¯¸ä¿¡æ¯
#         roi_size = roi_data.get('roi_size', 0)
#         cv2.putText(display_frame, f"ROI Size: {roi_size} pixels", 
#                    (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)
    
#     else:
#         # å¦‚æœæ²¡æœ‰ROIæ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
#         cv2.putText(display_frame, f"Strategy: {strategy_name}", 
#                    (display_width//2-100, display_height//2-30), 
#                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
#         cv2.putText(display_frame, "No ROI Data Available", 
#                    (display_width//2-120, display_height//2+30), 
#                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)
    
#     # æ·»åŠ è¾¹æ¡†
#     cv2.rectangle(display_frame, (0, 0), (display_width-1, display_height-1), 
#                  (100, 100, 100), 2)
    
#     return display_frame

# def main():
#     """ä¸»æµ‹è¯•å‡½æ•°"""
#     video_path = "data/test_videos/train_enter_station.mp4"
    
#     # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     if not Path(video_path).exists():
#         print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
#         print("è¯·ç¡®ä¿è§†é¢‘æ–‡ä»¶è·¯å¾„æ­£ç¡®")
#         return
    
#     # å®šä¹‰ROIåŒºåŸŸï¼ˆæ ¹æ®åˆ—è½¦è¿›ç«™çš„å…¸å‹åŒºåŸŸè°ƒæ•´ï¼‰
#     roi_points = [(200, 200), (600, 700)]  # [(x1,y1), (x2,y2)]
    
#     # åˆå§‹åŒ–ä¸‰ä¸ªèƒŒæ™¯å‡é™¤å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„å‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼‰
#     bg_subtractors = {
#         'no_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'post_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         #'full_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16)
#     }
    
#     # ä¸ºæ‰€æœ‰å‡é™¤å™¨è®¾ç½®ç›¸åŒçš„ROI
#     for bg_sub in bg_subtractors.values():
#         bg_sub.setup_single_roi(roi_points, 'train_detection_roi')
    
#     # æ‰“å¼€è§†é¢‘æ–‡ä»¶
#     cap = cv2.VideoCapture(video_path)
#     if not cap.isOpened():
#         print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
#         return
    
#     print("ğŸš€ å¼€å§‹èƒŒæ™¯å‡é™¤ç­–ç•¥å¯¹æ¯”æµ‹è¯•")
#     print("ğŸ“Š æ¯”è¾ƒä¸‰ç§å¤„ç†ç­–ç•¥:")
#     print("   1. æ— é¢„å¤„ç† + æ— åå¤„ç†")
#     print("   2. æ— é¢„å¤„ç† + æœ‰åå¤„ç†") 
#     #print("   3. æœ‰é¢„å¤„ç† + æœ‰åå¤„ç†")
#     print("ğŸ¯ æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'p' æš‚åœ/ç»§ç»­ï¼ŒæŒ‰ 'r' é‡ç½®èƒŒæ™¯æ¨¡å‹")
    
#     paused = False
#     frame_count = 0
    
#     try:
#         while True:
#             if not paused:
#                 ret, frame = cap.read()
#                 if not ret:
#                     print("âœ… è§†é¢‘æ’­æ”¾å®Œæ¯•")
#                     break
                
#                 frame_count += 1
                
#                 # åº”ç”¨ä¸‰ç§å¤„ç†ç­–ç•¥
#                 results = {
#                     'no_processing': bg_subtractors['no_processing'].apply_no_processing(frame),
#                     'post_only': bg_subtractors['post_only'].apply_postprocessing_only(frame),
#                     #'full_processing': bg_subtractors['full_processing'].apply_full_processing(frame)
#                 }
                
#                 # åˆ›å»ºå¹¶æ˜¾ç¤ºåŸå›¾çª—å£ï¼ˆå¸¦ROIæ ‡æ³¨ï¼‰
#                 original_display = create_original_display_frame(frame, roi_points)
#                 cv2.imshow('1. Original Frame with ROI', original_display)
                
#                 # åˆ›å»ºå¹¶æ˜¾ç¤ºä¸‰ä¸ªç­–ç•¥çš„ROIæ©ç çª—å£
#                 strategy_displays = {
#                     'no_processing': create_roi_mask_display_frame(
#                         results['no_processing'], "æ— é¢„å¤„ç†+æ— åå¤„ç†"
#                     ),
#                     'post_only': create_roi_mask_display_frame(
#                         results['post_only'], "æ— é¢„å¤„ç†+æœ‰åå¤„ç†"
#                     ),
#                     # 'full_processing': create_roi_mask_display_frame(
#                     #     results['full_processing'], "æœ‰é¢„å¤„ç†+æœ‰åå¤„ç†"
#                     # )
#                 }
                
#                 cv2.imshow('2. Strategy: No Pre+No Post', strategy_displays['no_processing'])
#                 cv2.imshow('3. Strategy: No Pre+With Post', strategy_displays['post_only'])
#                 #cv2.imshow('4. Strategy: With Pre+With Post', strategy_displays['full_processing'])
                
#                 # æ¯50å¸§è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
#                 if frame_count % 50 == 0:
#                     print(f"\nğŸ“ˆ å¸§ {frame_count} ç»Ÿè®¡:")
#                     for strategy, result in results.items():
#                         full_ratio = result['full_frame']['foreground_ratio']
#                         roi_ratio = result.get('roi_data', {}).get('foreground_ratio', 0)
#                         print(f"   {result['strategy']}:")
#                         print(f"      Full Frame FG Ratio: {full_ratio:.4f}")
#                         print(f"      ROI FG Ratio: {roi_ratio:.4f}")
            
#             # é”®ç›˜æ§åˆ¶
#             key = cv2.waitKey(1) & 0xFF
#             if key == ord('q'):
#                 break
#             elif key == ord('p'):
#                 paused = not paused
#                 print(f"{'â¸ï¸ æš‚åœ' if paused else 'â–¶ï¸ ç»§ç»­'}")
#             elif key == ord('r'):  # é‡ç½®èƒŒæ™¯æ¨¡å‹
#                 for name, bg_sub in bg_subtractors.items():
#                     bg_sub.back_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16)
#                 print("ğŸ”„ æ‰€æœ‰èƒŒæ™¯æ¨¡å‹å·²é‡ç½®")
    
#     except Exception as e:
#         print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
#         import traceback
#         traceback.print_exc()
    
#     finally:
#         cap.release()
#         cv2.destroyAllWindows()
    
#     print(f"\nâœ… æµ‹è¯•å®Œæˆ")
#     print(f"ğŸ“Š æ€»å…±å¤„ç†å¸§æ•°: {frame_count}")
#     print("ğŸ¯ åˆ†æå»ºè®®:")
#     print("   - çª—å£1: åŸå›¾+ROIåŒºåŸŸæ ‡æ³¨")
#     print("   - çª—å£2: æ— é¢„å¤„ç†+æ— åå¤„ç†æ•ˆæœ")
#     print("   - çª—å£3: æ— é¢„å¤„ç†+æœ‰åå¤„ç†æ•ˆæœ") 
#     #print("   - çª—å£4: æœ‰é¢„å¤„ç†+æœ‰åå¤„ç†æ•ˆæœ")
#     print("   - è§‚å¯Ÿä¸‰ç§ç­–ç•¥çš„å‰æ™¯æ£€æµ‹å®Œæ•´åº¦å’Œå™ªå£°æŠ‘åˆ¶æ•ˆæœ")

# if __name__ == "__main__":
#     main()

# #!/usr/bin/env python3
# """
# å››ç§å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•
# 1. å®Œå…¨ä¸å¤„ç†
# 2. åªåŠ é¢„å¤„ç†
# 3. åªåŠ åå¤„ç†
# 4. é¢„å¤„ç†+åå¤„ç†
# """

# import cv2
# import numpy as np
# from pathlib import Path

# class GMMBackgroundSubtractor:
#     """GMMèƒŒæ™¯å‡é™¤å™¨ - æ”¯æŒå››ç§å¤„ç†ç­–ç•¥"""
    
#     def __init__(self, algorithm: str = 'MOG2', **kwargs):
#         self.algorithm = algorithm.upper()
#         self.roi_manager = ROIManager()

#         if self.algorithm == 'MOG2':
#             self.back_sub = cv2.createBackgroundSubtractorMOG2(
#                 history=kwargs.get('history', 500),
#                 varThreshold=kwargs.get('varThreshold', 16),
#                 detectShadows=kwargs.get('detectShadows', False)
#             )
#         else:
#             self.back_sub = cv2.createBackgroundSubtractorKNN(
#                 history=kwargs.get('history', 500),
#                 dist2Threshold=kwargs.get('dist2Threshold', 400),
#                 detectShadows=kwargs.get('detectShadows', False)
#             )
        
#         print(f"âœ… {self.algorithm}èƒŒæ™¯å‡é™¤å™¨åˆå§‹åŒ–æˆåŠŸ")

#     def setup_single_roi(self, points: list, roi_name: str = 'detection_region'):
#         """è®¾ç½®å•ä¸ªROIåŒºåŸŸ"""
#         if len(points) != 2:
#             raise ValueError("ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")
#         self.roi_manager.add_roi(roi_name, points)
#         print(f"ğŸ¯ è®¾ç½®ROIåŒºåŸŸ {roi_name}: {points}")

#     def _enhance_dark_regions(self, frame: np.ndarray) -> np.ndarray:
#         """å¢å¼ºæš—éƒ¨åŒºåŸŸ"""
#         if len(frame.shape) == 3:
#             gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#         else:
#             gray_frame = frame.copy()
        
#         # åº”ç”¨ä¼½é©¬æ ¡æ­£å¢å¼ºæš—éƒ¨
#         gamma = 0.8  # å°äº1çš„å€¼å¢å¼ºæš—éƒ¨
#         inv_gamma = 1.0 / gamma
#         table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
#         enhanced_frame = cv2.LUT(gray_frame, table)
        
#         return enhanced_frame

#     def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
#         """é¢„å¤„ç†å¸§ - åŒ…å«æš—éƒ¨å¢å¼ºå’Œé™å™ª"""
#         if frame is None:
#             raise ValueError("è¾“å…¥å¸§ä¸èƒ½ä¸ºNone")

#         # Step 1: å¢å¼ºæš—éƒ¨åŒºåŸŸ
#         enhanced_frame = self._enhance_dark_regions(frame)

#         # Step 2: åº”ç”¨ROIæ©è†œ
#         if self.roi_manager.rois:
#             mask = np.zeros(enhanced_frame.shape[:2], dtype=np.uint8)
#             for points in self.roi_manager.rois.values():
#                 cv2.rectangle(mask, points[0], points[1], 255, -1)
#             enhanced_frame = cv2.bitwise_and(enhanced_frame, enhanced_frame, mask=mask)

#         # Step 3: è½»å¾®é«˜æ–¯æ¨¡ç³Šé™å™ª
#         blurred_frame = cv2.GaussianBlur(enhanced_frame, (3, 3), 0.5)

#         return blurred_frame

#     def _postprocess_mask(self, fg_mask: np.ndarray) -> np.ndarray:
#         """åå¤„ç†å‰æ™¯æ©ç  - é™ä½å»å™ªå¼ºåº¦"""
#         # Step 1: é™ä½äºŒå€¼åŒ–é˜ˆå€¼
#         _, binary_mask = cv2.threshold(fg_mask, 50, 255, cv2.THRESH_BINARY)

#         # Step 2: å‡å°‘å½¢æ€å­¦å¼€è¿ç®—çš„å¼ºåº¦
#         kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
#         opened_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_open, iterations=1)

#         # Step 3: ä½¿ç”¨æ›´å°çš„ä¸­å€¼æ»¤æ³¢æ ¸
#         filtered_mask = cv2.medianBlur(opened_mask, 3)

#         return filtered_mask

#     def apply_no_processing(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
#         """
#         ç­–ç•¥1: å®Œå…¨ä¸å¤„ç†
#         """
#         # ç›´æ¥åº”ç”¨èƒŒæ™¯å‡é™¤ï¼Œä¸åšä»»ä½•å¤„ç†
#         fg_mask = self.back_sub.apply(frame, learningRate=learning_rate)
#         return fg_mask

#     def apply_preprocessing_only(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
#         """
#         ç­–ç•¥2: åªåŠ é¢„å¤„ç†
#         """
#         # è¿›è¡Œé¢„å¤„ç†ï¼ˆåŒ…å«æš—éƒ¨å¢å¼ºï¼‰
#         preprocessed_frame = self._preprocess_frame(frame)
        
#         # åº”ç”¨èƒŒæ™¯å‡é™¤
#         fg_mask = self.back_sub.apply(preprocessed_frame, learningRate=learning_rate)
        
#         return fg_mask

#     def apply_postprocessing_only(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
#         """
#         ç­–ç•¥3: åªåŠ åå¤„ç†
#         """
#         # ç›´æ¥åº”ç”¨èƒŒæ™¯å‡é™¤
#         fg_mask = self.back_sub.apply(frame, learningRate=learning_rate)
        
#         # åªè¿›è¡Œåå¤„ç†
#         processed_mask = self._postprocess_mask(fg_mask)
        
#         return processed_mask

#     def apply_full_processing(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
#         """
#         ç­–ç•¥4: é¢„å¤„ç†+åå¤„ç†
#         """
#         # è¿›è¡Œé¢„å¤„ç†ï¼ˆåŒ…å«æš—éƒ¨å¢å¼ºï¼‰
#         preprocessed_frame = self._preprocess_frame(frame)
        
#         # åº”ç”¨èƒŒæ™¯å‡é™¤
#         fg_mask = self.back_sub.apply(preprocessed_frame, learningRate=learning_rate)
        
#         # è¿›è¡Œåå¤„ç†
#         processed_mask = self._postprocess_mask(fg_mask)
        
#         return processed_mask

# class ROIManager:
#     """ROIç®¡ç†å™¨"""
    
#     def __init__(self):
#         self.rois = {}
    
#     def add_roi(self, roi_name: str, points: list):
#         self.rois = {roi_name: points}
    
#     def crop_roi(self, image: np.ndarray, roi_name: str) -> np.ndarray:
#         if roi_name not in self.rois:
#             raise ValueError(f"ROI {roi_name} ä¸å­˜åœ¨")
        
#         points = self.rois[roi_name]
#         x1, y1 = points[0]
#         x2, y2 = points[1]
        
#         h, w = image.shape[:2]
#         x1, y1 = max(0, x1), max(0, y1)
#         x2, y2 = min(w, x2), min(h, y2)
        
#         return image[y1:y2, x1:x2]

# def get_frame_300(video_path: str) -> np.ndarray:
#     """è·å–è§†é¢‘çš„ç¬¬300å¸§"""
#     cap = cv2.VideoCapture(video_path)
#     if not cap.isOpened():
#         raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    
#     # è®¾ç½®åˆ°ç¬¬300å¸§
#     cap.set(cv2.CAP_PROP_POS_FRAMES, 299)  # 0-based index
    
#     ret, frame = cap.read()
#     cap.release()
    
#     if not ret:
#         raise ValueError("æ— æ³•è¯»å–ç¬¬300å¸§")
    
#     return frame

# def test_four_strategies_on_frame_300():
#     """åœ¨ç¬¬300å¸§ä¸Šæµ‹è¯•å››ç§å¤„ç†ç­–ç•¥"""
#     video_path = "data/test_videos/train_enter_station.mp4"
    
#     # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     if not Path(video_path).exists():
#         print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
#         return
    
#     # å®šä¹‰ROIåŒºåŸŸ
#     roi_points = [(200, 200), (600, 700)]
    
#     # åˆå§‹åŒ–å››ä¸ªèƒŒæ™¯å‡é™¤å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„å‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼‰
#     bg_subtractors = {
#         'no_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'pre_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'post_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'full_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16)
#     }
    
#     # ä¸ºæ‰€æœ‰å‡é™¤å™¨è®¾ç½®ç›¸åŒçš„ROI
#     for bg_sub in bg_subtractors.values():
#         bg_sub.setup_single_roi(roi_points, 'train_detection_roi')
    
#     print("ğŸš€ å¼€å§‹å››ç§å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•")
#     print("ğŸ“Š æ¯”è¾ƒå››ç§å¤„ç†ç­–ç•¥:")
#     print("   1. å®Œå…¨ä¸å¤„ç†")
#     print("   2. åªåŠ é¢„å¤„ç†ï¼ˆæš—éƒ¨å¢å¼º+é™å™ªï¼‰")
#     print("   3. åªåŠ åå¤„ç†ï¼ˆå½¢æ€å­¦æ»¤æ³¢ï¼‰")
#     print("   4. é¢„å¤„ç†+åå¤„ç†")
    
#     try:
#         # è·å–ç¬¬300å¸§
#         print("\nğŸ¯ æ­£åœ¨è¯»å–ç¬¬300å¸§...")
#         frame_300 = get_frame_300(video_path)
#         print(f"âœ… æˆåŠŸè¯»å–ç¬¬300å¸§ï¼Œå°ºå¯¸: {frame_300.shape}")
        
#         # åº”ç”¨å››ç§å¤„ç†ç­–ç•¥
#         print("\nğŸ”§ åº”ç”¨å››ç§å¤„ç†ç­–ç•¥...")
#         masks = {
#             '1. No Processing': bg_subtractors['no_processing'].apply_no_processing(frame_300),
#             '2. Preprocessing Only': bg_subtractors['pre_only'].apply_preprocessing_only(frame_300),
#             '3. Postprocessing Only': bg_subtractors['post_only'].apply_postprocessing_only(frame_300),
#             '4. Full Processing': bg_subtractors['full_processing'].apply_full_processing(frame_300)
#         }
        
#         # è®¡ç®—æ¯ç§ç­–ç•¥çš„å‰æ™¯æ¯”ä¾‹
#         stats = {}
#         for strategy_name, mask in masks.items():
#             foreground_pixels = np.sum(mask > 0)
#             total_pixels = mask.shape[0] * mask.shape[1]
#             foreground_ratio = foreground_pixels / total_pixels
#             stats[strategy_name] = foreground_ratio
        
#         # æ˜¾ç¤ºåŸå›¾å’Œå››ç§ç­–ç•¥çš„ç»“æœ
#         print("\nğŸ–¼ï¸ æ˜¾ç¤ºç»“æœçª—å£...")
        
#         # æ˜¾ç¤ºåŸå›¾ï¼ˆå¸¦ROIæ ‡æ³¨ï¼‰
#         original_with_roi = frame_300.copy()
#         cv2.rectangle(original_with_roi, roi_points[0], roi_points[1], (0, 255, 0), 2)
#         cv2.putText(original_with_roi, "Original Frame (Frame 300)", (10, 30),
#                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
#         cv2.imshow('0. Original Frame (Frame 300)', original_with_roi)
        
#         # æ˜¾ç¤ºå››ç§ç­–ç•¥çš„å‰æ™¯æ©ç 
#         for i, (strategy_name, mask) in enumerate(masks.items(), 1):
#             # å°†ç°åº¦æ©ç è½¬æ¢ä¸ºå½©è‰²ä»¥ä¾¿æ˜¾ç¤º
#             if len(mask.shape) == 2:
#                 mask_display = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
#             else:
#                 mask_display = mask.copy()
            
#             # æ·»åŠ æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
#             foreground_ratio = stats[strategy_name]
#             cv2.putText(mask_display, f"{strategy_name}", (10, 30),
#                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
#             cv2.putText(mask_display, f"FG Ratio: {foreground_ratio:.4f}", (10, 60),
#                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
#             # æ˜¾ç¤ºçª—å£
#             cv2.imshow(f'{i}. {strategy_name}', mask_display)
        
#         # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
#         print("\nğŸ“ˆ ç¬¬300å¸§å¤„ç†ç»“æœç»Ÿè®¡:")
#         for strategy_name, ratio in stats.items():
#             print(f"   {strategy_name}: {ratio:.4f}")
        
#         print("\nğŸ¯ æŒ‰ä»»æ„é”®å…³é—­çª—å£...")
#         cv2.waitKey(0)
#         cv2.destroyAllWindows()
        
#         # ä¿å­˜ç»“æœå›¾åƒï¼ˆå¯é€‰ï¼‰
#         save_results = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜ç»“æœå›¾åƒï¼Ÿ(y/n): ").lower().strip()
#         if save_results == 'y':
#             # åˆ›å»ºä¿å­˜ç›®å½•
#             save_dir = Path("test_results")
#             save_dir.mkdir(exist_ok=True)
            
#             # ä¿å­˜åŸå›¾
#             cv2.imwrite(str(save_dir / "original_frame_300.jpg"), original_with_roi)
            
#             # ä¿å­˜å„ç­–ç•¥ç»“æœ
#             for strategy_name, mask in masks.items():
#                 filename = f"strategy_{strategy_name.replace(' ', '_').replace('.', '')}.jpg"
#                 cv2.imwrite(str(save_dir / filename), mask)
            
#             print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {save_dir} ç›®å½•")
        
#     except Exception as e:
#         print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
#         import traceback
#         traceback.print_exc()

# def test_four_strategies_on_video():
#     """åœ¨å®Œæ•´è§†é¢‘ä¸Šæµ‹è¯•å››ç§å¤„ç†ç­–ç•¥"""
#     video_path = "data/test_videos/train_enter_station.mp4"
    
#     if not Path(video_path).exists():
#         print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
#         return
    
#     roi_points = [(200, 200), (600, 700)]
    
#     # åˆå§‹åŒ–å››ä¸ªèƒŒæ™¯å‡é™¤å™¨
#     bg_subtractors = {
#         'no_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'pre_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'post_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
#         'full_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16)
#     }
    
#     for bg_sub in bg_subtractors.values():
#         bg_sub.setup_single_roi(roi_points, 'train_detection_roi')
    
#     cap = cv2.VideoCapture(video_path)
#     if not cap.isOpened():
#         print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
#         return
    
#     print("ğŸš€ å¼€å§‹è§†é¢‘æµå››ç§å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•")
#     print("ğŸ¯ æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'p' æš‚åœ/ç»§ç»­ï¼ŒæŒ‰ 'r' é‡ç½®èƒŒæ™¯æ¨¡å‹")
    
#     paused = False
#     frame_count = 0
    
#     try:
#         while True:
#             if not paused:
#                 ret, frame = cap.read()
#                 if not ret:
#                     print("âœ… è§†é¢‘æ’­æ”¾å®Œæ¯•")
#                     break
                
#                 frame_count += 1
                
#                 # åº”ç”¨å››ç§å¤„ç†ç­–ç•¥
#                 masks = {
#                     '1. No Processing': bg_subtractors['no_processing'].apply_no_processing(frame),
#                     '2. Preprocessing Only': bg_subtractors['pre_only'].apply_preprocessing_only(frame),
#                     '3. Postprocessing Only': bg_subtractors['post_only'].apply_postprocessing_only(frame),
#                     '4. Full Processing': bg_subtractors['full_processing'].apply_full_processing(frame)
#                 }
                
#                 # æ˜¾ç¤ºåŸå›¾
#                 original_with_roi = frame.copy()
#                 cv2.rectangle(original_with_roi, roi_points[0], roi_points[1], (0, 255, 0), 2)
#                 cv2.putText(original_with_roi, f"Original Frame - Frame {frame_count}", (10, 30),
#                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
#                 cv2.imshow('0. Original Frame', original_with_roi)
                
#                 # æ˜¾ç¤ºå››ç§ç­–ç•¥çš„å‰æ™¯æ©ç 
#                 for i, (strategy_name, mask) in enumerate(masks.items(), 1):
#                     if len(mask.shape) == 2:
#                         mask_display = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
#                     else:
#                         mask_display = mask.copy()
                    
#                     # è®¡ç®—å‰æ™¯æ¯”ä¾‹
#                     foreground_ratio = np.sum(mask > 0) / (mask.shape[0] * mask.shape[1])
                    
#                     cv2.putText(mask_display, f"{strategy_name}", (10, 30),
#                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
#                     cv2.putText(mask_display, f"FG Ratio: {foreground_ratio:.4f}", (10, 60),
#                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                    
#                     cv2.imshow(f'{i}. {strategy_name}', mask_display)
                
#                 # æ¯100å¸§è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
#                 if frame_count % 100 == 0:
#                     print(f"\nğŸ“ˆ å¸§ {frame_count} ç»Ÿè®¡:")
#                     for strategy_name, mask in masks.items():
#                         foreground_ratio = np.sum(mask > 0) / (mask.shape[0] * mask.shape[1])
#                         print(f"   {strategy_name}: {foreground_ratio:.4f}")
            
#             # é”®ç›˜æ§åˆ¶
#             key = cv2.waitKey(1) & 0xFF
#             if key == ord('q'):
#                 break
#             elif key == ord('p'):
#                 paused = not paused
#                 print(f"{'â¸ï¸ æš‚åœ' if paused else 'â–¶ï¸ ç»§ç»­'}")
#             elif key == ord('r'):
#                 for bg_sub in bg_subtractors.values():
#                     bg_sub.back_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16)
#                 print("ğŸ”„ æ‰€æœ‰èƒŒæ™¯æ¨¡å‹å·²é‡ç½®")
    
#     except Exception as e:
#         print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
#         import traceback
#         traceback.print_exc()
    
#     finally:
#         cap.release()
#         cv2.destroyAllWindows()
    
#     print(f"\nâœ… è§†é¢‘æµ‹è¯•å®Œæˆï¼Œæ€»å…±å¤„ç† {frame_count} å¸§")

# if __name__ == "__main__":
    # print("è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    # print("1. æµ‹è¯•ç¬¬300å¸§")
    # print("2. æµ‹è¯•å®Œæ•´è§†é¢‘")
    
    # choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
    
    # if choice == "1":
    #     test_four_strategies_on_frame_300()
    # elif choice == "2":
    #     test_four_strategies_on_video()
    # else:
    #     print("âŒ æ— æ•ˆé€‰æ‹©")

#!/usr/bin/env python3
"""
å››ç§å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•
1. æ— é¢„å¤„ç† + æ— åå¤„ç†
2. åªåŠ ROIæ©ç ï¼ˆé¢„å¤„ç†ï¼‰
3. åªåŠ åå¤„ç†
4. ROIæ©ç  + åå¤„ç†
"""

import cv2
import numpy as np
from pathlib import Path

class ROIManager:
    """ROIç®¡ç†å™¨"""
    
    def __init__(self):
        self.rois = {}
    
    def add_roi(self, roi_name: str, points: list):
        self.rois = {roi_name: points}
    
    def crop_roi(self, image: np.ndarray, roi_name: str) -> np.ndarray:
        if roi_name not in self.rois:
            raise ValueError(f"ROI {roi_name} ä¸å­˜åœ¨")
        
        points = self.rois[roi_name]
        x1, y1 = points[0]
        x2, y2 = points[1]
        
        h, w = image.shape[:2]
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        return image[y1:y2, x1:x2]

class GMMBackgroundSubtractor:
    """GMMèƒŒæ™¯å‡é™¤å™¨ - æ”¯æŒå››ç§å¤„ç†ç­–ç•¥"""
    
    def __init__(self, algorithm: str = 'MOG2', **kwargs):
        self.algorithm = algorithm.upper()
        self.roi_manager = ROIManager()

        if self.algorithm == 'MOG2':
            self.back_sub = cv2.createBackgroundSubtractorMOG2(
                history=kwargs.get('history', 500),
                varThreshold=kwargs.get('varThreshold', 16),
                detectShadows=kwargs.get('detectShadows', False)
            )
        else:
            self.back_sub = cv2.createBackgroundSubtractorKNN(
                history=kwargs.get('history', 500),
                dist2Threshold=kwargs.get('dist2Threshold', 400),
                detectShadows=kwargs.get('detectShadows', False)
            )
        
        print(f"âœ… {self.algorithm}èƒŒæ™¯å‡é™¤å™¨åˆå§‹åŒ–æˆåŠŸ")

    def setup_single_roi(self, points: list, roi_name: str = 'detection_region'):
        """è®¾ç½®å•ä¸ªROIåŒºåŸŸ"""
        if len(points) != 2:
            raise ValueError("ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")
        self.roi_manager.add_roi(roi_name, points)
        print(f"ğŸ¯ è®¾ç½®ROIåŒºåŸŸ {roi_name}: {points}")

    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        é¢„å¤„ç†å¸§ - åªä¿ç•™ROIæ©ç åº”ç”¨
        """
        if frame is None:
            raise ValueError("è¾“å…¥å¸§ä¸èƒ½ä¸ºNone")

        # Step 1: è½¬æ¢ä¸ºç°åº¦å›¾
        if len(frame.shape) == 3:
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray_frame = frame.copy()

        # Step 2: åº”ç”¨ROIæ©è†œ
        if self.roi_manager.rois:
            mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
            for points in self.roi_manager.rois.values():
                cv2.rectangle(mask, points[0], points[1], 255, -1)
            gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

        return gray_frame
    
    def _postprocess_mask(self, fg_mask: np.ndarray) -> np.ndarray:
        """
        åå¤„ç†å‰æ™¯æ©ç 
        """
        # Step 1: é™ä½äºŒå€¼åŒ–é˜ˆå€¼æ£€æµ‹æš—è‰²å‰æ™¯
        _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)

        # Step 2: å½¢æ€å­¦é—­è¿ç®—å¡«å……å­”æ´
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        closed_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)

        # Step 3: å½¢æ€å­¦å¼€è¿ç®—å»é™¤å°å™ªå£°
        kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        opened_mask = cv2.morphologyEx(closed_mask, cv2.MORPH_OPEN, kernel_open, iterations=1)

        # Step 4: ä¸­å€¼æ»¤æ³¢é™å™ª
        filtered_mask = cv2.medianBlur(opened_mask, 3)
        return filtered_mask
    
    def apply_no_processing(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
        """
        ç­–ç•¥1: æ— é¢„å¤„ç† + æ— åå¤„ç†
        """
        # ç›´æ¥åº”ç”¨èƒŒæ™¯å‡é™¤ï¼Œä¸åšä»»ä½•å¤„ç†
        fg_mask = self.back_sub.apply(frame, learningRate=learning_rate)
        return fg_mask
    
    def apply_roi_only(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
        """
        ç­–ç•¥2: åªåŠ ROIæ©ç ï¼ˆé¢„å¤„ç†ï¼‰
        """
        # åªè¿›è¡ŒROIæ©ç é¢„å¤„ç†ï¼Œæ— åå¤„ç†
        preprocessed_frame = self._preprocess_frame(frame)
        fg_mask = self.back_sub.apply(preprocessed_frame, learningRate=learning_rate)
        return fg_mask
    
    def apply_post_only(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
        """
        ç­–ç•¥3: åªåŠ åå¤„ç†
        """
        # æ— é¢„å¤„ç†ï¼Œåªè¿›è¡Œåå¤„ç†
        fg_mask = self.back_sub.apply(frame, learningRate=learning_rate)
        processed_mask = self._postprocess_mask(fg_mask)
        return processed_mask
    
    def apply_full_processing(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
        """
        ç­–ç•¥4: ROIæ©ç  + åå¤„ç†
        """
        # å®Œæ•´å¤„ç†ï¼šROIæ©ç  + åå¤„ç†
        preprocessed_frame = self._preprocess_frame(frame)
        fg_mask = self.back_sub.apply(preprocessed_frame, learningRate=learning_rate)
        processed_mask = self._postprocess_mask(fg_mask)
        return processed_mask

def get_frame_300(video_path: str) -> np.ndarray:
    """è·å–è§†é¢‘çš„ç¬¬300å¸§"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    
    # è®¾ç½®åˆ°ç¬¬300å¸§
    cap.set(cv2.CAP_PROP_POS_FRAMES, 299)  # 0-based index
    
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        raise ValueError("æ— æ³•è¯»å–ç¬¬300å¸§")
    
    return frame

def calculate_mask_statistics(mask: np.ndarray) -> dict:
    """è®¡ç®—æ©ç çš„ç»Ÿè®¡ä¿¡æ¯"""
    foreground_pixels = np.sum(mask > 0)
    total_pixels = mask.shape[0] * mask.shape[1]
    foreground_ratio = foreground_pixels / total_pixels
    
    return {
        'foreground_pixels': foreground_pixels,
        'total_pixels': total_pixels,
        'foreground_ratio': foreground_ratio
    }

def create_mask_display(mask: np.ndarray, title: str, stats: dict) -> np.ndarray:
    """åˆ›å»ºæ©ç æ˜¾ç¤ºå›¾åƒ"""
    # å°†ç°åº¦æ©ç è½¬æ¢ä¸ºå½©è‰²
    if len(mask.shape) == 2:
        display = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
    else:
        display = mask.copy()
    
    # æ·»åŠ æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
    cv2.putText(display, title, (10, 30),
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    cv2.putText(display, f"FG Ratio: {stats['foreground_ratio']:.4f}", (10, 60),
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    cv2.putText(display, f"FG Pixels: {stats['foreground_pixels']}", (10, 90),
               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    return display

def test_four_strategies_on_frame_300():
    """åœ¨ç¬¬300å¸§ä¸Šæµ‹è¯•å››ç§å¤„ç†ç­–ç•¥"""
    video_path = "data/test_videos/train_enter_station.mp4"
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(video_path).exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    # å®šä¹‰ROIåŒºåŸŸ
    roi_points = [(200, 200), (600, 700)]
    
    # åˆå§‹åŒ–å››ä¸ªèƒŒæ™¯å‡é™¤å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„å‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼‰
    bg_subtractors = {
        'no_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
        'roi_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
        'post_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
        'full_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16)
    }
    
    # ä¸ºæ‰€æœ‰å‡é™¤å™¨è®¾ç½®ç›¸åŒçš„ROI
    for bg_sub in bg_subtractors.values():
        bg_sub.setup_single_roi(roi_points, 'train_detection_roi')
    
    print("ğŸš€ å¼€å§‹å››ç§å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•")
    print("ğŸ“Š æ¯”è¾ƒå››ç§å¤„ç†ç­–ç•¥:")
    print("   1. æ— é¢„å¤„ç† + æ— åå¤„ç†")
    print("   2. åªåŠ ROIæ©ç ï¼ˆé¢„å¤„ç†ï¼‰")
    print("   3. åªåŠ åå¤„ç†")
    print("   4. ROIæ©ç  + åå¤„ç†")
    
    try:
        # è·å–ç¬¬300å¸§
        print("\nğŸ¯ æ­£åœ¨è¯»å–ç¬¬300å¸§...")
        frame_300 = get_frame_300(video_path)
        print(f"âœ… æˆåŠŸè¯»å–ç¬¬300å¸§ï¼Œå°ºå¯¸: {frame_300.shape}")
        
        # åº”ç”¨å››ç§å¤„ç†ç­–ç•¥
        print("\nğŸ”§ åº”ç”¨å››ç§å¤„ç†ç­–ç•¥...")
        masks = {
            '1. No Pre + No Post': bg_subtractors['no_processing'].apply_no_processing(frame_300),
            '2. ROI Only': bg_subtractors['roi_only'].apply_roi_only(frame_300),
            '3. Post Only': bg_subtractors['post_only'].apply_post_only(frame_300),
            '4. ROI + Post': bg_subtractors['full_processing'].apply_full_processing(frame_300)
        }
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = {}
        for strategy_name, mask in masks.items():
            stats[strategy_name] = calculate_mask_statistics(mask)
        
        # æ˜¾ç¤ºåŸå›¾
        original_with_roi = frame_300.copy()
        cv2.rectangle(original_with_roi, roi_points[0], roi_points[1], (0, 255, 0), 2)
        cv2.putText(original_with_roi, "Original Frame (Frame 300)", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.imshow('0. Original Frame (Frame 300)', original_with_roi)
        
        # æ˜¾ç¤ºå››ç§ç­–ç•¥çš„å‰æ™¯æ©ç 
        for strategy_name, mask in masks.items():
            display = create_mask_display(mask, strategy_name, stats[strategy_name])
            cv2.imshow(strategy_name, display)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ ç¬¬300å¸§å¤„ç†ç»“æœç»Ÿè®¡:")
        for strategy_name, stat in stats.items():
            print(f"   {strategy_name}:")
            print(f"     å‰æ™¯æ¯”ä¾‹: {stat['foreground_ratio']:.4f}")
            print(f"     å‰æ™¯åƒç´ : {stat['foreground_pixels']}")
            print(f"     æ€»åƒç´ : {stat['total_pixels']}")
        
        print("\nğŸ¯ æŒ‰ä»»æ„é”®å…³é—­çª—å£...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def test_four_strategies_on_video():
    """åœ¨å®Œæ•´è§†é¢‘ä¸Šæµ‹è¯•å››ç§å¤„ç†ç­–ç•¥"""
    video_path = "data/test_videos/train_enter_station.mp4"
    
    if not Path(video_path).exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    roi_points = [(200, 200), (600, 700)]
    
    # åˆå§‹åŒ–å››ä¸ªèƒŒæ™¯å‡é™¤å™¨
    bg_subtractors = {
        #'no_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
        'roi_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
        #'post_only': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16),
        'full_processing': GMMBackgroundSubtractor(algorithm='MOG2', history=500, varThreshold=16)
    }
    
    for bg_sub in bg_subtractors.values():
        bg_sub.setup_single_roi(roi_points, 'train_detection_roi')
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    print("ğŸš€ å¼€å§‹è§†é¢‘æµå››ç§å¤„ç†ç­–ç•¥å¯¹æ¯”æµ‹è¯•")
    print("ğŸ¯ æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'p' æš‚åœ/ç»§ç»­ï¼ŒæŒ‰ 'r' é‡ç½®èƒŒæ™¯æ¨¡å‹")
    
    paused = False
    frame_count = 0
    
    try:
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("âœ… è§†é¢‘æ’­æ”¾å®Œæ¯•")
                    break
                
                frame_count += 1
                
                # åº”ç”¨å››ç§å¤„ç†ç­–ç•¥
                masks = {
                    #'1. No Pre + No Post': bg_subtractors['no_processing'].apply_no_processing(frame),
                    '2. ROI Only': bg_subtractors['roi_only'].apply_roi_only(frame),
                    #'3. Post Only': bg_subtractors['post_only'].apply_post_only(frame),
                    '4. ROI + Post': bg_subtractors['full_processing'].apply_full_processing(frame)
                }
                
                # æ˜¾ç¤ºåŸå›¾
                original_with_roi = frame.copy()
                cv2.rectangle(original_with_roi, roi_points[0], roi_points[1], (0, 255, 0), 2)
                cv2.putText(original_with_roi, f"Original Frame - Frame {frame_count}", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.imshow('0. Original Frame', original_with_roi)
                
                # æ˜¾ç¤ºå››ç§ç­–ç•¥çš„å‰æ™¯æ©ç 
                for strategy_name, mask in masks.items():
                    stats = calculate_mask_statistics(mask)
                    display = create_mask_display(mask, f"{strategy_name} - Frame {frame_count}", stats)
                    cv2.imshow(strategy_name, display)
                
                # æ¯50å¸§è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                if frame_count % 50 == 0:
                    print(f"\nğŸ“ˆ å¸§ {frame_count} ç»Ÿè®¡:")
                    for strategy_name, mask in masks.items():
                        stats = calculate_mask_statistics(mask)
                        print(f"   {strategy_name}: {stats['foreground_ratio']:.4f}")
            
            # é”®ç›˜æ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('p'):
                paused = not paused
                print(f"{'â¸ï¸ æš‚åœ' if paused else 'â–¶ï¸ ç»§ç»­'}")
            elif key == ord('r'):
                for bg_sub in bg_subtractors.values():
                    bg_sub.back_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16)
                print("ğŸ”„ æ‰€æœ‰èƒŒæ™¯æ¨¡å‹å·²é‡ç½®")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
    
    print(f"\nâœ… è§†é¢‘æµ‹è¯•å®Œæˆï¼Œæ€»å…±å¤„ç† {frame_count} å¸§")

if __name__ == "__main__":
    print("è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. æµ‹è¯•ç¬¬300å¸§")
    print("2. æµ‹è¯•å®Œæ•´è§†é¢‘")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
    
    if choice == "1":
        test_four_strategies_on_frame_300()
    elif choice == "2":
        test_four_strategies_on_video()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")