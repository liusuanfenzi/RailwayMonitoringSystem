#!/usr/bin/env python3
"""
éªŒè¯ç«è½¦è¿›ç«™æ£€æµ‹æ•ˆæœ
"""

import cv2
import numpy as np
from models.background_subtractors.gmm_model_old1 import GMMBackgroundSubtractor

def validate_train_detection(video_path: str):
    """éªŒè¯GMMå¯¹ç«è½¦è¿›ç«™çš„æ£€æµ‹æ•ˆæœ"""
    
    print("ğŸš‚ éªŒè¯ç«è½¦è¿›ç«™æ£€æµ‹æ•ˆæœ...")
    
    # æµ‹è¯•ä¸‰ç§é…ç½®
    configs = [
        {'name': 'ä¿å®ˆ', 'history': 500, 'var_threshold': 16},
        {'name': 'å¹³è¡¡', 'history': 200, 'var_threshold': 10},
        {'name': 'æ•æ„Ÿ', 'history': 100, 'var_threshold': 8},
    ]
    
    results = {}
    
    for config in configs:
        print(f"\nğŸ”§ æµ‹è¯• {config['name']} é…ç½®...")
        
        gmm = GMMBackgroundSubtractor(
            'MOG2',
            history=config['history'],
            var_threshold=config['var_threshold'],
            detect_shadows=False
        )
        
        # å¤„ç†è§†é¢‘å¹¶åˆ†æå¸§é—´å˜åŒ–
        cap = cv2.VideoCapture(video_path)
        foreground_pixels = []
        
        prev_frame = None
        frame_changes = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # è½¬æ¢ä¸ºç°åº¦
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # åº”ç”¨GMM
            fg_mask = gmm.apply(gray)
            foreground_pixels.append(np.sum(fg_mask > 0))
            
            # åˆ†æå¸§é—´å˜åŒ–ï¼ˆç”¨äºæ£€æµ‹ç«è½¦è¿›å…¥ROIï¼‰
            if prev_frame is not None:
                frame_diff = cv2.absdiff(prev_frame, gray)
                change_ratio = np.sum(frame_diff > 25) / (1080 * 1116)
                frame_changes.append(change_ratio)
            
            prev_frame = gray
        
        cap.release()
        
        # åˆ†æç»“æœ
        avg_foreground = np.mean(foreground_pixels)
        max_foreground = np.max(foreground_pixels)
        foreground_ratio = avg_foreground / (1080 * 1116)
        
        # æ£€æµ‹æ˜¾è‘—è¿åŠ¨å¸§ï¼ˆå¯èƒ½è¡¨ç¤ºç«è½¦è¿›å…¥ï¼‰
        significant_changes = [x for x in frame_changes if x > 0.02]  # 2%çš„å˜åŒ–é˜ˆå€¼
        train_enter_frames = len(significant_changes)
        
        results[config['name']] = {
            'avg_foreground': avg_foreground,
            'max_foreground': max_foreground,
            'foreground_ratio': foreground_ratio,
            'train_enter_events': train_enter_frames,
            'sensitivity': "é«˜" if foreground_ratio > 0.08 else "ä¸­" if foreground_ratio > 0.06 else "ä½"
        }
        
        print(f"  å‰æ™¯æ¯”ä¾‹: {foreground_ratio:.3f}")
        print(f"  æœ€å¤§å‰æ™¯: {max_foreground}")
        print(f"  æ£€æµ‹åˆ°æ˜¾è‘—è¿åŠ¨å¸§: {train_enter_frames}")
        print(f"  çµæ•åº¦: {results[config['name']]['sensitivity']}")
    
    # è¾“å‡ºæ¨è
    print("\nğŸ¯ é…ç½®æ¨è:")
    best_config = max(results.items(), key=lambda x: x[1]['foreground_ratio'])
    print(f"  æ¨èä½¿ç”¨: {best_config[0]} é…ç½®")
    print(f"  ç†ç”±: å‰æ™¯æ¯”ä¾‹æœ€é«˜ ({best_config[1]['foreground_ratio']:.3f})")
    
    return results

if __name__ == "__main__":
    results = validate_train_detection("data/test_videos/train_enter_station.mp4")