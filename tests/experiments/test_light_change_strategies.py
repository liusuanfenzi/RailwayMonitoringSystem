#!/usr/bin/env python3
"""
é“è½¨å…‰å½±å˜åŒ–å¤„ç†ç­–ç•¥æµ‹è¯•
"""

import cv2
import numpy as np
import time
import sys
import os
from pathlib import Path

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.background_subtractors.gmm_model_old1 import GMMBackgroundSubtractor

def simulate_light_change_scenario():
    """æ¨¡æ‹Ÿé“è½¨å…‰å½±å˜åŒ–åœºæ™¯"""
    print("ğŸ¬ æ¨¡æ‹Ÿé“è½¨å…‰å½±å˜åŒ–åœºæ™¯...")
    
    # åˆ›å»ºåŸºç¡€é“è½¨åœºæ™¯
    width, height = 800, 600
    frames = []
    
    # é˜¶æ®µ1: æ­£å¸¸å…‰ç…§
    for i in range(30):
        frame = np.full((height, width, 3), 120, dtype=np.uint8)  # ä¸­ç­‰äº®åº¦
        # æ·»åŠ é“è½¨çº¹ç†
        cv2.line(frame, (100, 300), (700, 300), (80, 80, 80), 10)  # é“è½¨
        cv2.line(frame, (100, 320), (700, 320), (80, 80, 80), 10)  # é“è½¨
        frames.append(frame)
    
    # é˜¶æ®µ2: å…‰å½±å˜åŒ–ï¼ˆæ¨¡æ‹Ÿåˆ—è½¦è¿›å…¥ï¼‰
    for i in range(20):
        # é€æ¸å˜äº®å†å˜æš—ï¼Œæ¨¡æ‹Ÿå…‰å½±å˜åŒ–
        brightness = 120 + 50 * np.sin(i * 0.3)
        frame = np.full((height, width, 3), max(50, min(200, brightness)), dtype=np.uint8)
        cv2.line(frame, (100, 300), (700, 300), (80, 80, 80), 10)
        cv2.line(frame, (100, 320), (700, 320), (80, 80, 80), 10)
        frames.append(frame)
    
    # é˜¶æ®µ3: åˆ—è½¦å®ä½“é€šè¿‡
    for i in range(30):
        frame = np.full((height, width, 3), 120, dtype=np.uint8)
        cv2.line(frame, (100, 300), (700, 300), (80, 80, 80), 10)
        cv2.line(frame, (100, 320), (700, 320), (80, 80, 80), 10)
        # æ·»åŠ åˆ—è½¦
        train_x = 200 + i * 15
        cv2.rectangle(frame, (train_x, 250), (train_x + 100, 350), (180, 180, 180), -1)
        frames.append(frame)
    
    return frames

def test_strategy_with_equalization():
    """æµ‹è¯•ä½¿ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–çš„ç­–ç•¥"""
    print("\nğŸ”§ æµ‹è¯•ç­–ç•¥1: ä½¿ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–")
    
    frames = simulate_light_change_scenario()
    
    # ä½¿ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–çš„KNN
    knn = cv2.createBackgroundSubtractorKNN(
        history=200,
        dist2Threshold=400,
        detectShadows=False
    )
    
    foreground_ratios = []
    light_change_detected = []
    train_detected = []
    
    for i, frame in enumerate(frames):
        # åº”ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])
        processed_frame = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
        
        # åº”ç”¨KNN
        fg_mask = knn.apply(processed_frame)
        
        # è®¡ç®—å‰æ™¯æ¯”ä¾‹
        fg_ratio = np.sum(fg_mask > 0) / fg_mask.size
        foreground_ratios.append(fg_ratio)
        
        # åˆ†ææ£€æµ‹æƒ…å†µ
        if 30 <= i < 50:  # å…‰å½±å˜åŒ–é˜¶æ®µ
            light_change_detected.append(fg_ratio > 0.01)
        elif i >= 50:  # åˆ—è½¦é€šè¿‡é˜¶æ®µ
            train_detected.append(fg_ratio > 0.05)
    
    # ç»Ÿè®¡ç»“æœ
    light_change_detection_rate = np.mean(light_change_detected) if light_change_detected else 0
    train_detection_rate = np.mean(train_detected) if train_detected else 0
    
    print(f"   å…‰å½±å˜åŒ–æ£€æµ‹ç‡: {light_change_detection_rate:.2f}")
    print(f"   åˆ—è½¦æ£€æµ‹ç‡: {train_detection_rate:.2f}")
    print(f"   å¹³å‡å‰æ™¯æ¯”ä¾‹: {np.mean(foreground_ratios):.4f}")
    
    return {
        'strategy': 'ç›´æ–¹å›¾å‡è¡¡åŒ–',
        'light_change_detection': light_change_detection_rate,
        'train_detection': train_detection_rate,
        'avg_foreground': np.mean(foreground_ratios)
    }

def test_strategy_treat_light_as_foreground():
    """æµ‹è¯•å°†å…‰å½±å˜åŒ–è§†ä¸ºå‰æ™¯çš„ç­–ç•¥"""
    print("\nğŸ”§ æµ‹è¯•ç­–ç•¥2: å…‰å½±å˜åŒ–è§†ä¸ºå‰æ™¯")
    
    frames = simulate_light_change_scenario()
    
    # ä½¿ç”¨æ›´æ•æ„Ÿçš„KNNå‚æ•°
    knn = cv2.createBackgroundSubtractorKNN(
        history=100,           # è¾ƒçŸ­å†å²ï¼Œæ›´å¿«é€‚åº”å˜åŒ–
        dist2Threshold=300,    # è¾ƒä½é˜ˆå€¼ï¼Œæ›´æ•æ„Ÿ
        detectShadows=False    # ä¸åŒºåˆ†é˜´å½±
    )
    
    foreground_ratios = []
    light_change_detected = []
    train_detected = []
    
    for i, frame in enumerate(frames):
        # ç›´æ¥åº”ç”¨KNNï¼Œä¸è¿›è¡Œå‡è¡¡åŒ–
        fg_mask = knn.apply(frame)
        
        # è®¡ç®—å‰æ™¯æ¯”ä¾‹
        fg_ratio = np.sum(fg_mask > 0) / fg_mask.size
        foreground_ratios.append(fg_ratio)
        
        # åˆ†ææ£€æµ‹æƒ…å†µ
        if 30 <= i < 50:  # å…‰å½±å˜åŒ–é˜¶æ®µ
            light_change_detected.append(fg_ratio > 0.01)
        elif i >= 50:  # åˆ—è½¦é€šè¿‡é˜¶æ®µ
            train_detected.append(fg_ratio > 0.05)
    
    # ç»Ÿè®¡ç»“æœ
    light_change_detection_rate = np.mean(light_change_detected) if light_change_detected else 0
    train_detection_rate = np.mean(train_detected) if train_detected else 0
    
    print(f"   å…‰å½±å˜åŒ–æ£€æµ‹ç‡: {light_change_detection_rate:.2f}")
    print(f"   åˆ—è½¦æ£€æµ‹ç‡: {train_detection_rate:.2f}")
    print(f"   å¹³å‡å‰æ™¯æ¯”ä¾‹: {np.mean(foreground_ratios):.4f}")
    
    return {
        'strategy': 'å…‰å½±å˜åŒ–è§†ä¸ºå‰æ™¯',
        'light_change_detection': light_change_detection_rate,
        'train_detection': train_detection_rate,
        'avg_foreground': np.mean(foreground_ratios)
    }

def test_hybrid_strategy():
    """æµ‹è¯•æ··åˆç­–ç•¥"""
    print("\nğŸ”§ æµ‹è¯•ç­–ç•¥3: æ··åˆç­–ç•¥")
    
    frames = simulate_light_change_scenario()
    
    # ä½¿ç”¨ä¸­ç­‰å‚æ•°çš„KNN
    knn = cv2.createBackgroundSubtractorKNN(
        history=150,
        dist2Threshold=350,
        detectShadows=True     # å¯ç”¨é˜´å½±æ£€æµ‹
    )
    
    foreground_ratios = []
    light_change_detected = []
    train_detected = []
    
    for i, frame in enumerate(frames):
        # è½»åº¦é«˜æ–¯æ¨¡ç³Šå»å™ªï¼Œä½†ä¸è¿›è¡Œç›´æ–¹å›¾å‡è¡¡åŒ–
        processed_frame = cv2.GaussianBlur(frame, (3, 3), 0)
        
        # åº”ç”¨KNN
        fg_mask = knn.apply(processed_frame)
        
        # è®¡ç®—å‰æ™¯æ¯”ä¾‹ï¼ˆæ’é™¤é˜´å½±ï¼‰
        foreground_pixels = np.sum(fg_mask == 255)  # åªè®¡ç®—ç¡®å®šçš„å‰æ™¯
        fg_ratio = foreground_pixels / fg_mask.size
        foreground_ratios.append(fg_ratio)
        
        # åˆ†ææ£€æµ‹æƒ…å†µ
        if 30 <= i < 50:  # å…‰å½±å˜åŒ–é˜¶æ®µ
            light_change_detected.append(fg_ratio > 0.005)  # è¾ƒä½é˜ˆå€¼
        elif i >= 50:  # åˆ—è½¦é€šè¿‡é˜¶æ®µ
            train_detected.append(fg_ratio > 0.03)  # ä¸­ç­‰é˜ˆå€¼
    
    # ç»Ÿè®¡ç»“æœ
    light_change_detection_rate = np.mean(light_change_detected) if light_change_detected else 0
    train_detection_rate = np.mean(train_detected) if train_detected else 0
    
    print(f"   å…‰å½±å˜åŒ–æ£€æµ‹ç‡: {light_change_detection_rate:.2f}")
    print(f"   åˆ—è½¦æ£€æµ‹ç‡: {train_detection_rate:.2f}")
    print(f"   å¹³å‡å‰æ™¯æ¯”ä¾‹: {np.mean(foreground_ratios):.4f}")
    
    return {
        'strategy': 'æ··åˆç­–ç•¥',
        'light_change_detection': light_change_detection_rate,
        'train_detection': train_detection_rate,
        'avg_foreground': np.mean(foreground_ratios)
    }

def analyze_real_video_strategies():
    """åœ¨çœŸå®è§†é¢‘ä¸Šæµ‹è¯•ä¸åŒç­–ç•¥"""
    print("\nğŸ¬ åœ¨çœŸå®è§†é¢‘ä¸Šæµ‹è¯•ç­–ç•¥")
    
    video_path = "data/test_videos/train_enter_station.mp4"
    
    if not Path(video_path).exists():
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {video_path}")
        return None
    
    strategies = [
        {
            'name': 'å‡è¡¡åŒ–ç­–ç•¥',
            'params': {
                'algorithm': 'KNN',
                'history': 200,
                'dist2_threshold': 400,
                'use_histogram_equalization': True,
                'use_median_blur': True
            }
        },
        {
            'name': 'æ•æ„Ÿç­–ç•¥', 
            'params': {
                'algorithm': 'KNN',
                'history': 100,
                'dist2_threshold': 300,
                'use_histogram_equalization': False,
                'use_median_blur': False
            }
        },
        {
            'name': 'æ··åˆç­–ç•¥',
            'params': {
                'algorithm': 'KNN', 
                'history': 150,
                'dist2_threshold': 350,
                'use_histogram_equalization': False,
                'use_median_blur': True,
                'gaussian_kernel': (3, 3)
            }
        }
    ]
    
    results = []
    
    for strategy in strategies:
        print(f"\n   æµ‹è¯•: {strategy['name']}")
        
        try:
            gmm = GMMBackgroundSubtractor(**strategy['params'])
            gmm.setup_track_roi([(300, 200), (800, 900)])
            
            stats = gmm.process_video(video_path, max_frames=50, show_visualization=False)
            
            results.append({
                'strategy': strategy['name'],
                'avg_foreground_ratio': stats['avg_foreground_ratio'],
                'std_foreground_ratio': stats['std_foreground_ratio'],
                'frames_processed': stats['total_frames']
            })
            
            print(f"     å¹³å‡å‰æ™¯æ¯”ä¾‹: {stats['avg_foreground_ratio']:.4f}")
            print(f"     å‰æ™¯æ¯”ä¾‹æ ‡å‡†å·®: {stats['std_foreground_ratio']:.4f}")
            
        except Exception as e:
            print(f"     å¤±è´¥: {e}")
    
    return results

def run_comprehensive_analysis():
    """è¿è¡Œç»¼åˆåˆ†æ"""
    print("=" * 60)
    print("ğŸ¤” é“è½¨å…‰å½±å˜åŒ–å¤„ç†ç­–ç•¥åˆ†æ")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿåœºæ™¯æµ‹è¯•
    print("\nğŸ“Š æ¨¡æ‹Ÿåœºæ™¯æµ‹è¯•ç»“æœ:")
    results_sim = [
        test_strategy_with_equalization(),
        test_strategy_treat_light_as_foreground(),
        test_hybrid_strategy()
    ]
    
    # çœŸå®è§†é¢‘æµ‹è¯•
    print("\nğŸ“Š çœŸå®è§†é¢‘æµ‹è¯•ç»“æœ:")
    results_real = analyze_real_video_strategies()
    
    # è¾“å‡ºå»ºè®®
    print("\n" + "=" * 60)
    print("ğŸ’¡ ç­–ç•¥é€‰æ‹©å»ºè®®:")
    print("=" * 60)
    
    if results_sim:
        best_sim = max(results_sim, key=lambda x: x['train_detection'])
        print(f"æ¨¡æ‹Ÿåœºæ™¯æ¨è: {best_sim['strategy']}")
        print(f"  - åˆ—è½¦æ£€æµ‹ç‡: {best_sim['train_detection']:.2f}")
        print(f"  - å…‰å½±å˜åŒ–æ£€æµ‹ç‡: {best_sim['light_change_detection']:.2f}")
    
    if results_real:
        best_real = min(results_real, key=lambda x: x['std_foreground_ratio'])
        print(f"çœŸå®è§†é¢‘æ¨è: {best_real['strategy']}")
        print(f"  - å¹³å‡å‰æ™¯æ¯”ä¾‹: {best_real['avg_foreground_ratio']:.4f}")
        print(f"  - ç¨³å®šæ€§(æ ‡å‡†å·®): {best_real['std_foreground_ratio']:.4f}")
    
    print("\nğŸ¯ æœ€ç»ˆå»ºè®®:")
    print("1. å¦‚æœå…‰å½±å˜åŒ–æ˜¯åˆ—è½¦è¿›å‡ºçš„é‡è¦æŒ‡æ ‡ â†’ é€‰æ‹©æ•æ„Ÿç­–ç•¥")
    print("2. å¦‚æœè¿½æ±‚ç¨³å®šçš„èƒŒæ™¯æ¨¡å‹ â†’ é€‰æ‹©å‡è¡¡åŒ–ç­–ç•¥") 
    print("3. å¦‚æœåœºæ™¯å¤æ‚å¤šå˜ â†’ é€‰æ‹©æ··åˆç­–ç•¥")
    print("4. å»ºè®®åœ¨å®é™…åœºæ™¯ä¸­æµ‹è¯•å¤šç§ç­–ç•¥")

if __name__ == "__main__":
    run_comprehensive_analysis()