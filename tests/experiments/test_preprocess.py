#!/usr/bin/env python3
"""
é¢„å¤„ç†æŠ€æœ¯æµ‹è¯•è„šæœ¬ - æµ‹è¯•æ•ˆæœå’Œèµ„æºæ¶ˆè€—
"""

import cv2
import numpy as np
import time
import sys
import os
from pathlib import Path

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.background_subtractors.gmm_model_old1 import GMMBackgroundSubtractor

def create_test_frame_with_noise(width=800, height=600):
    """
    åˆ›å»ºå¸¦å™ªå£°çš„æµ‹è¯•å¸§
    
    Returns:
        å¸¦å™ªå£°çš„æµ‹è¯•å¸§
    """
    # åˆ›å»ºåŸºç¡€å›¾åƒ
    frame = np.full((height, width, 3), 100, dtype=np.uint8)
    
    # æ·»åŠ ä¸€äº›å‰æ™¯ç‰©ä½“
    cv2.rectangle(frame, (200, 150), (400, 350), (200, 200, 200), -1)
    cv2.circle(frame, (600, 300), 80, (150, 150, 150), -1)
    
    # æ·»åŠ é«˜æ–¯å™ªå£°
    noise = np.random.normal(0, 25, frame.shape).astype(np.uint8)
    frame_noisy = cv2.add(frame, noise)
    
    # æ·»åŠ æ¤’ç›å™ªå£°
    salt_pepper_prob = 0.01
    noise_mask = np.random.random(frame_noisy.shape[:2])
    frame_noisy[noise_mask < salt_pepper_prob/2] = 0    # æ¤’å™ªå£°
    frame_noisy[noise_mask > 1 - salt_pepper_prob/2] = 255  # ç›å™ªå£°
    
    return frame_noisy

def test_gaussian_blur():
    """æµ‹è¯•é«˜æ–¯æ¨¡ç³Šæ•ˆæœ"""
    print("ğŸ” æµ‹è¯•é«˜æ–¯æ¨¡ç³Š...")
    
    frame = create_test_frame_with_noise()
    
    start_time = time.time()
    
    # ä¸åŒæ ¸å¤§å°çš„é«˜æ–¯æ¨¡ç³Š
    kernels = [(3, 3), (5, 5), (7, 7)]
    
    for kernel_size in kernels:
        single_start = time.time()
        blurred = cv2.GaussianBlur(frame, kernel_size, 0)
        single_time = time.time() - single_start
        
        noise_reduction = np.std(frame) - np.std(blurred)
        print(f"   æ ¸å¤§å° {kernel_size}: {single_time*1000:.2f}ms, å™ªå£°å‡å°‘: {noise_reduction:.2f}")
    
    total_time = time.time() - start_time
    print(f"   âœ… é«˜æ–¯æ¨¡ç³Šæµ‹è¯•å®Œæˆ - æ€»è€—æ—¶: {total_time*1000:.2f}ms")
    
    return True

def test_median_blur():
    """æµ‹è¯•ä¸­å€¼æ»¤æ³¢æ•ˆæœ"""
    print("ğŸ” æµ‹è¯•ä¸­å€¼æ»¤æ³¢...")
    
    frame = create_test_frame_with_noise()
    
    start_time = time.time()
    
    # ä¸åŒæ ¸å¤§å°çš„ä¸­å€¼æ»¤æ³¢
    kernel_sizes = [3, 5, 7]
    
    for ksize in kernel_sizes:
        single_start = time.time()
        median = cv2.medianBlur(frame, ksize)
        single_time = time.time() - single_start
        
        # è®¡ç®—æ¤’ç›å™ªå£°å‡å°‘ç¨‹åº¦
        salt_pepper_pixels_original = np.sum((frame == 0) | (frame == 255))
        salt_pepper_pixels_filtered = np.sum((median == 0) | (median == 255))
        noise_reduction = salt_pepper_pixels_original - salt_pepper_pixels_filtered
        
        print(f"   æ ¸å¤§å° {ksize}: {single_time*1000:.2f}ms, æ¤’ç›å™ªå£°å‡å°‘: {noise_reduction}åƒç´ ")
    
    total_time = time.time() - start_time
    print(f"   âœ… ä¸­å€¼æ»¤æ³¢æµ‹è¯•å®Œæˆ - æ€»è€—æ—¶: {total_time*1000:.2f}ms")
    
    return True

def test_bilateral_filter():
    """æµ‹è¯•åŒè¾¹æ»¤æ³¢æ•ˆæœ"""
    print("ğŸ” æµ‹è¯•åŒè¾¹æ»¤æ³¢...")
    
    frame = create_test_frame_with_noise()
    
    start_time = time.time()
    
    # ä¸åŒå‚æ•°çš„åŒè¾¹æ»¤æ³¢
    params = [
        {'d': 9, 'sigmaColor': 75, 'sigmaSpace': 75},
        {'d': 15, 'sigmaColor': 100, 'sigmaSpace': 100},
        {'d': 5, 'sigmaColor': 50, 'sigmaSpace': 50}
    ]
    
    for param in params:
        single_start = time.time()
        bilateral = cv2.bilateralFilter(frame, param['d'], param['sigmaColor'], param['sigmaSpace'])
        single_time = time.time() - single_start
        
        # è®¡ç®—è¾¹ç¼˜ä¿æŒåº¦ï¼ˆé€šè¿‡è®¡ç®—æ¢¯åº¦å˜åŒ–ï¼‰
        original_grad = cv2.Laplacian(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()
        filtered_grad = cv2.Laplacian(cv2.cvtColor(bilateral, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()
        edge_preservation = filtered_grad / original_grad
        
        print(f"   å‚æ•° {param}: {single_time*1000:.2f}ms, è¾¹ç¼˜ä¿æŒåº¦: {edge_preservation:.3f}")
    
    total_time = time.time() - start_time
    print(f"   âœ… åŒè¾¹æ»¤æ³¢æµ‹è¯•å®Œæˆ - æ€»è€—æ—¶: {total_time*1000:.2f}ms")
    
    return True

def test_histogram_equalization():
    """æµ‹è¯•ç›´æ–¹å›¾å‡è¡¡åŒ–æ•ˆæœ"""
    print("ğŸ” æµ‹è¯•ç›´æ–¹å›¾å‡è¡¡åŒ–...")
    
    frame = create_test_frame_with_noise()
    
    start_time = time.time()
    
    # æµ‹è¯•ä¸åŒçš„ç›´æ–¹å›¾å‡è¡¡åŒ–æ–¹æ³•
    methods = [
        ('å…¨å±€å‡è¡¡åŒ–', lambda img: cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))),
        ('YUVé€šé“å‡è¡¡åŒ–', lambda img: 
            cv2.cvtColor(
                cv2.merge([cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:, :, 0]), 
                          cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:, :, 1], 
                          cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:, :, 2]]), 
                cv2.COLOR_YUV2BGR)
        ),
        ('CLAHE', lambda img: 
            cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            .apply(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))
        )
    ]
    
    for method_name, method_func in methods:
        single_start = time.time()
        try:
            if 'YUV' in method_name:
                result = method_func(frame)
                contrast_improvement = np.std(result) - np.std(frame)
            else:
                result = method_func(frame)
                contrast_improvement = np.std(result) - np.std(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))
            
            single_time = time.time() - single_start
            print(f"   {method_name}: {single_time*1000:.2f}ms, å¯¹æ¯”åº¦æå‡: {contrast_improvement:.2f}")
            
        except Exception as e:
            print(f"   {method_name}: å¤±è´¥ - {e}")
    
    total_time = time.time() - start_time
    print(f"   âœ… ç›´æ–¹å›¾å‡è¡¡åŒ–æµ‹è¯•å®Œæˆ - æ€»è€—æ—¶: {total_time*1000:.2f}ms")
    
    return True

def test_preprocessing_combinations():
    """æµ‹è¯•é¢„å¤„ç†ç»„åˆæ•ˆæœ"""
    print("ğŸ” æµ‹è¯•é¢„å¤„ç†ç»„åˆ...")
    
    frame = create_test_frame_with_noise()
    
    combinations = [
        {
            'name': 'ä»…é«˜æ–¯æ¨¡ç³Š',
            'func': lambda img: cv2.GaussianBlur(img, (5, 5), 0)
        },
        {
            'name': 'é«˜æ–¯+ä¸­å€¼',
            'func': lambda img: cv2.medianBlur(cv2.GaussianBlur(img, (3, 3), 0), 3)
        },
        {
            'name': 'ä¸­å€¼+åŒè¾¹',
            'func': lambda img: cv2.bilateralFilter(cv2.medianBlur(img, 3), 9, 75, 75)
        },
        {
            'name': 'å‡è¡¡åŒ–+é«˜æ–¯+ä¸­å€¼',
            'func': lambda img: 
                cv2.medianBlur(
                    cv2.GaussianBlur(
                        cv2.cvtColor(
                            cv2.merge([cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:, :, 0]), 
                                      cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:, :, 1], 
                                      cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:, :, 2]]), 
                            cv2.COLOR_YUV2BGR
                        ), (3, 3), 0
                    ), 3
                )
        }
    ]
    
    for combo in combinations:
        start_time = time.time()
        
        try:
            processed = combo['func'](frame)
            process_time = time.time() - start_time
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            original_noise = np.std(frame)
            processed_noise = np.std(processed)
            noise_reduction = original_noise - processed_noise
            
            # è®¡ç®—PSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰
            mse = np.mean((frame - processed) ** 2)
            psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else float('inf')
            
            print(f"   {combo['name']}:")
            print(f"     è€—æ—¶: {process_time*1000:.2f}ms")
            print(f"     å™ªå£°å‡å°‘: {noise_reduction:.2f}")
            print(f"     PSNR: {psnr:.2f} dB")
            
        except Exception as e:
            print(f"   {combo['name']}: å¤±è´¥ - {e}")
    
    print("   âœ… é¢„å¤„ç†ç»„åˆæµ‹è¯•å®Œæˆ")
    return True

def test_preprocessing_impact_on_gmm():
    """æµ‹è¯•é¢„å¤„ç†å¯¹GMMç®—æ³•çš„å½±å“"""
    print("ğŸ” æµ‹è¯•é¢„å¤„ç†å¯¹GMMçš„å½±å“...")
    
    video_path = "data/test_videos/train_enter_station.mp4"
    
    if not Path(video_path).exists():
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {video_path}")
        return False
    
    # ä¸åŒçš„é¢„å¤„ç†é…ç½®
    preprocess_configs = [
        {
            'name': 'æ— é¢„å¤„ç†',
            'params': {
                'gaussian_kernel': (0, 0),
                'use_median_blur': False,
                'use_bilateral_filter': False,
                'use_histogram_equalization': False
            }
        },
        {
            'name': 'åŸºç¡€å»å™ª',
            'params': {
                'gaussian_kernel': (5, 5),
                'use_median_blur': True,
                'use_bilateral_filter': False,
                'use_histogram_equalization': False
            }
        },
        {
            'name': 'å¢å¼ºå»å™ª',
            'params': {
                'gaussian_kernel': (3, 3),
                'use_median_blur': True,
                'use_bilateral_filter': True,
                'use_histogram_equalization': False
            }
        },
        {
            'name': 'å®Œæ•´é¢„å¤„ç†',
            'params': {
                'gaussian_kernel': (3, 3),
                'use_median_blur': True,
                'use_bilateral_filter': True,
                'use_histogram_equalization': True
            }
        }
    ]
    
    results = []
    
    for config in preprocess_configs:
        print(f"\n   æµ‹è¯•é…ç½®: {config['name']}")
        
        try:
            start_time = time.time()
            
            gmm = GMMBackgroundSubtractor(
                'MOG2',
                history=200,
                var_threshold=10,
                **config['params']
            )
            
            gmm.setup_track_roi([(300, 200), (800, 900)])
            
            # å¤„ç†å°‘é‡å¸§è¿›è¡Œæµ‹è¯•
            stats = gmm.process_video(video_path, max_frames=30, show_visualization=False)
            
            process_time = time.time() - start_time
            
            results.append({
                'name': config['name'],
                'avg_foreground_ratio': stats['avg_foreground_ratio'],
                'process_time': process_time,
                'frames_processed': stats['total_frames']
            })
            
            print(f"     å¹³å‡å‰æ™¯æ¯”ä¾‹: {stats['avg_foreground_ratio']:.4f}")
            print(f"     å¤„ç†æ—¶é—´: {process_time:.2f}s")
            print(f"     å¸§ç‡: {stats['total_frames']/process_time:.2f} FPS")
            
        except Exception as e:
            print(f"     å¤±è´¥: {e}")
    
    # è¾“å‡ºæ¯”è¾ƒç»“æœ
    print("\nğŸ“Š GMMé¢„å¤„ç†æ•ˆæœæ¯”è¾ƒ:")
    for result in results:
        print(f"   {result['name']}:")
        print(f"     å‰æ™¯æ¯”ä¾‹: {result['avg_foreground_ratio']:.4f}")
        print(f"     å¤„ç†é€Ÿåº¦: {result['frames_processed']/result['process_time']:.2f} FPS")
    
    return True

def visualize_preprocessing_effects():
    """å¯è§†åŒ–é¢„å¤„ç†æ•ˆæœ"""
    print("ğŸ¨ å¯è§†åŒ–é¢„å¤„ç†æ•ˆæœ...")
    
    frame = create_test_frame_with_noise(400, 300)  # å°å°ºå¯¸ç”¨äºæ˜¾ç¤º
    
    # ä¸åŒçš„é¢„å¤„ç†æ–¹æ³•
    methods = [
        ('åŸå›¾', lambda img: img),
        ('é«˜æ–¯æ¨¡ç³Š', lambda img: cv2.GaussianBlur(img, (5, 5), 0)),
        ('ä¸­å€¼æ»¤æ³¢', lambda img: cv2.medianBlur(img, 3)),
        ('åŒè¾¹æ»¤æ³¢', lambda img: cv2.bilateralFilter(img, 9, 75, 75)),
        ('ç»„åˆå»å™ª', lambda img: cv2.medianBlur(cv2.GaussianBlur(img, (3, 3), 0), 3))
    ]
    
    try:
        for i, (name, func) in enumerate(methods):
            processed = func(frame)
            cv2.imshow(f'Preprocessing: {name}', processed)
        
        print("   ğŸ’¡ æŒ‰ä»»æ„é”®å…³é—­çª—å£...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        print("   âœ… å¯è§†åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"   âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        return False

def run_all_preprocess_tests():
    """è¿è¡Œæ‰€æœ‰é¢„å¤„ç†æµ‹è¯•"""
    print("=" * 60)
    print("ğŸ§ª é¢„å¤„ç†æŠ€æœ¯å…¨é¢æµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("é«˜æ–¯æ¨¡ç³Šæµ‹è¯•", test_gaussian_blur),
        ("ä¸­å€¼æ»¤æ³¢æµ‹è¯•", test_median_blur),
        ("åŒè¾¹æ»¤æ³¢æµ‹è¯•", test_bilateral_filter),
        ("ç›´æ–¹å›¾å‡è¡¡åŒ–æµ‹è¯•", test_histogram_equalization),
        ("é¢„å¤„ç†ç»„åˆæµ‹è¯•", test_preprocessing_combinations),
        ("é¢„å¤„ç†å¯¹GMMå½±å“æµ‹è¯•", test_preprocessing_impact_on_gmm),
        ("é¢„å¤„ç†æ•ˆæœå¯è§†åŒ–", visualize_preprocessing_effects),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ” {test_name}")
        print("-" * 40)
        try:
            if test_func():
                passed += 1
                print("âœ… æµ‹è¯•é€šè¿‡")
            else:
                print("âŒ æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    
    print("=" * 60)
    print(f"ğŸ“Š é¢„å¤„ç†æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰é¢„å¤„ç†æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    
    print("=" * 60)
    return passed == total

if __name__ == "__main__":
    run_all_preprocess_tests()