#!/usr/bin/env python3
"""
Jetsonäººè½¦åœç•™æ£€æµ‹æ¼”ç¤ºç¨‹åº - é›¶PyTorchç‰ˆæœ¬
ä½¿ç”¨TensorRT YOLO + IoU-Only DeepSORT + StayDetector
"""

import argparse
import cv2
import os
import time
import numpy as np
import gc
from pathlib import Path

# é›¶PyTorchçš„æ£€æµ‹å™¨ & è·Ÿè¸ªå™¨
from models.detector.yolo_detector import JetsonYOLODetectorTensorRT as JetsonYOLODetector
from models.tracker.multi_object_tracker import MultiObjectTrackerTensorRT as MultiObjectTracker
from models.detector.stay_detector import StayDetector  

# ç®€å•çš„å·¥å…·ç±»æ›¿ä»£
class JetsonROIManager:
    def __init__(self):
        self.rois = {}
    def add_roi(self, name, points):
        self.rois[name] = points
    def point_in_roi(self, x, y, name):
        if name not in self.rois:
            return False
        (x1, y1), (x2, y2) = self.rois[name]
        return x1 <= x <= x2 and y1 <= y <= y2
    def get_roi_names(self):
        return list(self.rois.keys())

class JetsonPerformanceMonitor:
    def start_timing(self):
        return time.time()
    def end_timing(self, start_time, operation_name):
        return time.time() - start_time


def setup_jetson_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒï¼ˆæ— æ¡Œé¢ä¹Ÿå¯è·‘ï¼‰"""
    if 'DISPLAY' not in os.environ:
        os.environ['DISPLAY'] = ':0'
    os.environ['OPENCV_LOG_LEVEL'] = 'ERROR'
    print("ğŸ”§ Jetsonç¯å¢ƒè®¾ç½®å®Œæˆï¼ˆé›¶PyTorchï¼‰")


def cleanup_resources(cap=None, detector=None, tracker=None, stay_detector=None):
    """æ¸…ç†èµ„æº"""
    print("ğŸ§¹ æ¸…ç†èµ„æº...")
    if cap: 
        cap.release()
    cv2.destroyAllWindows()
    if detector:
        try:
            stats = detector.get_performance_stats()
            print(f"ğŸ“Š æœ€ç»ˆæ€§èƒ½: {stats['avg_fps']:.1f}FPS")
        except: 
            pass
        detector.cleanup()
    if stay_detector:
        stay_detector.reset()
    gc.collect()
    print("âœ… èµ„æºæ¸…ç†å®Œæˆ")

# ---------------- ä¸»å‡½æ•° ----------------
def main():
    parser = argparse.ArgumentParser(description='Jetsonäººè½¦åœç•™æ£€æµ‹æ¼”ç¤ºï¼ˆé›¶PyTorchï¼‰')
    parser.add_argument('--engine', type=str, default='yolov8n.engine',
                        help='TensorRTå¼•æ“è·¯å¾„')
    parser.add_argument('--video', type=str,
                        default="data/test_videos/callpose_test/callpose_test.mp4",
                        help='è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--detection_roi', type=str, default='350,340,750,580',
                        help='æ£€æµ‹ROIåæ ‡ x1,y1,x2,y2')
    parser.add_argument('--stay_roi', type=str,
                        help='åœç•™ROIåæ ‡ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--conf', type=float, default=0.6,
                        help='æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--stay_threshold', type=float, default=10.0,
                        help='åœç•™é˜ˆå€¼ï¼ˆç§’ï¼‰')  
    parser.add_argument('--movement_threshold', type=float, default=15.0,
                        help='ç§»åŠ¨é˜ˆå€¼ï¼ˆåƒç´ ï¼‰')
    parser.add_argument('--min_frames', type=int, default=5,
                        help='æœ€å°è¿ç»­é™æ­¢å¸§æ•°')
    parser.add_argument('--detection_interval', type=int, default=3,
                        help='æ£€æµ‹é—´éš”å¸§æ•°')
    parser.add_argument('--max_frames', type=int, default=1000,
                        help='æœ€å¤§å¤„ç†å¸§æ•°')
    parser.add_argument('--frame_skip', type=int, default=0,
                        help='é¢å¤–è·³å¸§æ•°é‡')
    parser.add_argument('--save', type=str, default='video/output.mp4',
                        help='ä¿å­˜è·¯å¾„ï¼ˆç©ºåˆ™ä¸ä¿å­˜ï¼‰')
    args = parser.parse_args()

    setup_jetson_environment()

    # è§£æROI
    try:
        detection_coords = [int(x) for x in args.detection_roi.split(',')]
        detection_points = [(detection_coords[0], detection_coords[1]),
                            (detection_coords[2], detection_coords[3])]
        stay_points = None
        if args.stay_roi:
            stay_coords = [int(x) for x in args.stay_roi.split(',')]
            stay_points = [(stay_coords[0], stay_coords[1]),
                           (stay_coords[2], stay_coords[3])]
    except Exception as e:
        print(f"âŒ ROIè§£æé”™è¯¯: {e}")
        return

    video_path = Path(args.video)
    if not video_path.exists():
        print(f"âŒ è§†é¢‘ä¸å­˜åœ¨: {args.video}")
        return

    print("ğŸš€ å¯åŠ¨Jetsonäººè½¦æ£€æµ‹ç³»ç»Ÿï¼ˆé›¶PyTorchï¼‰")
    print(f"ğŸ“¹ è§†é¢‘: {args.video}")
    print(f"ğŸ¯ æ£€æµ‹ROI: {detection_points}")
    if stay_points: 
        print(f"ğŸ¯ åœç•™ROI: {stay_points}")
    print(f"ğŸ”§ å¼•æ“: {args.engine}")
    print(f"âš™ï¸ ç½®ä¿¡åº¦: {args.conf}")
    print(f"â±ï¸ åœç•™é˜ˆå€¼: {args.stay_threshold}ç§’")  # æ˜¾ç¤ºç§’æ•°
    print(f"ğŸƒ ç§»åŠ¨é˜ˆå€¼: {args.movement_threshold}åƒç´ ")
    print(f"â© æ£€æµ‹é—´éš”: æ¯{args.detection_interval}å¸§")
    print("-" * 60)

    cap = None
    detector = None
    tracker = None
    stay_detector = None
    
    try:
        # 1. åˆå§‹åŒ–ç³»ç»Ÿï¼ˆé›¶PyTorchï¼‰
        detector = JetsonYOLODetector(args.engine, conf_threshold=args.conf)
        tracker = MultiObjectTracker(max_age=50, min_hits=2, iou_threshold=0.3, use_gpu=True)
        roi_manager = JetsonROIManager()
        perf_mon = JetsonPerformanceMonitor()

        # 2. è®¾ç½®ROI
        detector.set_roi(detection_points)
        tracker.set_roi(detection_points)
        roi_manager.add_roi("detection_roi", detection_points)
        if stay_points:
            roi_manager.add_roi("stay_roi", stay_points)

        # 3. åˆå§‹åŒ–StayDetector
        stay_detector = StayDetector(
            stay_threshold=args.stay_threshold,
            movement_threshold=args.movement_threshold,
            min_frames=args.min_frames,
            roi_manager=roi_manager,
            alert_dir="alerts"
        )

        # 4. æ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened(): 
            print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘")
            return
            
        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
        
        # è§†é¢‘å†™å…¥å™¨
        writer = None
        if args.save:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(args.save, fourcc, fps, (w, h))

        print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        print("ğŸ® æŒ‰é”®: q=é€€å‡º  r=é‡ç½®  s=åˆ‡æ¢è·³å¸§  c=æ¸…ç†å†…å­˜")
        print("-" * 60)

        frame_count = 0
        last_log_time = time.time()
        last_frame_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret or frame_count >= args.max_frames: 
                break
                
            # é¢å¤–è·³å¸§
            if args.frame_skip > 0 and frame_count % (args.frame_skip + 1) != 0:
                frame_count += 1
                continue

            # å®šæœŸgc
            if frame_count % 200 == 0: 
                gc.collect()

            try:
                current_time = time.time()
                
                # æ¨ç† - ç›´æ¥ä½¿ç”¨detectæ–¹æ³•ï¼Œä¸éœ€è¦è°ƒç”¨_postprocess
                detections = detector.detect(frame)
                
                # è¿‡æ»¤æ£€æµ‹ç»“æœï¼Œåªä¿ç•™ç›®æ ‡ç±»åˆ«
                if len(detections) > 0:
                    # detectionså·²ç»æ˜¯åå¤„ç†åçš„ç»“æœï¼Œæ ¼å¼ä¸º[[x1,y1,x2,y2,conf,class_id], ...]
                    valid_detections = []
                    for det in detections:
                        if len(det) >= 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å…ƒç´ 
                            class_id = int(det[5])
                            # åªä¿ç•™person(0), car(2), bus(5), truck(7)
                            if class_id in [0, 2, 5, 7]:
                                valid_detections.append(det)
                    detections = np.array(valid_detections, dtype=np.float32)
                else:
                    detections = np.empty((0, 6), dtype=np.float32)
                
                # è·Ÿè¸ª
                tracked_objects = tracker.update(detections, frame) if len(detections) > 0 else []
                
                # ä½¿ç”¨StayDetectorè¿›è¡Œåœç•™æ£€æµ‹
                stay_detector.update(tracked_objects, current_time, frame)
                staying_objects = stay_detector.get_staying_objects()

                # å¯è§†åŒ–
                vis = frame.copy()
                
                # ç»˜åˆ¶ROIæ¡†
                for name, points in roi_manager.rois.items():
                    cv2.rectangle(vis, points[0], points[1], (0, 255, 0), 2)
                    cv2.putText(vis, name, (points[0][0], points[0][1]-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†
                for obj in tracked_objects:
                    if len(obj) < 5:
                        continue
                    x1, y1, x2, y2, tid = obj[:5]
                    
                    # æ ¹æ®æ˜¯å¦åœç•™è®¾ç½®é¢œè‰²
                    if tid in staying_objects:
                        color = (0, 0, 255)  # çº¢è‰² - åœç•™
                        status = "STAYING"
                    else:
                        color = (0, 255, 0)   # ç»¿è‰² - æ­£å¸¸
                        status = "MOVING"
                    
                    cv2.rectangle(vis, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    
                    # æ˜¾ç¤ºIDå’ŒçŠ¶æ€
                    label = f'ID:{int(tid)} {status}'
                    cv2.putText(vis, label, (int(x1), int(y1) - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                # æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
                current_time = time.time()
                fps = 1.0 / (current_time - last_frame_time + 1e-7)
                last_frame_time = current_time
                
                info = f'FPS:{fps:.1f}  Track:{len(tracked_objects)}  Stay:{len(staying_objects)}'
                cv2.putText(vis, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                
                # æ˜¾ç¤ºåœç•™é˜ˆå€¼ä¿¡æ¯
                threshold_info = f'Stay Threshold: {args.stay_threshold}s  Move Threshold: {args.movement_threshold}px'
                cv2.putText(vis, threshold_info, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
                
                # ä¿å­˜/æ˜¾ç¤º
                if writer:
                    writer.write(vis)
                cv2.imshow('Jetson Zero-PyTorch Demo', vis)
                
                # æ€§èƒ½æ—¥å¿—
                if current_time - last_log_time > 5:
                    print(f"ğŸ“Š å¸§: {frame_count}  FPS: {fps:.1f}  è·Ÿè¸ª: {len(tracked_objects)}  åœç•™: {len(staying_objects)}")
                    last_log_time = current_time

                # é”®ç›˜æ§åˆ¶
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):
                    # é‡ç½®çŠ¶æ€
                    stay_detector.reset()
                    print("ğŸ”„ åœç•™æ£€æµ‹çŠ¶æ€å·²é‡ç½®")
                elif key == ord('c'):
                    gc.collect()
                    print("ğŸ§¹ å¼ºåˆ¶åƒåœ¾å›æ”¶")

            except Exception as e:
                print(f"âŒ å¤„ç†å¸§ {frame_count} æ—¶å‡ºé”™: {e}")
                continue

            frame_count += 1

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cleanup_resources(cap, detector, tracker, stay_detector)
        print("ğŸ›‘ ç¨‹åºç»“æŸï¼ˆé›¶PyTorchï¼‰")


if __name__ == "__main__":
    main()
