# jetson_train_detection_visual_demo.py
#!/usr/bin/env python3
"""
Jetsonä¼˜åŒ–çš„åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹æ¼”ç¤ºç¨‹åº - å¯è§†åŒ–ç‰ˆæœ¬
å®æ—¶æ˜¾ç¤ºæ£€æµ‹ç»“æœï¼Œé€‚åˆåœ¨Jetsonæœ¬åœ°æµ‹è¯•æ•ˆæœ
"""

import argparse
from pathlib import Path
import os
from models.detector.train_detector import JetsonTrainStationDetectorVisual
from models.background_subtractor.gmm_model import JetsonGMMBackgroundSubtractor

def setup_display():
    """è®¾ç½®æ˜¾ç¤ºç¯å¢ƒ"""
    # è®¾ç½®æ˜¾ç¤ºï¼ˆé€‚ç”¨äºJetsonï¼‰
    if 'DISPLAY' not in os.environ:
        os.environ['DISPLAY'] = ':0'
    
    # è®¾ç½®GTKåç«¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
    os.environ['GDK_BACKEND'] = 'x11'

def main():
    """ä¸»å‡½æ•° - å¯è§†åŒ–ç‰ˆæœ¬"""
    parser = argparse.ArgumentParser(description='Jetsonåˆ—è½¦è¿›å‡ºç«™æ£€æµ‹æ¼”ç¤º - å¯è§†åŒ–ç‰ˆæœ¬')
    parser.add_argument('--video', type=str, default='data/test_videos/train_enter_station.mp4',
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ ')
    parser.add_argument('--roi', type=str, default='180,200,600,700',
                       help='ROIåŒºåŸŸåæ ‡ x1,y1,x2,y2 ')
    parser.add_argument('--preprocess_mode', type=str, default='enhance_dark', 
                       choices=['basic', 'enhance_dark'],
                       help='é¢„å¤„ç†æ¨¡å¼: basic(æ€§èƒ½ä¼˜å…ˆ) æˆ– enhance_dark(æ•ˆæœä¼˜å…ˆ) ')
    parser.add_argument('--spatial_threshold', type=float, default=0.3,
                       help='ç©ºåŸŸæ£€æµ‹é˜ˆå€¼ (é»˜è®¤: 0.3)')
    parser.add_argument('--temporal_frames', type=int, default=50,
                       help='æ—¶åŸŸåˆ¤æ–­å¸§æ•° (é»˜è®¤: 50)')
    parser.add_argument('--temporal_threshold', type=int, default=25,
                       help='æ—¶åŸŸåˆ¤æ–­é˜ˆå€¼ ')
    parser.add_argument('--max_frames', type=int, default=1500,
                       help='æœ€å¤§å¤„ç†å¸§æ•° ')
    parser.add_argument('--print_interval', type=int, default=10,
                       help='ç½®ä¿¡åº¦æ‰“å°é—´éš”å¸§æ•° (é»˜è®¤: 10)')
    parser.add_argument('--no_visualization', action='store_true',
                       help='ç¦ç”¨å¯è§†åŒ–æ˜¾ç¤º')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ˜¾ç¤ºç¯å¢ƒ
    if not args.no_visualization:
        setup_display()
    
    # è§£æROIåæ ‡
    try:
        roi_coords = [int(x) for x in args.roi.split(',')]
        if len(roi_coords) != 4:
            raise ValueError("ROIåæ ‡å¿…é¡»æ˜¯4ä¸ªæ•°å­—")
        roi_points = [(roi_coords[0], roi_coords[1]), (roi_coords[2], roi_coords[3])]
    except Exception as e:
        print(f"âŒ ROIåæ ‡è§£æé”™è¯¯: {e}")
        return
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
    if not Path(args.video).exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video}")
        print("ğŸ’¡ è¯·ç¡®ä¿è§†é¢‘æ–‡ä»¶å·²å¤åˆ¶åˆ°Jetsonï¼Œæˆ–ä½¿ç”¨ --video å‚æ•°æŒ‡å®šæ­£ç¡®è·¯å¾„")
        return
    
    print("ğŸš€ å¯åŠ¨Jetsonåˆ—è½¦è¿›å‡ºç«™æ£€æµ‹ç³»ç»Ÿ - å¯è§†åŒ–ç‰ˆæœ¬")
    print(f"ğŸ“¹ è§†é¢‘æ–‡ä»¶: {args.video}")
    print(f"ğŸ¯ ROIåŒºåŸŸ: {roi_points}")
    print(f"ğŸ”§ é¢„å¤„ç†æ¨¡å¼: {args.preprocess_mode}")
    print(f"âš™ï¸ ç©ºåŸŸé˜ˆå€¼: {args.spatial_threshold}")
    print(f"â±ï¸ æ—¶åŸŸå¸§æ•°: {args.temporal_frames}")
    print(f"ğŸ“Š æ—¶åŸŸé˜ˆå€¼: {args.temporal_threshold}")
    print(f"ğŸ“ æ‰“å°é—´éš”: æ¯ {args.print_interval} å¸§")
    print(f"ğŸ‘ï¸ å¯è§†åŒ–: {'å¯ç”¨' if not args.no_visualization else 'ç¦ç”¨'}")
    print(f"ğŸ’¾ æˆªå›¾ç±»å‹: ROIå‰æ™¯æ©ç  (åå¤„ç†)")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: outputs/train_detection/")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–Jetsonä¼˜åŒ–çš„GMMèƒŒæ™¯å‡é™¤å™¨
        bg_subtractor = JetsonGMMBackgroundSubtractor(
            algorithm='MOG2', 
            preprocess_mode=args.preprocess_mode,
            history=150,
            varThreshold=16,
            detect_shadows=False
        )
        
        # è®¾ç½®ROIåŒºåŸŸ
        bg_subtractor.setup_single_roi(roi_points, 'train_detection_roi')
        
        # åˆå§‹åŒ–Jetsonä¼˜åŒ–çš„åˆ—è½¦æ£€æµ‹å™¨
        detector = JetsonTrainStationDetectorVisual(
            spatial_threshold=args.spatial_threshold,
            temporal_frames=args.temporal_frames,
            temporal_threshold=args.temporal_threshold,
            print_interval=args.print_interval
        )
        
        # è®¾ç½®å¯è§†åŒ–æ¨¡å¼
        detector.show_visualization = not args.no_visualization
        
        print("ğŸ¯ å¼€å§‹æ£€æµ‹...")
        print("æ§åˆ¶è¯´æ˜:")
        print("  - æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
        print("  - æŒ‰ 's' é”®æ‰‹åŠ¨ä¿å­˜å½“å‰å¸§æˆªå›¾")
        print("-" * 60)
        
        # å¤„ç†è§†é¢‘ï¼ˆå¯è§†åŒ–ç‰ˆæœ¬ï¼‰
        stats = detector.process_video_with_visualization(
            video_path=args.video,
            bg_subtractor=bg_subtractor,
            max_frames=args.max_frames
        )
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æ£€æµ‹ç»Ÿè®¡ç»“æœ:")
        print("=" * 60)
        print(f"   æ€»å¤„ç†å¸§æ•°: {stats['total_frames']}")
        print(f"   è¿›ç«™äº‹ä»¶æ•°: {stats['entry_events']}")
        print(f"   å¹³å‡FPS: {stats['avg_fps']:.1f}")
        print(f"   ä¿å­˜ROIæ©ç æˆªå›¾: {stats['saved_snapshots']} å¼ ")
        print(f"   æœ€ç»ˆçŠ¶æ€: {stats['final_state']}")
        
        # æ˜¾ç¤ºäº‹ä»¶å†å²
        if stats['event_history']:
            print(f"\nğŸ“‹ äº‹ä»¶å†å²:")
            for i, event in enumerate(stats['event_history']):
                print(f"   äº‹ä»¶{i+1}: å¸§{event['frame_index']} - {event['event_type']} "
                      f"(ç½®ä¿¡åº¦: {event['confidence']:.3f})")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        bg_stats = bg_subtractor.get_performance_stats()
        detector_stats = detector.get_detection_status()
        print(f"\nğŸ¯ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   é¢„å¤„ç†æ¨¡å¼: {args.preprocess_mode}")
        print(f"   èƒŒæ™¯å‡é™¤å¹³å‡è€—æ—¶: {bg_stats['avg_time']:.1f}ms")
        print(f"   æ£€æµ‹å™¨å¹³å‡FPS: {detector_stats['fps']:.1f}")
        
        # è¾“å‡ºæ–‡ä»¶ä½ç½®
        print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
        print(f"   ROIå‰æ™¯æ©ç æˆªå›¾ä¿å­˜è‡³: outputs/train_detection/")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        # å³ä½¿ä¸­æ–­ä¹Ÿæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        try:
            detector_stats = detector.get_detection_status()
            print(f"\nğŸ“Š ä¸­æ–­æ—¶ç»Ÿè®¡:")
            print(f"   å·²å¤„ç†å¸§æ•°: {detector_stats.get('total_frames', 0)}")
            print(f"   è¿›ç«™äº‹ä»¶: {detector_stats.get('entry_count', 0)}")
            print(f"   ä¿å­˜ROIæ©ç æˆªå›¾: {detector_stats.get('saved_snapshots', 0)}")
        except:
            pass
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
