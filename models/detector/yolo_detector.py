# models/yolo_detector.py
import numpy as np
import os
import cv2
import time
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit  # æ·»åŠ è¿™ä¸€è¡Œï¼Œè‡ªåŠ¨åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
from collections import deque

class YOLODetector:
    """çœŸæ­£çš„TensorRT YOLOç›®æ ‡æ£€æµ‹å™¨"""

    def __init__(self, model_path='yolov8n.engine', conf_threshold=0.5,
                 target_classes=None, use_gpu=True):
        """
        TensorRT YOLOæ£€æµ‹å™¨åˆå§‹åŒ–

        Args:
            model_path: TensorRTå¼•æ“æ–‡ä»¶è·¯å¾„ (.engine)
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            target_classes: ç›®æ ‡ç±»åˆ«åˆ—è¡¨
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        """

        print("ğŸ¯ ä½¿ç”¨pycuda.autoinitè‡ªåŠ¨åˆ›å»ºCUDAä¸Šä¸‹æ–‡")
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        try:
            # è·å–å½“å‰CUDAä¸Šä¸‹æ–‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            ctx = cuda.Context.get_current()
            print(f"âœ… å½“å‰çº¿ç¨‹å·²è·å–CUDAä¸Šä¸‹æ–‡: {ctx}")
        except Exception as e:
            print(f"âš ï¸ è·å–CUDAä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {e}")
        # ------------------------------------------------
        
        self.conf_threshold = conf_threshold
        self.target_classes = target_classes or ['person', 'car']
        self.use_gpu = use_gpu
        self.input_shape = (1, 3, 640, 640)
        self.input_size = 640
        
        # COCOç±»åˆ«åç§° (ä¿æŒä¸å˜)
        self.class_names = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
        
        # åˆ›å»ºç›®æ ‡ç±»åˆ«çš„IDæ˜ å°„
        self.target_class_ids = []
        for class_name in self.target_classes:
            if class_name in self.class_names:
                self.target_class_ids.append(self.class_names.index(class_name))
        
        # æ€§èƒ½ç›‘æ§
        self.inference_times = deque(maxlen=30)
        self.frame_count = 0
        
        # ROIç›¸å…³
        self.roi_points = None
        self.roi_active = False
        
        # æ ‡è®°å·²æ¸…ç†çŠ¶æ€
        self._cleaned = False
        self._context_created_by_autoinit = True  # æ ‡è®°ä¸Šä¸‹æ–‡åˆ›å»ºæ–¹å¼
        
        # åŠ è½½TensorRTå¼•æ“
        self.engine = self._load_tensorrt_engine(model_path)
        
        print(f"âœ… TensorRT YOLOæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ¯ ç›®æ ‡ç±»åˆ«: {self.target_classes}")
        print(f"ğŸ¯ ç›®æ ‡ç±»åˆ«ID: {self.target_class_ids}")

        # if use_gpu:
        #     self.verify_cuda_context()

    def verify_cuda_context(self):
        """éªŒè¯CUDAä¸Šä¸‹æ–‡æ˜¯å¦æ­£ç¡®è®¾ç½®"""
        try:
            import pycuda.driver as cuda
            import traceback
            
            print("\nğŸ” éªŒè¯CUDAä¸Šä¸‹æ–‡çŠ¶æ€:")
            
            # 1. æ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡
            try:
                ctx = cuda.Context.get_current()
                print(f"  âœ… å½“å‰CUDAä¸Šä¸‹æ–‡: {ctx}")
            except cuda.Error as e:
                print(f"  âŒ æ— æ³•è·å–å½“å‰CUDAä¸Šä¸‹æ–‡: {e}")
                return False
            
            # 2. æ£€æŸ¥è®¾å¤‡ä¿¡æ¯
            try:
                device = ctx.get_device()
                print(f"  âœ… å½“å‰è®¾å¤‡: {device.name()}")
                print(f"  âœ… è®¾å¤‡è®¡ç®—èƒ½åŠ›: {device.compute_capability()}")
            except Exception as e:
                print(f"  âš ï¸ æ— æ³•è·å–è®¾å¤‡ä¿¡æ¯: {e}")
            
            # 3. æ£€æŸ¥GPUå†…å­˜åˆ†é…
            if hasattr(self, 'input_gpu') and self.input_gpu:
                print(f"  âœ… è¾“å…¥GPUå†…å­˜å·²åˆ†é…: {int(self.input_gpu)}")
            else:
                print(f"  âŒ è¾“å…¥GPUå†…å­˜æœªåˆ†é…")
                return False
                
            if hasattr(self, 'output_gpu') and self.output_gpu:
                print(f"  âœ… è¾“å‡ºGPUå†…å­˜å·²åˆ†é…: {int(self.output_gpu)}")
            else:
                print(f"  âŒ è¾“å‡ºGPUå†…å­˜æœªåˆ†é…")
                return False
            
            # 4. æ£€æŸ¥CUDAæµ
            if hasattr(self, 'stream') and self.stream:
                print(f"  âœ… CUDAæµå·²åˆ›å»º: {self.stream}")
            else:
                print(f"  âŒ CUDAæµæœªåˆ›å»º")
                return False
            
            # 5. æ£€æŸ¥TensorRTä¸Šä¸‹æ–‡
            if hasattr(self, 'context') and self.context:
                print(f"  âœ… TensorRTä¸Šä¸‹æ–‡å·²åˆ›å»º")
            else:
                print(f"  âŒ TensorRTä¸Šä¸‹æ–‡æœªåˆ›å»º")
                return False
            
            print("  ğŸ‰ æ‰€æœ‰CUDAå’ŒTensorRTèµ„æºéªŒè¯é€šè¿‡ï¼")
            return True
            
        except Exception as e:
            print(f"  âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()
            return False

    def _load_tensorrt_engine(self, engine_path):
        """åŠ è½½TensorRTå¼•æ“ - ç¡®ä¿åœ¨æ­£ç¡®çš„CUDAä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œ"""
        if not os.path.exists(engine_path):
            raise FileNotFoundError(f"TensorRTå¼•æ“æ–‡ä»¶ä¸å­˜åœ¨: {engine_path}")
        
        print(f"ğŸ“ åŠ è½½TensorRTå¼•æ“: {engine_path}")
        
        # try:
        #     # éªŒè¯å½“å‰æ˜¯å¦æœ‰CUDAä¸Šä¸‹æ–‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        #     import pycuda.driver as cuda
        #     try:
        #         ctx = cuda.Context.get_current()
        #         print(f"ğŸ” TensorRTå¼•æ“åŠ è½½æ—¶çš„CUDAä¸Šä¸‹æ–‡: {ctx}")
        #     except Exception as e:
        #         print(f"âš ï¸ è­¦å‘Š: å½“å‰çº¿ç¨‹æ²¡æœ‰CUDAä¸Šä¸‹æ–‡: {e}")
        #         print("ğŸ”„ æ­£åœ¨å°è¯•é€šè¿‡pycudaæ“ä½œè‡ªåŠ¨åˆ›å»ºä¸Šä¸‹æ–‡...")
        # except ImportError:
        #     pass
        
        # åˆå§‹åŒ–TensorRT
        logger = trt.Logger(trt.Logger.WARNING)
        
        with open(engine_path, 'rb') as f, trt.Runtime(logger) as runtime:
            engine = runtime.deserialize_cuda_engine(f.read())
        
        # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        self.context = engine.create_execution_context()
        
        # åˆ†é…è¾“å…¥è¾“å‡ºå†…å­˜ - è¿™ä¼šåœ¨å½“å‰CUDAä¸Šä¸‹æ–‡ä¸­åˆ†é…å†…å­˜
        self._allocate_buffers(engine)
        
        print("âœ… TensorRTå¼•æ“åŠ è½½æˆåŠŸ")
        
        # éªŒè¯å¼•æ“ç»‘å®šæ˜¯å¦æˆåŠŸ
        if hasattr(self, 'bindings') and self.bindings:
            print(f"ğŸ”— å¼•æ“ç»‘å®šå®Œæˆï¼Œbindingæ•°é‡: {len(self.bindings)}")
        
        return engine

    def _allocate_buffers(self, engine):
        """åˆ†é…GPUå†…å­˜ç¼“å†²åŒº - ç¡®ä¿åœ¨æ­£ç¡®çš„CUDAä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œ"""
        try:
            # éªŒè¯å½“å‰çº¿ç¨‹æ˜¯å¦æœ‰CUDAä¸Šä¸‹æ–‡
            import pycuda.driver as cuda
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            # try:
            #     ctx = cuda.Context.get_current()
            #     device = ctx.get_device()
            #     print(f"ğŸ” å†…å­˜åˆ†é…æ—¶CUDAä¸Šä¸‹æ–‡: {ctx}")
            #     print(f"ğŸ” å½“å‰è®¾å¤‡: {device.name()}")
            # except Exception as e:
            #     print(f"âš ï¸ æ— æ³•è·å–CUDAä¸Šä¸‹æ–‡ä¿¡æ¯: {e}")
                # è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæœ‰äº›ç³»ç»Ÿå¯èƒ½ä¸æä¾›è¯¦ç»†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
                
        except ImportError:
            print("âš ï¸ æ— æ³•å¯¼å…¥pycuda.driverï¼Œå†…å­˜åˆ†é…å¯èƒ½å¤±è´¥")
            return
        
        # è¾“å…¥é…ç½®
        self.input_shape = (1, 3, 640, 640)
        self.input_size = int(np.prod(self.input_shape))
        
        # è¾“å‡ºé…ç½®
        self.output_shape = (84, 8400)
        self.output_size = int(np.prod(self.output_shape))
        
        # print(f"ğŸ“Š å†…å­˜åˆ†é…ä¿¡æ¯:")
        # print(f"  è¾“å…¥å½¢çŠ¶: {self.input_shape}, å¤§å°: {self.input_size} å…ƒç´ ")
        # print(f"  è¾“å‡ºå½¢çŠ¶: {self.output_shape}, å¤§å°: {self.output_size} å…ƒç´ ")
        
        try:
            # åˆ†é…GPUå†…å­˜ - è¿™äº›æ“ä½œå¿…é¡»åœ¨æœ‰æ•ˆçš„CUDAä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œ
            print("ğŸ”„ åˆ†é…è¾“å…¥GPUå†…å­˜...")
            self.input_gpu = cuda.mem_alloc(self.input_size * 4)  # float32 (4å­—èŠ‚)
            print(f"  è¾“å…¥å†…å­˜åœ°å€: {int(self.input_gpu)}")
            
            print("ğŸ”„ åˆ†é…è¾“å‡ºGPUå†…å­˜...")
            self.output_gpu = cuda.mem_alloc(self.output_size * 4)  # float32 (4å­—èŠ‚)
            print(f"  è¾“å‡ºå†…å­˜åœ°å€: {int(self.output_gpu)}")
            
            # åˆ›å»ºbindingsåˆ—è¡¨
            self.bindings = [int(self.input_gpu), int(self.output_gpu)]
            
            # å°è¯•è®¾ç½®å¼ é‡åœ°å€ï¼ˆTensorRT 8.5+ APIï¼‰
            try:
                print("ğŸ”„ è®¾ç½®TensorRTå¼ é‡åœ°å€...")
                self.context.set_tensor_address("images", int(self.input_gpu))
                self.context.set_tensor_address("output0", int(self.output_gpu))
                print("âœ… ä½¿ç”¨TensorRT 8.5+ set_tensor_address API")
            except Exception as e:
                print(f"âš ï¸ è®¾ç½®å¼ é‡åœ°å€æ—¶å‡ºé”™ï¼Œä½¿ç”¨ä¼ ç»Ÿbindingsæ–¹æ³•: {e}")
                # å¯¹äºæ—§ç‰ˆæœ¬TensorRTï¼Œbindingså·²ç»è¶³å¤Ÿ
            
            # åˆ›å»ºCUDAæµ
            print("ğŸ”„ åˆ›å»ºCUDAæµ...")
            self.stream = cuda.Stream()
            print(f"  CUDAæµåˆ›å»ºæˆåŠŸ: {self.stream}")
            
            print("âœ… GPUå†…å­˜åˆ†é…å®Œæˆ")
            
            # éªŒè¯å†…å­˜åˆ†é…
            total_memory = (self.input_size + self.output_size) * 4 / 1024 / 1024  # MB
            print(f"ğŸ“Š åˆ†é…çš„GPUå†…å­˜æ€»é‡: {total_memory:.2f} MB")
            
        except Exception as e:
            print(f"âŒ GPUå†…å­˜åˆ†é…å¤±è´¥: {e}")
            print("âš ï¸ å¯èƒ½çš„åŸå› :")
            print("   1. æ²¡æœ‰å¯ç”¨çš„GPU")
            print("   2. GPUå†…å­˜ä¸è¶³")
            print("   3. CUDAä¸Šä¸‹æ–‡æœªæ­£ç¡®åˆå§‹åŒ–")
            print("   4. pycudaå®‰è£…æœ‰é—®é¢˜")
            
            # æ¸…ç†å·²åˆ†é…çš„èµ„æº
            if hasattr(self, 'input_gpu') and self.input_gpu:
                try:
                    self.input_gpu.free()
                except:
                    pass
            
            if hasattr(self, 'output_gpu') and self.output_gpu:
                try:
                    self.output_gpu.free()
                except:
                    pass
            
            raise RuntimeError(f"GPUå†…å­˜åˆ†é…å¤±è´¥: {e}")

    def set_roi(self, points):
        """è®¾ç½®ROIåŒºåŸŸ"""
        if len(points) == 2:
            self.roi_points = points
            self.roi_active = True
            print(f"ğŸ¯ è®¾ç½®æ£€æµ‹ROI: {points}")
        else:
            print("âš ï¸ ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")

    def disable_roi(self):
        """ç¦ç”¨ROIæ£€æµ‹"""
        self.roi_active = False
        print("ğŸ”“ ç¦ç”¨ROIæ£€æµ‹")

    def detect(self, frame):
        """
        TensorRTç›®æ ‡æ£€æµ‹

        Args:
            frame: è¾“å…¥å›¾åƒ

        Returns:
            detections: æ£€æµ‹ç»“æœ [[x1, y1, x2, y2, confidence, class_id], ...]
        """
        start_time = time.time()
        self.frame_count += 1

        try:
            if self.roi_active and self.roi_points:
                detections = self._detect_in_roi(frame)
            else:
                detections = self._detect_full_frame(frame)

            # æ€§èƒ½ç»Ÿè®¡
            inference_time = time.time() - start_time
            self.inference_times.append(inference_time)

            return detections

        except Exception as e:
            print(f"âŒ TensorRTæ£€æµ‹å¤±è´¥: {e}")
            return np.empty((0, 6), dtype=np.float32)

    def _detect_in_roi(self, frame):
        """ROIåŒºåŸŸæ£€æµ‹"""
        x1, y1 = self.roi_points[0]
        x2, y2 = self.roi_points[1]

        h, w = frame.shape[:2]
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)

        if x2 <= x1 or y2 <= y1:
            return np.empty((0, 6), dtype=np.float32)

        roi_frame = frame[y1:y2, x1:x2]
        
        if roi_frame.size == 0:
            return np.empty((0, 6), dtype=np.float32)

        # åœ¨ROIåŒºåŸŸè¿›è¡Œæ¨ç†
        detections = self._inference(roi_frame)
        
        # åæ ‡æ˜ å°„å›åŸå›¾
        if len(detections) > 0:
            detections[:, 0] += x1  # x1
            detections[:, 1] += y1  # y1  
            detections[:, 2] += x1  # x2
            detections[:, 3] += y1  # y2
            
        return detections

    def _detect_full_frame(self, frame):
        """å…¨å›¾æ£€æµ‹"""
        return self._inference(frame)

    def _inference(self, frame):
        """TensorRTæ¨ç†æ ¸å¿ƒå‡½æ•°"""
        # ä½¿ç”¨ä¼˜åŒ–ç‰ˆæ¨ç†
        return self._inference_optimized(frame)

    def _preprocess(self, frame):
        """å›¾åƒé¢„å¤„ç† - ä½¿ç”¨640x640"""
        # è°ƒæ•´å¤§å°åˆ°640x640
        img = cv2.resize(frame, (640, 640))  # æ”¹å›640x640
        
        # å½’ä¸€åŒ–: 0-255 -> 0-1
        img = img.astype(np.float32) / 255.0
        
        # BGR to RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # HWC to CHW
        img = img.transpose(2, 0, 1)
        
        # æ·»åŠ batchç»´åº¦å¹¶ç¡®ä¿å†…å­˜è¿ç»­
        blob = np.ascontiguousarray(img).reshape(1, 3, 640, 640)  # æ”¹å›640x640
        
        return blob

    def _postprocess(self, outputs, orig_shape):
        """å®Œå…¨å‘é‡åŒ–çš„åå¤„ç† - å‚è€ƒæ‰‹åŠ¿æ£€æµ‹ä»£ç """
        start_time = time.time()
        
        # 1. è¾“å‡ºé‡å¡‘ (0.1ms)
        predictions = outputs.transpose(1, 0)  # [8400, 84]
        
        # 2. ä¸€æ¬¡æ€§æå–æ‰€æœ‰åˆ†æ•°å’Œç±»åˆ« (1ms)
        scores = predictions[:, 4:84]
        max_scores = np.max(scores, axis=1)
        max_class_ids = np.argmax(scores, axis=1)
        
        # 3. å‘é‡åŒ–è¿‡æ»¤ (1ms)
        conf_mask = max_scores > self.conf_threshold
        class_mask = np.isin(max_class_ids, self.target_class_ids)
        valid_mask = conf_mask & class_mask
        
        if not np.any(valid_mask):
            return np.empty((0, 6), dtype=np.float32)
        
        # 4. æå–æœ‰æ•ˆæ£€æµ‹
        valid_indices = np.where(valid_mask)[0]
        boxes = predictions[valid_indices, :4]
        scores = max_scores[valid_indices]
        class_ids = max_class_ids[valid_indices]
        
        # 5. å‘é‡åŒ–åæ ‡è½¬æ¢ (2ms)
        orig_h, orig_w = orig_shape[:2]
        scale_x = orig_w / 640.0
        scale_y = orig_h / 640.0
        
        # ä¸­å¿ƒåæ ‡è½¬è§’ç‚¹åæ ‡
        x_center, y_center, width, height = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
        
        x1 = (x_center - width / 2) * scale_x
        y1 = (y_center - height / 2) * scale_y
        x2 = (x_center + width / 2) * scale_x
        y2 = (y_center + height / 2) * scale_y
        
        # è¾¹ç•Œæ£€æŸ¥
        x1 = np.clip(x1, 0, orig_w)
        y1 = np.clip(y1, 0, orig_h)
        x2 = np.clip(x2, 0, orig_w)
        y2 = np.clip(y2, 0, orig_h)
        
        # 6. ç»„è£…æ¡†
        boxes_array = np.column_stack([x1, y1, x2, y2])
        
        # 7. å¿«é€ŸNMS - ä½¿ç”¨OpenCV (2-5ms)
        indices = self._fast_nms_opencv(boxes_array, scores)
        
        # 8. æœ€ç»ˆç»“æœ
        result = np.column_stack([
            boxes_array[indices, 0], boxes_array[indices, 1],
            boxes_array[indices, 2], boxes_array[indices, 3],
            scores[indices], class_ids[indices]
        ])
        # æ¯100å¸§è¾“å‡ºä¸€æ¬¡ï¼Œè€Œä¸æ˜¯æ¯å¸§
        if self.frame_count % 100 == 0:
            print(f"ğŸ”§ å‘é‡åŒ–åå¤„ç†è€—æ—¶: {(time.time()-start_time)*1000:.1f}ms")
        return result.astype(np.float32)

    def _fast_nms_opencv(self, boxes, scores, iou_threshold=0.45):
        """ä½¿ç”¨OpenCVçš„å¿«é€ŸNMS"""
        if len(boxes) == 0:
            return []
        
        # è½¬æ¢ä¸º(x, y, w, h)æ ¼å¼
        boxes_wh = boxes.copy()
        boxes_wh[:, 2] = boxes[:, 2] - boxes[:, 0]  # w
        boxes_wh[:, 3] = boxes[:, 3] - boxes[:, 1]  # h
        
        # ä½¿ç”¨OpenCVçš„NMS (C++å®ç°ï¼Œå¾ˆå¿«)
        indices = cv2.dnn.NMSBoxes(
            boxes_wh.tolist(), 
            scores.tolist(), 
            self.conf_threshold, 
            iou_threshold
        )
        
        return indices.flatten() if len(indices) > 0 else []

    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.inference_times:
            return {"avg_inference_time": 0, "avg_fps": 0, "total_frames": 0}
            
        avg_time = sum(self.inference_times) / len(self.inference_times)
        avg_fps = 1.0 / avg_time if avg_time > 0 else 0
        
        return {
            'avg_inference_time': avg_time,
            'avg_fps': avg_fps,
            'total_frames': self.frame_count
        }

    def cleanup(self):
        """æ¸…ç†èµ„æº - æ”¹å›autoinitæ–¹å¼"""
        if self._cleaned:
            return
        
        print("ğŸ§¹ å¼€å§‹æ¸…ç†TensorRTèµ„æºï¼ˆautoinitæ–¹å¼ï¼‰...")
        
        try:
            # 1. æ¸…ç†GPUå†…å­˜å’ŒCUDAæµ
            if hasattr(self, 'input_gpu') and self.input_gpu:
                try:
                    self.input_gpu.free()
                    self.input_gpu = None
                    print("âœ… input_gpu å·²é‡Šæ”¾")
                except Exception as e:
                    print(f"âš ï¸ é‡Šæ”¾input_gpuæ—¶å‡ºé”™: {e}")
            
            if hasattr(self, 'output_gpu') and self.output_gpu:
                try:
                    self.output_gpu.free()
                    self.output_gpu = None
                    print("âœ… output_gpu å·²é‡Šæ”¾")
                except Exception as e:
                    print(f"âš ï¸ é‡Šæ”¾output_gpuæ—¶å‡ºé”™: {e}")
            
            if hasattr(self, 'stream') and self.stream:
                try:
                    self.stream.synchronize()
                    # å¯¹äºautoinitæ–¹å¼ï¼Œæˆ‘ä»¬ä¸éœ€è¦é”€æ¯æµï¼Œä½†å¯ä»¥ç½®ä¸ºNone
                    self.stream = None
                    print("âœ… CUDAæµ å·²åŒæ­¥")
                except Exception as e:
                    print(f"âš ï¸ åŒæ­¥CUDAæµæ—¶å‡ºé”™: {e}")
            
            # 2. æ¸…ç†TensorRTèµ„æº
            if hasattr(self, 'context') and self.context:
                try:
                    del self.context
                    self.context = None
                    print("âœ… TensorRTä¸Šä¸‹æ–‡å·²æ¸…ç†")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†TensorRTä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {e}")
            
            if hasattr(self, 'engine') and self.engine:
                try:
                    del self.engine
                    self.engine = None
                    print("âœ… TensorRTå¼•æ“å·²æ¸…ç†")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†TensorRTå¼•æ“æ—¶å‡ºé”™: {e}")
            
            # 3. é‡è¦ï¼šå¯¹äºautoinitæ–¹å¼ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨å¼¹å‡ºCUDAä¸Šä¸‹æ–‡
            # autoinitä¼šè‡ªåŠ¨ç®¡ç†ä¸Šä¸‹æ–‡çš„ç”Ÿå‘½å‘¨æœŸ
            # ä½†æˆ‘ä»¬å¯ä»¥æ‰“å°ä¸€äº›è°ƒè¯•ä¿¡æ¯
            try:
                ctx = cuda.Context.get_current()
                print(f"ğŸ” æ¸…ç†åå½“å‰CUDAä¸Šä¸‹æ–‡: {ctx}")
            except:
                print("ğŸ” æ¸…ç†åæ— æ³•è·å–CUDAä¸Šä¸‹æ–‡ï¼ˆå¯èƒ½å·²è¢«é‡Šæ”¾ï¼‰")
            
            self._cleaned = True
            print("âœ… TensorRTèµ„æºå·²å®Œå…¨æ¸…ç†ï¼ˆautoinitæ–¹å¼ï¼‰")
            
        except Exception as e:
            print(f"âŒ TensorRTèµ„æºæ¸…ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self._cleaned = True

    def _inference_optimized(self, frame):
        """ä¼˜åŒ–ç‰ˆæ¨ç† - æ·»åŠ æ€§èƒ½ç›‘æ§"""
        import time
        
        # æ€§èƒ½è®¡æ—¶
        preprocess_time = 0
        inference_time = 0
        postprocess_time = 0
        
        # é¢„å¤„ç†
        preprocess_start = time.time()
        input_blob = self._preprocess(frame)
        preprocess_time = time.time() - preprocess_start
        
        # æ‰§è¡Œæ¨ç†
        inference_start = time.time()
        cuda.memcpy_htod_async(self.input_gpu, input_blob, self.stream)
        
        # ä½¿ç”¨æœ€å¿«çš„æ‰§è¡Œæ–¹æ³•
        try:
            self.context.execute_async_v3(stream_handle=self.stream.handle)
        except AttributeError:
            try:
                self.context.execute_async_v2(bindings=self.bindings, stream_handle=self.stream.handle)
            except AttributeError:
                self.context.execute_async(batch_size=1, bindings=self.bindings, stream_handle=self.stream.handle)
        
        # è·å–è¾“å‡º
        host_output = np.empty(self.output_shape, dtype=np.float32)
        cuda.memcpy_dtoh_async(host_output, self.output_gpu, self.stream)
        self.stream.synchronize()
        inference_time = time.time() - inference_start
        
        # åå¤„ç†
        postprocess_start = time.time()
        detections = self._postprocess(host_output, frame.shape)
        postprocess_time = time.time() - postprocess_start
        
        # æ€§èƒ½æ—¥å¿—ï¼ˆæ¯30å¸§è¾“å‡ºä¸€æ¬¡ï¼‰
        if self.frame_count % 30 == 0:
            print(f"â±ï¸ YOLOæ€§èƒ½ç»Ÿè®¡ (æœ€è¿‘30å¸§):")
            print(f"  é¢„å¤„ç†: {preprocess_time*1000:.1f}ms")
            print(f"  æ¨ç†: {inference_time*1000:.1f}ms") 
            print(f"  åå¤„ç†: {postprocess_time*1000:.1f}ms")
            print(f"  æ€»æ—¶é—´: {(preprocess_time+inference_time+postprocess_time)*1000:.1f}ms, "
                  f"FPS: {1/(preprocess_time+inference_time+postprocess_time):.1f}")
        
        return detections