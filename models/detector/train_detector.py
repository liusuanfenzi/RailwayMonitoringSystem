# models/jetson_train_detector_visual.py
import cv2
import numpy as np
from pathlib import Path
from typing import Dict
from datetime import datetime
from models.background_subtractor.gmm_model import GMMBackgroundSubtractor
from utils.state_manager import TrainStateManager
from utils.utils import PerformanceMonitor
from utils.output_manager import OutputManager


class TrainDetector:
    """Jetsonä¼˜åŒ–çš„åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å™¨ - å¯è§†åŒ–ç‰ˆæœ¬"""

    def __init__(self, **kwargs):
        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        self.state_manager = TrainStateManager(
            spatial_threshold=kwargs.get('spatial_threshold', 0.05),
            temporal_frames=kwargs.get('temporal_frames', 50),
            temporal_threshold=kwargs.get('temporal_threshold', 45)
        )

        self.performance_monitor = PerformanceMonitor()
        self.output_manager = OutputManager()
        self.event_history = []
        self.frame_count = 0

        # å¯è§†åŒ–é…ç½®
        self.original_window = "Original Frame with ROI"
        self.mask_window = "ROI Foreground Mask"
        self.show_visualization = True
        self.print_interval = kwargs.get('print_interval', 10)
        self.last_print_frame = 0

        print("âœ… Jetsonåˆ—è½¦æ£€æµ‹å™¨(å¯è§†åŒ–ç‰ˆæœ¬)åˆå§‹åŒ–æˆåŠŸ")

    def detect_events(self, bg_subtractor_results: dict, frame: np.ndarray, frame_index: int) -> dict:
        """ä¼˜åŒ–äº‹ä»¶æ£€æµ‹ï¼Œæ”¯æŒæˆªå›¾ä¿å­˜"""
        confidence = 0.0
        roi_name = None

        # æŸ¥æ‰¾ROIåŒºåŸŸç»“æœ
        for key in bg_subtractor_results.keys():
            if key != 'full_frame':
                roi_name = key
                confidence = bg_subtractor_results[key]['foreground_ratio']
                break

        # æ›´æ–°çŠ¶æ€
        state_result = self.state_manager.update_state(confidence, frame_index)

        events = {
            'confidence': confidence,
            'spatial_detected': state_result['spatial_detected'],
            'current_state': state_result['state'],
            'event_triggered': state_result['event_triggered'],
            'event_type': state_result.get('event_type', None),
            'roi_name': roi_name,
            'frame_index': frame_index
        }

        # è®°å½•é‡è¦äº‹ä»¶
        if state_result['event_triggered']:
            event_record = {
                'frame_index': frame_index,
                'event_type': state_result['event_type'],
                'confidence': confidence,
            }
            self.event_history.append(event_record)

            # ä¿å­˜äº‹ä»¶æˆªå›¾ - ä½¿ç”¨ROIå‰æ™¯æ©ç 
            self._save_event_snapshot(frame, events, bg_subtractor_results)

            print(f"ğŸš‚ æ£€æµ‹åˆ°åˆ—è½¦è¿›ç«™! å¸§: {frame_index}, ç½®ä¿¡åº¦: {confidence:.3f}")

        return events

    def _save_event_snapshot(self, frame: np.ndarray, events: dict, bg_results: dict):
        """ä¿å­˜äº‹ä»¶æˆªå›¾ - ä½¿ç”¨ROIå‰æ™¯æ©ç """
        try:
            # è·å–ROIå‰æ™¯æ©ç 
            if 'roi_name' not in events or events['roi_name'] not in bg_results:
                return None

            roi_data = bg_results[events['roi_name']]
            roi_mask = roi_data['mask']

            # ç›´æ¥ä¿å­˜åŸå§‹æ©ç ï¼Œä¸æ·»åŠ æ ‡æ³¨
            success = self.output_manager.save_event_frame(
                frame=roi_mask,
                event_type=events['event_type'],
                confidence=events['confidence'],
                frame_index=events['frame_index'],
                subfolder="train_detection"
            )

            if not success:
                print(f"âš ï¸ ä¿å­˜æˆªå›¾å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›®å½•æƒé™")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜äº‹ä»¶æˆªå›¾å¤±è´¥: {e}")

    def _create_original_display(self, frame: np.ndarray, events: dict, bg_subtractor: GMMBackgroundSubtractor) -> np.ndarray:
        """åˆ›å»ºåŸå§‹å¸§æ˜¾ç¤ºï¼Œåªä¿ç•™ROIæ¡†ï¼Œç§»é™¤æ‰€æœ‰æ–‡å­—æ ‡æ³¨"""
        display_frame = frame.copy()

        # ç»˜åˆ¶ROIåŒºåŸŸ
        if hasattr(bg_subtractor, 'roi_manager') and bg_subtractor.roi_manager.rois:
            for roi_name, points in bg_subtractor.roi_manager.rois.items():
                # æ ¹æ®äº‹ä»¶è§¦å‘çŠ¶æ€é€‰æ‹©é¢œè‰²
                color = (0, 255, 0) if events['event_triggered'] else (0, 0, 255)
                cv2.rectangle(display_frame, points[0], points[1], color, 2)

        return display_frame

    def _create_mask_display(self, events: dict, bg_results: dict) -> np.ndarray:
        """åˆ›å»ºROIå‰æ™¯æ©ç æ˜¾ç¤ºï¼Œç§»é™¤æ‰€æœ‰æ–‡å­—æ ‡æ³¨"""
        if 'roi_name' not in events or events['roi_name'] not in bg_results:
            # å¦‚æœæ²¡æœ‰æ©ç ï¼Œè¿”å›é»‘è‰²å›¾åƒ
            return np.zeros((480, 640, 3), dtype=np.uint8)

        roi_data = bg_results[events['roi_name']]
        roi_mask = roi_data['mask']

        # å°†äºŒå€¼æ©ç è½¬æ¢ä¸ºå½©è‰²å›¾åƒ
        if len(roi_mask.shape) == 2:
            mask_display = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR)
        else:
            mask_display = roi_mask.copy()

        return mask_display

    def _print_confidence_info(self, confidence: float, frame_index: int, events: dict):
        """æ‰“å°ç½®ä¿¡åº¦ä¿¡æ¯åˆ°æ§åˆ¶å°"""
        if (frame_index - self.last_print_frame >= self.print_interval or
            events['event_triggered'] or
                confidence > 0.1):

            status_info = f"frame {frame_index}: confidence={confidence:.3f}"

            if events['spatial_detected']:
                status_info += " [detecting]"
            if events['event_triggered']:
                status_info += " [event triggered!]"

            print(status_info)
            self.last_print_frame = frame_index

    def process_video_with_visualization(self, video_path: str,
                                         bg_subtractor: GMMBackgroundSubtractor,
                                         max_frames: int = 1000) -> Dict:
        """
        Jetsonä¼˜åŒ–çš„è§†é¢‘å¤„ç† - å¯è§†åŒ–ç‰ˆæœ¬ï¼ˆæ— æ–‡å­—æ ‡æ³¨ï¼‰
        """
        if not Path(video_path).exists():
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        self.frame_count = 0
        print(f"ğŸ¬ å¼€å§‹Jetsonåˆ—è½¦æ£€æµ‹(å¯è§†åŒ–ç‰ˆæœ¬): {video_path}")

        # åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹çª—å£
        if self.show_visualization:
            try:
                cv2.namedWindow(self.original_window, cv2.WINDOW_NORMAL)
                cv2.namedWindow(self.mask_window, cv2.WINDOW_NORMAL)
                
                # è®¾ç½®çª—å£ä½ç½®ï¼ˆé¿å…é‡å ï¼‰
                cv2.moveWindow(self.original_window, 100, 100)
                cv2.moveWindow(self.mask_window, 800, 100)
                
                print("âœ… åŒçª—å£å¯è§†åŒ–å·²åˆ›å»ºï¼ˆæ— æ–‡å­—æ ‡æ³¨ï¼‰")
            except Exception as e:
                print(f"âš ï¸ åˆ›å»ºå¯è§†åŒ–çª—å£å¤±è´¥: {e}")
                self.show_visualization = False

        # ç®€åŒ–çš„èƒŒæ™¯æ¨¡å‹é¢„çƒ­
        print("ğŸ”¥ é¢„çƒ­èƒŒæ™¯æ¨¡å‹...")
        warmup_frames = 15
        for i in range(warmup_frames):
            ret, frame = cap.read()
            if not ret:
                break
            bg_subtractor.apply(frame, learning_rate=0.1)

        print(f"âœ… èƒŒæ™¯æ¨¡å‹é¢„çƒ­å®Œæˆ")

        # é‡ç½®å¸§è®¡æ•°
        self.frame_count = 0
        self.last_print_frame = 0

        while True:
            ret, frame = cap.read()
            if not ret or self.frame_count >= max_frames:
                break

            # åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†æ
            start_time = self.performance_monitor.start_timing()
            bg_results = bg_subtractor.apply_with_roi_analysis(frame)
            self.performance_monitor.end_timing(start_time, "èƒŒæ™¯åˆ†æ")

            # æ£€æµ‹åˆ—è½¦äº‹ä»¶
            events = self.detect_events(bg_results, frame, self.frame_count)

            # æ‰“å°ç½®ä¿¡åº¦ä¿¡æ¯åˆ°æ§åˆ¶å°
            self._print_confidence_info(
                events['confidence'], self.frame_count, events)

            # æ˜¾ç¤ºåŒçª—å£å¯è§†åŒ–ï¼ˆæ— æ–‡å­—æ ‡æ³¨ï¼‰
            if self.show_visualization:
                try:
                    # åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹çš„æ˜¾ç¤ºå›¾åƒï¼ˆæ— æ–‡å­—æ ‡æ³¨ï¼‰
                    original_display = self._create_original_display(
                        frame, events, bg_subtractor)
                    mask_display = self._create_mask_display(events, bg_results)

                    # åˆ†åˆ«æ˜¾ç¤ºåœ¨ä¸¤ä¸ªçª—å£ä¸­
                    cv2.imshow(self.original_window, original_display)
                    cv2.imshow(self.mask_window, mask_display)

                    # å¤„ç†é”®ç›˜è¾“å…¥
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("â¹ï¸ ç”¨æˆ·è¯·æ±‚é€€å‡º")
                        break
                    elif key == ord('s'):
                        # æ‰‹åŠ¨ä¿å­˜æˆªå›¾
                        self._save_event_snapshot(frame, events, bg_results)
                        print("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜æˆªå›¾")

                except Exception as e:
                    print(f"âš ï¸ å¯è§†åŒ–æ˜¾ç¤ºå¤±è´¥: {e}")
                    self.show_visualization = False

            self.frame_count += 1

            # å‡å°‘çŠ¶æ€æ‰“å°é¢‘ç‡
            if self.frame_count % 100 == 0 or events['event_triggered']:
                status = self.state_manager.get_status()
                perf_stats = self.performance_monitor.get_performance_stats()
                print(f"ğŸ“ˆ å¸§: {self.frame_count}, çŠ¶æ€: {status['current_state']}, "
                      f"è¿›ç«™: {status['entry_count']}, FPS: {perf_stats['fps']:.1f}")

        cap.release()

        # å…³é—­æ˜¾ç¤ºçª—å£
        if self.show_visualization:
            try:
                cv2.destroyAllWindows()
            except:
                pass

        # è·å–æœ€ç»ˆçŠ¶æ€
        final_status = self.state_manager.get_status()
        perf_stats = self.performance_monitor.get_performance_stats()

        stats = {
            'total_frames': self.frame_count,
            'entry_events': final_status['entry_count'],
            'final_state': final_status['current_state'],
            'avg_fps': perf_stats['fps'],
            'event_history': self.event_history,
            'saved_snapshots': len(self.event_history)
        }

        print(f"âœ… Jetsonåˆ—è½¦æ£€æµ‹å®Œæˆ")
        print(f"ğŸ“Š å…±å¤„ç† {self.frame_count} å¸§, å¹³å‡FPS: {perf_stats['fps']:.1f}")
        print(f"ğŸš‚ è¿›ç«™äº‹ä»¶: {final_status['entry_count']} æ¬¡")
        print(f"ğŸ’¾ ä¿å­˜ROIæ©ç æˆªå›¾: {len(self.event_history)} å¼ ")

        # æ˜¾ç¤ºæˆªå›¾ä¿å­˜ä½ç½®
        output_path = self.output_manager.base_output_dir / "train_detection"
        print(f"ğŸ“ ROIæ©ç æˆªå›¾ä½ç½®: {output_path.absolute()}")

        return stats

    def get_detection_status(self) -> dict:
        """è·å–æ£€æµ‹çŠ¶æ€"""
        status = self.state_manager.get_status()
        perf_stats = self.performance_monitor.get_performance_stats()
        status.update(perf_stats)
        status['total_frames'] = self.frame_count
        status['saved_snapshots'] = len(self.event_history)
        return status

    def reset_detector(self):
        """é‡ç½®æ£€æµ‹å™¨"""
        self.state_manager.reset()
        self.event_history.clear()
        self.frame_count = 0
        self.last_print_frame = 0
        print("ğŸ”„ åˆ—è½¦æ£€æµ‹å™¨å·²é‡ç½®")
