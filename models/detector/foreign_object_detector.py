# foreign_object_detector.py
import cv2
import numpy as np
from typing import List, Tuple, Dict, Any, Optional
import os
import time


class MotionDetector:
    """
    åŸºäºå›ºå®šèƒŒæ™¯æ¨¡å‹çš„è¿åŠ¨æ£€æµ‹å™¨ - ç®€åŒ–ç‰ˆæœ¬
    """

    def __init__(self, roi_coords,
                 motion_threshold=1000,
                 background_frames=10,
                 difference_threshold=25):
        """
        åˆå§‹åŒ–è¿åŠ¨æ£€æµ‹å™¨

        Args:
            roi_coords: ROIåŒºåŸŸåˆ—è¡¨ [(x, y, w, h), ...]
            motion_threshold: è¿åŠ¨åƒç´ é˜ˆå€¼
            background_frames: èƒŒæ™¯æ¨¡å‹å¸§æ•°
            difference_threshold: å·®åˆ†é˜ˆå€¼
        """
        self.roi_coords = roi_coords
        self.motion_threshold = motion_threshold
        self.background_frames = background_frames
        self.difference_threshold = difference_threshold

        # å†…éƒ¨å˜é‡
        self.cap = None
        self.background_model = None
        self.frame_count = 0
        self.background_initialized = False

    def build_background_from_buffer(self, frame_buffer, stop_event):
        """
        ä»å¸§ç¼“å†²åŒºæ„å»ºèƒŒæ™¯æ¨¡å‹
        
        Args:
            frame_buffer: å¸§ç¼“å†²åŒºå®ä¾‹
            stop_event: åœæ­¢äº‹ä»¶
        """
        print(f"ğŸ“Š æ­£åœ¨ä»è§†é¢‘å‰ {self.background_frames} å¸§æ„å»ºèƒŒæ™¯æ¨¡å‹...")
        
        frames_for_bg = []
        bg_frame_count = 0
        
        # ç­‰å¾…è¶³å¤Ÿå¤šçš„å¸§
        max_wait_time = 30  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        start_time = time.time()
        
        while bg_frame_count < self.background_frames:
            if time.time() - start_time > max_wait_time:
                print(f"âš ï¸ ç­‰å¾…è¶…æ—¶ï¼Œåªè¯»å–äº† {bg_frame_count} å¸§ç”¨äºèƒŒæ™¯å»ºæ¨¡")
                break
            
            if stop_event and stop_event.is_set():
                print("â¹ï¸ æ„å»ºèƒŒæ™¯æ¨¡å‹è¢«ä¸­æ–­")
                return False
            
            # ä»ç¼“å†²åŒºè·å–å¸§ - ç›´æ¥å¤„ç† numpy æ•°ç»„
            frame = frame_buffer.get_latest_frame()
            
            # æ£€æŸ¥å¸§æ˜¯å¦æœ‰æ•ˆ
            if frame is not None:
                # ç¡®ä¿æ˜¯ numpy æ•°ç»„
                if isinstance(frame, np.ndarray) and frame.size > 0:
                    try:
                        # è½¬æ¢ä¸ºç°åº¦å›¾
                        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                        frames_for_bg.append(gray_frame)
                        bg_frame_count += 1
                        
                        if bg_frame_count % 5 == 0:
                            print(f"  è¯»å–ç¬¬ {bg_frame_count}/{self.background_frames} å¸§...")
                    except Exception as e:
                        print(f"âš ï¸ è½¬æ¢ç°åº¦å›¾å¤±è´¥: {e}")
                        # ç»§ç»­å°è¯•ï¼Œä¸ä¸­æ–­
                else:
                    print("âš ï¸ è·å–åˆ°æ— æ•ˆçš„å¸§")
            
            time.sleep(0.05)  # çŸ­æš‚ç­‰å¾…
        
        if not frames_for_bg:
            print("âŒ æ— æ³•è¯»å–ä»»ä½•å¸§ç”¨äºèƒŒæ™¯å»ºæ¨¡")
            return False
        
        # è®¡ç®—å¹³å‡èƒŒæ™¯
        print("ğŸ“ˆ è®¡ç®—å¹³å‡èƒŒæ™¯æ¨¡å‹...")
        self.background_model = np.mean(
            np.array(frames_for_bg, dtype=np.float32), axis=0).astype(np.uint8)
        
        # å¯é€‰ï¼šå¯¹èƒŒæ™¯è¿›è¡Œæ¨¡ç³Šå¤„ç†ï¼Œå‡å°‘å™ªå£°
        self.background_model = cv2.GaussianBlur(
            self.background_model, (5, 5), 0)
        
        self.background_initialized = True
        print(f"âœ… èƒŒæ™¯æ¨¡å‹æ„å»ºå®Œæˆï¼Œä½¿ç”¨ {len(frames_for_bg)} å¸§")
        return True
    
    def _create_roi_mask(self, width, height):
        """åˆ›å»ºROIæ©ç """
        roi_mask = np.zeros((height, width), dtype=np.uint8)
        for (x, y, w, h) in self.roi_coords:
            cv2.rectangle(roi_mask, (x, y), (x + w, y + h), 255, -1)
        return roi_mask

    def process_frame(self, frame):
        """å¤„ç†å•å¸§å¹¶è¿”å›å¤šä¸ªç»“æœ"""
        if frame is None or not self.background_initialized:
            return None, None, None, None

        # è½¬æ¢ä¸ºç°åº¦
        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 1. èƒŒæ™¯å·®åˆ†
        diff = cv2.absdiff(gray_frame, self.background_model)

        # 2. äºŒå€¼åŒ–
        _, fgmask = cv2.threshold(
            diff, self.difference_threshold, 255, cv2.THRESH_BINARY)

        # 3. åˆ›å»ºROIæ©ç 
        roi_mask = self._create_roi_mask(frame.shape[1], frame.shape[0])

        # 4. åº”ç”¨ROI
        roi_fgmask = cv2.bitwise_and(fgmask, roi_mask)

        # 5. å½¢æ€å­¦å¤„ç†
        kernel = np.ones((5, 5), np.uint8)
        roi_fgmask = cv2.morphologyEx(roi_fgmask, cv2.MORPH_CLOSE, kernel)
        roi_fgmask = cv2.morphologyEx(roi_fgmask, cv2.MORPH_OPEN, kernel)

        # 6. ç»Ÿè®¡è¿åŠ¨åƒç´ 
        motion_pixels = np.sum(roi_fgmask > 0)
        has_motion = motion_pixels > self.motion_threshold

        # 7. åˆ›å»ºå½©è‰²æ©ç å¸§
        colored_mask = cv2.cvtColor(roi_fgmask, cv2.COLOR_GRAY2BGR)

        # 8. åˆ›å»ºå¸¦æœ‰ROIæ¡†çš„åŸå§‹å¸§
        frame_with_roi = frame.copy()
        for (x, y, w, h) in self.roi_coords:
            # ç”¨ç»¿è‰²çŸ©å½¢æ¡†å‡ºROIåŒºåŸŸ
            cv2.rectangle(frame_with_roi, (x, y),
                          (x + w, y + h), (0, 255, 0), 2)

        # 9. è£å‰ªROIåŒºåŸŸçš„å‰æ™¯æ©ç 
        cropped_masks = []
        for (x, y, w, h) in self.roi_coords:
            cropped_mask = roi_fgmask[y:y+h, x:x+w]
            cropped_masks.append(cropped_mask)

        self.frame_count += 1

        return frame_with_roi, colored_mask, cropped_masks, has_motion


class ForeignObjectDetector:
    def __init__(self, roi_coords, min_static_duration=2.0, threshold=200, min_area=100,
                 alert_dir="alerts/foreign_object_detection"):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            roi_coords: ROIåæ ‡åˆ—è¡¨ [(x, y, w, h), ...]
            min_static_duration: æœ€å°é™æ­¢æ—¶é—´(ç§’)
            threshold: ç™½è‰²é˜ˆå€¼(0-255ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼)
            min_area: æœ€å°åŒºåŸŸé¢ç§¯(åƒç´ )
            alert_dir: è­¦æŠ¥æˆªå›¾ä¿å­˜ç›®å½•
        """
        self.min_static_duration = min_static_duration
        self.threshold = threshold
        self.min_area = min_area
        self.fps = 30
        self.roi_coords = roi_coords
        self.alert_dir = alert_dir
        
        # çŠ¶æ€ç®¡ç†
        self.static_candidates = {}  # å€™é€‰é™æ­¢åŒºåŸŸ
        self.alerted_regions = set()  # å·²æŠ¥è­¦åŒºåŸŸID
        self.frame_count = 0
        self.last_alert_time = {}  # æ¯ä¸ªåŒºåŸŸä¸Šæ¬¡æŠ¥è­¦æ—¶é—´
        
        # è¿åŠ¨æ£€æµ‹å™¨
        self.motion_detector = None
        
        # åˆ›å»ºè­¦æŠ¥ç›®å½•
        os.makedirs(self.alert_dir, exist_ok=True)
        print(f"ğŸ“ å¼‚ç‰©æ£€æµ‹è­¦æŠ¥ç›®å½•: {os.path.abspath(self.alert_dir)}")

    def initialize(self, motion_detector: MotionDetector):
        """åˆå§‹åŒ–è¿åŠ¨æ£€æµ‹å™¨"""
        self.motion_detector = motion_detector
        return True

    def extract_white_regions(self, frame: np.ndarray) -> List[np.ndarray]:
        """ä»å¸§ä¸­æå–ç™½è‰²åŒºåŸŸçš„äºŒå€¼æ©ç """
        if frame is None:
            return []
            
        # è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame.copy()

        # åˆ›å»ºç™½è‰²åŒºåŸŸæ©ç 
        _, white_mask = cv2.threshold(
            gray, self.threshold, 255, cv2.THRESH_BINARY)

        # å½¢æ€å­¦æ“ä½œå»é™¤å™ªå£°
        kernel = np.ones((3, 3), np.uint8)
        white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_OPEN, kernel)
        white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, kernel)

        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(
            white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # è¿‡æ»¤å°åŒºåŸŸ
        large_contours = [
            cnt for cnt in contours if cv2.contourArea(cnt) > self.min_area]

        return large_contours

    def process_frame(self, frame: np.ndarray) -> Dict[str, Any]:
        """
        å¤„ç†å•å¸§å›¾åƒ
        
        Args:
            frame: è¾“å…¥å¸§
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        if frame is None or self.motion_detector is None:
            return {}
        
        # å¤„ç†å½“å‰å¸§
        frame_with_roi, colored_mask, cropped_masks, has_motion = self.motion_detector.process_frame(frame)
        
        if frame_with_roi is None:
            return {}
        
        self.frame_count += 1
        contours = self.extract_white_regions(colored_mask)
        
        # æ›´æ–°å€™é€‰åŒºåŸŸ
        self._update_static_candidates(contours, self.frame_count)
        
        # æ£€æŸ¥é™æ­¢åŒºåŸŸå¹¶è§¦å‘è­¦æŠ¥
        alert_info = self._check_and_trigger_alerts(frame_with_roi, self.frame_count)
        
        # åœ¨å¸§ä¸Šç»˜åˆ¶ç»“æœ
        result_frame = self._visualize_results(frame_with_roi, contours, cropped_masks)
        
        return {
            'frame': result_frame,
            'alert_info': alert_info,
            'contours': len(contours),
            'static_count': len([r for r in self.static_candidates.values() 
                               if r['duration'] >= self.min_static_duration * 25]),
            'alert_count': len(self.alerted_regions),
            'frame_count': self.frame_count,
            'has_motion': has_motion
        }

    def _update_static_candidates(self, contours, frame_count):
        """æ›´æ–°å€™é€‰é™æ­¢åŒºåŸŸ"""
        for i, contour in enumerate(contours):
            # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†å’Œé¢ç§¯
            x, y, w, h = cv2.boundingRect(contour)
            area = cv2.contourArea(contour)

            # æŸ¥æ‰¾åŒ¹é…çš„ç°æœ‰åŒºåŸŸ
            matched_region_id = None
            for region_id, data in self.static_candidates.items():
                if self._is_region_stable(data['contour'], contour, x, y, w, h):
                    matched_region_id = region_id
                    break

            if matched_region_id is not None:
                # æ›´æ–°ç°æœ‰åŒºåŸŸ
                self.static_candidates[matched_region_id]['last_frame'] = frame_count
                self.static_candidates[matched_region_id]['duration'] += 1
                self.static_candidates[matched_region_id]['bbox'] = (x, y, w, h)
                self.static_candidates[matched_region_id]['contour'] = contour
            else:
                # åˆ›å»ºæ–°åŒºåŸŸ
                region_id = len(self.static_candidates)
                self.static_candidates[region_id] = {
                    'first_frame': frame_count,
                    'last_frame': frame_count,
                    'duration': 0,
                    'bbox': (x, y, w, h),
                    'contour': contour
                }

    def _check_and_trigger_alerts(self, frame_with_roi, frame_count):
        """æ£€æŸ¥å¹¶è§¦å‘è­¦æŠ¥"""
        alert_info = None
        current_time = time.time()
        
        for region_id, data in self.static_candidates.items():
            if data['duration'] >= self.min_static_duration * 25:
                if data['last_frame'] == frame_count:
                    # è®¡ç®—æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
                    duration_seconds = (frame_count - data['first_frame']) / self.fps
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ¥è­¦ï¼ˆé˜²é‡å¤ï¼‰
                    should_alert = False
                    if region_id not in self.alerted_regions:
                        should_alert = True
                    else:
                        # å¦‚æœå·²ç»æŠ¥è­¦è¿‡ï¼Œæ£€æŸ¥æ˜¯å¦è¶…è¿‡ä¸€å®šæ—¶é—´
                        last_time = self.last_alert_time.get(region_id, 0)
                        if current_time - last_time > 300:  # 5åˆ†é’Ÿåå†æŠ¥è­¦
                            should_alert = True
                    
                    if should_alert:
                        alert_info = self._trigger_alert(region_id, duration_seconds, data['bbox'], frame_with_roi)
                        self.alerted_regions.add(region_id)
                        self.last_alert_time[region_id] = current_time
        
        return alert_info

    def _trigger_alert(self, region_id: int, duration: float, bbox: Tuple, frame_with_roi: np.ndarray):
        """è§¦å‘è­¦æŠ¥å¹¶ä¿å­˜æˆªå›¾"""
        x, y, w, h = bbox
        
        # ä¿å­˜åŸå§‹çª—å£å½“å‰å¸§çš„æˆªå›¾
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        save_path = os.path.join(
            self.alert_dir, 
            f"foreign_object_region_{region_id}_{timestamp}.jpg"
        )
        cv2.imwrite(save_path, frame_with_roi)
        
        alert_info = {
            'region_id': region_id,
            'duration': duration,
            'save_path': save_path,
            'timestamp': timestamp,
            'type': 'foreign_object'
        }
        
        print(f"ğŸš¨ å¼‚ç‰©è­¦æŠ¥ï¼åŒºåŸŸ {region_id} é™æ­¢ {duration:.2f} ç§’")
        print(f"ğŸ’¾ è­¦æŠ¥æˆªå›¾å·²ä¿å­˜: {save_path}")
        
        return alert_info

    def _visualize_results(self, frame_with_roi, contours, cropped_masks):
        """å¯è§†åŒ–å¤„ç†ç»“æœ"""
        # ç»˜åˆ¶æ»¡è¶³é™æ­¢æ¡ä»¶çš„åŒºåŸŸ
        for region_id, data in self.static_candidates.items():
            if data['duration'] >= self.min_static_duration * 25:
                x, y, w, h = data['bbox']
                
                # ç»˜åˆ¶æ©™è‰²æ¡†è¡¨ç¤ºæ»¡è¶³æ¡ä»¶çš„åŒºåŸŸ
                cv2.rectangle(frame_with_roi, (x, y),
                              (x + w, y + h), (0, 165, 255), 3)
                
                # æ˜¾ç¤ºåœç•™æ—¶é—´
                duration_seconds = (self.frame_count - data['first_frame']) / self.fps
                text = f"{duration_seconds:.2f}s"
                cv2.putText(
                    img=frame_with_roi,
                    text=text,
                    org=(x, y - 10),
                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                    fontScale=0.5,
                    color=(0, 165, 255),
                    thickness=2,
                    lineType=cv2.LINE_AA
                )
        
        # æ·»åŠ å¸§è®¡æ•°ä¿¡æ¯
        cv2.putText(frame_with_roi, f'Frame: {self.frame_count}', (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame_with_roi, f'Detected: {len(contours)}', (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        static_count = len([r for r in self.static_candidates.values() 
                          if r['duration'] >= self.min_static_duration * 25])
        cv2.putText(frame_with_roi, f'Static: {static_count}',
                    (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)
        
        cv2.putText(frame_with_roi, f'Alerts: {len(self.alerted_regions)}', (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        return frame_with_roi

    def _is_region_stable(self, old_contour, new_contour, x, y, w, h, tolerance=0.1):
        """æ£€æŸ¥åŒºåŸŸæ˜¯å¦ç¨³å®šåœ¨åŒä¸€ä½ç½®"""
        if old_contour is None or new_contour is None:
            return False
            
        prev_x, prev_y, prev_w, prev_h = cv2.boundingRect(old_contour)

        # æ£€æŸ¥ä½ç½®å˜åŒ–
        center_x = x + w // 2
        center_y = y + h // 2
        prev_center_x = prev_x + prev_w // 2
        prev_center_y = prev_y + prev_h // 2

        dx = abs(center_x - prev_center_x)
        dy = abs(center_y - prev_center_y)
        if dx > max(w, prev_w) * tolerance or dy > max(h, prev_h) * tolerance:
            return False

        # æ£€æŸ¥å°ºå¯¸å˜åŒ–
        current_area = cv2.contourArea(old_contour)
        prev_area = cv2.contourArea(new_contour)
        if prev_area > 0:
            area_change = abs(current_area - prev_area) / prev_area
            if area_change > 0.2:  # å…è®¸20%çš„é¢ç§¯å˜åŒ–
                return False

        return True

    def reset(self):
        """é‡ç½®æ£€æµ‹å™¨çŠ¶æ€"""
        self.static_candidates = {}
        self.alerted_regions.clear()
        self.frame_count = 0
        self.last_alert_time.clear()

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.reset()