# """
# ç®€åŒ–çš„åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å™¨ - åŸºäºå•ä¸ªROIåŒºåŸŸ
# """
from typing import Dict
import cv2
import numpy as np
from pathlib import Path
from models.background_subtractors.gmm_model import GMMBackgroundSubtractor
from utils.state_manager import TrainStateManager

class TrainStationDetector:
    """ç®€åŒ–çš„åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å™¨ - åŸºäºå•ä¸ªROIåŒºåŸŸ"""

    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–åˆ—è½¦æ£€æµ‹å™¨

        Args:
            **kwargs: çŠ¶æ€æœºå‚æ•°
        """
        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        self.state_manager = TrainStateManager(
            spatial_threshold=kwargs.get('spatial_threshold', 0.05),
            temporal_frames=kwargs.get('temporal_frames', 100),
            temporal_threshold=kwargs.get('temporal_threshold', 90)
        )

        self.event_history = []  # äº‹ä»¶å†å²è®°å½•

        print("âœ… ç®€åŒ–åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")

    def detect_events(self, bg_subtractor_results: dict, frame_index: int) -> dict:
        """
        åŸºäºèƒŒæ™¯å‡é™¤ç»“æœæ£€æµ‹åˆ—è½¦äº‹ä»¶

        Args:
            bg_subtractor_results: GMMBackgroundSubtractor.apply_with_roi_analysisè¿”å›çš„ç»“æœ
            frame_index: å½“å‰å¸§ç´¢å¼•

        Returns:
            äº‹ä»¶æ£€æµ‹ç»“æœå’ŒçŠ¶æ€ä¿¡æ¯
        """
        # è·å–ROIåŒºåŸŸçš„ç½®ä¿¡åº¦
        confidence = 0.0
        roi_name = None

        # æŸ¥æ‰¾ROIåŒºåŸŸç»“æœ
        for key in bg_subtractor_results.keys():
            if key != 'full_frame':
                roi_name = key
                confidence = bg_subtractor_results[key]['foreground_ratio']
                break

        # æ›´æ–°çŠ¶æ€
        state_result = self.state_manager.update_state(confidence, frame_index)

        # æ„å»ºå®Œæ•´ç»“æœ
        events = {
            'confidence': confidence,
            'spatial_detected': state_result['spatial_detected'],
            'current_state': state_result['state'],
            'event_triggered': state_result['event_triggered'],
            'event_type': state_result.get('event_type', None),
            'buffer_size': state_result['buffer_size'],
            'roi_name': roi_name
        }

        # è®°å½•é‡è¦äº‹ä»¶
        if state_result['event_triggered']:
            event_record = {
                'frame_index': frame_index,
                'event_type': state_result['event_type'],
                'confidence': confidence,
                'true_count': state_result.get('true_count', 0)
            }
            self.event_history.append(event_record)
            print(f"ğŸ“ è®°å½•äº‹ä»¶: {event_record}")

        return events

    def visualize_detection(self, frame: np.ndarray, result: dict, events: dict, bg_subtractor: GMMBackgroundSubtractor = None):
        """
        å¯è§†åŒ–æ˜¾ç¤ºæ£€æµ‹ç»“æœ

        Args:
            frame: åŸå§‹å¸§
            result: apply_with_roi_analysisè¿”å›çš„ç»“æœ
            events: äº‹ä»¶æ£€æµ‹ç»“æœ
            bg_subtractor: èƒŒæ™¯å‡é™¤å™¨å®ä¾‹
        """
        # è·å–å‰æ™¯æ©ç 
        fg_mask = result['full_frame']['mask']

        # åœ¨åŸå›¾ä¸Šç»˜åˆ¶ROIåŒºåŸŸ
        frame_with_rois = frame.copy()

        # ä½¿ç”¨èƒŒæ™¯å‡é™¤å™¨çš„ROIç®¡ç†å™¨ç»˜åˆ¶ROIåŒºåŸŸ
        if bg_subtractor and hasattr(bg_subtractor, 'roi_manager'):
            roi_manager = bg_subtractor.roi_manager
            for roi_name, points in roi_manager.rois.items():
                # ç»˜åˆ¶ç»¿è‰²çŸ©å½¢è¾¹æ¡†
                cv2.rectangle(frame_with_rois,
                            points[0], points[1], (0, 255, 0), 2)

                # æ·»åŠ ROIæ ‡ç­¾
                label = roi_name.replace('_', ' ').title()
                text_x = points[0][0]
                text_y = points[0][1] - 10

                if text_y < 20:
                    text_y = points[0][1] + 25

                cv2.putText(frame_with_rois, label,
                            (text_x, text_y),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # æ·»åŠ çŠ¶æ€ä¿¡æ¯
        y_offset = 30
        status_info = [
            f"State: {events['current_state'].name}",
            f"Confidence: {events['confidence']:.3f}",
            f"Spatial Detected: {events['spatial_detected']}",
            f"Buffer Size: {events['buffer_size']}"
        ]

        for text in status_info:
            cv2.putText(frame_with_rois, text, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 25

        # æ·»åŠ äº‹ä»¶çŠ¶æ€
        if events['event_triggered']:
            event_text = f"Event: {events['event_type']}"
            cv2.putText(frame_with_rois, event_text, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            y_offset += 30

        # æ ¹æ®çŠ¶æ€æ”¹å˜è¾¹æ¡†é¢œè‰²
        border_color = (
            0, 255, 0) if events['event_triggered'] else (0, 0, 255)

        # æ·»åŠ è¾¹æ¡†
        cv2.rectangle(frame_with_rois, (0, 0),
                    (frame_with_rois.shape[1]-1, frame_with_rois.shape[0]-1),
                    border_color, 3)

        # æ˜¾ç¤ºåŸå›¾çª—å£
        cv2.imshow('Simple Train Detection', frame_with_rois)

        # æ˜¾ç¤ºROIåŒºåŸŸçš„åå¤„ç†å‰æ™¯æ©ç 
        if events['roi_name'] and events['roi_name'] in result:
            roi_data = result[events['roi_name']]
            roi_mask = roi_data['mask']
            roi_ratio = roi_data['foreground_ratio']

            roi_display = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR)
            text = f"{events['roi_name']} (Post-processed): {roi_ratio:.3f}"
            cv2.putText(roi_display, text, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            cv2.imshow(f'ROI: {events["roi_name"]} (Post-processed)', roi_display)
        
        # æ–°å¢ï¼šæ˜¾ç¤ºæœªåšåå¤„ç†çš„ROIåŒºåŸŸå‰æ™¯æ©ç 
        if bg_subtractor and events['roi_name']:
            try:
                # è·å–æœªåå¤„ç†çš„æ©ç 
                # å…ˆè¿›è¡Œé¢„å¤„ç†
                preprocessed_frame = bg_subtractor._preprocess_frame(frame)
                # åº”ç”¨èƒŒæ™¯å‡é™¤ä½†ä¸è¿›è¡Œåå¤„ç†
                raw_fg_mask = bg_subtractor.back_sub.apply(preprocessed_frame, learningRate=0.005)
                
                # è£å‰ªROIåŒºåŸŸ
                roi_manager = bg_subtractor.roi_manager
                raw_roi_mask = roi_manager.crop_roi(raw_fg_mask, events['roi_name'])
                
                # è®¡ç®—æœªåå¤„ç†çš„ROIå‰æ™¯æ¯”ä¾‹
                raw_roi_size = raw_roi_mask.shape[0] * raw_roi_mask.shape[1]
                raw_roi_foreground_pixels = np.sum(raw_roi_mask > 0)
                raw_roi_foreground_ratio = raw_roi_foreground_pixels / raw_roi_size if raw_roi_size > 0 else 0
                
                # æ˜¾ç¤ºæœªåå¤„ç†çš„ROIæ©ç 
                raw_roi_display = cv2.cvtColor(raw_roi_mask, cv2.COLOR_GRAY2BGR)
                raw_text = f"{events['roi_name']} (Raw): {raw_roi_foreground_ratio:.3f}"
                cv2.putText(raw_roi_display, raw_text, (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                cv2.imshow(f'ROI: {events["roi_name"]} (Raw - No Post-processing)', raw_roi_display)
                
                # åœ¨æ§åˆ¶å°è¾“å‡ºä¸¤ç§æ©ç çš„å¯¹æ¯”ä¿¡æ¯
                if events['event_triggered']:
                    print(f"ğŸ” æ©ç å¯¹æ¯” - å¸§ {events.get('frame_index', 'N/A')}:")
                    print(f"   é¢„å¤„ç†+åå¤„ç†æ©ç å‰æ™¯æ¯”ä¾‹: {roi_ratio:.4f}")
                    print(f"   é¢„å¤„ç†æ©ç å‰æ™¯æ¯”ä¾‹: {raw_roi_foreground_ratio:.4f}")
                    print(f"   å·®å¼‚: {abs(roi_ratio - raw_roi_foreground_ratio):.4f}")
                    
            except Exception as e:
                print(f"âš ï¸ æ˜¾ç¤ºåŸå§‹ROIæ©ç å¤±è´¥: {e}")
    
    def process_video_with_detection(self, video_path: str, bg_subtractor: GMMBackgroundSubtractor,
                                     max_frames: int = 1000, show_visualization: bool = True) -> Dict:
        """
        ä½¿ç”¨æ£€æµ‹å™¨å¤„ç†è§†é¢‘
        """
        if not Path(video_path).exists():
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        frame_count = 0
        print(f"ğŸ¬ å¼€å§‹ç®€åŒ–åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹: {video_path}")
        
        # æ·»åŠ èƒŒæ™¯æ¨¡å‹é¢„çƒ­æœŸ
        print("ğŸ”¥ é¢„çƒ­èƒŒæ™¯æ¨¡å‹...")
        warmup_frames = 30
        for i in range(warmup_frames):
            ret, frame = cap.read()
            if not ret:
                break
            # ä½¿ç”¨è¾ƒé«˜çš„å­¦ä¹ ç‡å¿«é€Ÿå»ºç«‹èƒŒæ™¯æ¨¡å‹
            bg_subtractor.apply(frame, learning_rate=0.1)
            frame_count += 1
        
        print(f"âœ… èƒŒæ™¯æ¨¡å‹é¢„çƒ­å®Œæˆï¼Œå·²å¤„ç† {warmup_frames} å¸§")
        
        # é‡ç½®å¸§è®¡æ•°
        frame_count = 0

        while True:
            ret, frame = cap.read()
            if not ret or frame_count >= max_frames:
                break

            # åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†æ
            bg_results = bg_subtractor.apply_with_roi_analysis(frame)

            # æ£€æµ‹åˆ—è½¦äº‹ä»¶
            events = self.detect_events(bg_results, frame_count)

            # æ˜¾ç¤ºå¯è§†åŒ–
            if show_visualization:
                self.visualize_detection(frame, bg_results, events, bg_subtractor)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            frame_count += 1
            if frame_count % 50 == 0:
                status = self.state_manager.get_status()
                print(f"ğŸ“ˆ å¸§: {frame_count}, çŠ¶æ€: {status['current_state']}, "
                    f"è¿›ç«™: {status['entry_count']}, ç¼“å†²åŒº: {status['buffer_size']}")


        cap.release()
        if show_visualization:
            cv2.destroyAllWindows()

        # è·å–æœ€ç»ˆçŠ¶æ€
        final_status = self.state_manager.get_status()

        stats = {
            'total_frames': frame_count,
            'entry_events': final_status['entry_count'],
            'final_state': final_status['current_state'],
            'event_history': self.event_history
        }

        print(f"âœ… ç®€åŒ–åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å®Œæˆ")
        print(f"ğŸ“Š å…±å¤„ç† {frame_count} å¸§")
        print(f"ğŸš‚ è¿›ç«™äº‹ä»¶: {final_status['entry_count']} æ¬¡")

        return stats

    def get_detection_status(self) -> dict:
        """è·å–å½“å‰æ£€æµ‹çŠ¶æ€"""
        return self.state_manager.get_status()

    def reset_detector(self):
        """é‡ç½®æ£€æµ‹å™¨"""
        self.state_manager.reset()
        self.event_history.clear()
        print("ğŸ”„ åˆ—è½¦æ£€æµ‹å™¨å·²é‡ç½®")
