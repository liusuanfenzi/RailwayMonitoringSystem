# """
# åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹æ¨¡å— - åŸºäºçŠ¶æ€æœºçš„äº‹ä»¶æ£€æµ‹
# """
from typing import Dict, List
import cv2
import numpy as np
from pathlib import Path
from utils.state_manager_old import TrainState, TrainStateManager
from models.background_subtractors.gmm_model_old1 import GMMBackgroundSubtractor


class TrainStationDetector:
    """åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å™¨ - åŸºäºçŠ¶æ€æœºçš„äº‹ä»¶æ£€æµ‹"""

    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–åˆ—è½¦æ£€æµ‹å™¨

        Args:
            **kwargs: çŠ¶æ€æœºå‚æ•°
        """
        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        self.state_manager = TrainStateManager(
            min_stay_duration=kwargs.get('min_stay_duration', 5.0),
            cooldown_duration=kwargs.get('cooldown_duration', 3.0),
            entering_timeout=kwargs.get('entering_timeout', 10.0),
            exiting_timeout=kwargs.get('exiting_timeout', 10.0)
        )

        self.event_history = []  # äº‹ä»¶å†å²è®°å½•
        self.entry_threshold = kwargs.get('entry_threshold', 0.05)
        self.exit_threshold = kwargs.get('exit_threshold', 0.05)

        print("âœ… åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")

    def detect_events(self, bg_subtractor_results: dict, frame_timestamp: float = None) -> dict:
        """
        åŸºäºèƒŒæ™¯å‡é™¤ç»“æœæ£€æµ‹åˆ—è½¦äº‹ä»¶

        Args:
            bg_subtractor_results: GMMBackgroundSubtractor.apply_with_roi_analysisè¿”å›çš„ç»“æœ
            frame_timestamp: å½“å‰å¸§æ—¶é—´æˆ³

        Returns:
            äº‹ä»¶æ£€æµ‹ç»“æœå’ŒçŠ¶æ€ä¿¡æ¯
        """
        if frame_timestamp is None:
            import time
            frame_timestamp = time.time()

        # æ£€æµ‹å„ROIåŒºåŸŸçš„æ´»åŠ¨
        entry_detected = False
        exit_detected = False
        entry_confidence = 0.0
        exit_confidence = 0.0

        # è®¡ç®—å„åŒºåŸŸå‰æ™¯æ¯”ä¾‹
        if 'entry_region' in bg_subtractor_results:
            entry_ratio = bg_subtractor_results['entry_region']['foreground_ratio']
            entry_confidence = entry_ratio
            entry_detected = entry_ratio > self.entry_threshold

        if 'exit_region' in bg_subtractor_results:
            exit_ratio = bg_subtractor_results['exit_region']['foreground_ratio']
            exit_confidence = exit_ratio
            exit_detected = exit_ratio > self.exit_threshold

        # æ›´æ–°çŠ¶æ€
        state_result = self.state_manager.update_state(
            entry_detected, exit_detected, frame_timestamp
        )

        # æ„å»ºå®Œæ•´ç»“æœ
        events = {
            'entry_detected': entry_detected,
            'exit_detected': exit_detected,
            'entry_confidence': entry_confidence,
            'exit_confidence': exit_confidence,
            'current_state': state_result['state'],
            'state_changed': state_result['state_changed'],
            'event_triggered': state_result['event_triggered'],
            'event_type': state_result['event_type'],
            'in_cooldown': state_result['in_cooldown'],
            'state_duration': state_result['state_duration']
        }

        # è®°å½•é‡è¦äº‹ä»¶
        if state_result['event_triggered'] and state_result['event_type'] in ['train_entered', 'train_exited']:
            event_record = {
                'timestamp': frame_timestamp,
                'event_type': state_result['event_type'],
                'state': state_result['new_state'].name if state_result['new_state'] else events['current_state'].name,
                'entry_confidence': entry_confidence,
                'exit_confidence': exit_confidence
            }
            self.event_history.append(event_record)
            print(f"ğŸ“ è®°å½•äº‹ä»¶: {event_record}")

        return events
    
    def visualize_detection(self, frame: np.ndarray, result: dict, events: dict, bg_subtractor: GMMBackgroundSubtractor = None):
        """
        å¯è§†åŒ–æ˜¾ç¤ºæ£€æµ‹ç»“æœ - åŸºäºåŸæœ‰ç»“æ„ä¿®æ”¹
        
        Args:
            frame: åŸå§‹å¸§
            result: apply_with_roi_analysisè¿”å›çš„ç»“æœ
            events: äº‹ä»¶æ£€æµ‹ç»“æœ
            bg_subtractor: èƒŒæ™¯å‡é™¤å™¨å®ä¾‹ï¼ˆç”¨äºè·å–ROIä¿¡æ¯ï¼‰
        """
        # è·å–å‰æ™¯æ©ç 
        fg_mask = result['full_frame']['mask']

        # åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ‰€æœ‰ROIåŒºåŸŸ
        frame_with_rois = frame.copy()
        
        # ä½¿ç”¨èƒŒæ™¯å‡é™¤å™¨çš„ROIç®¡ç†å™¨ç»˜åˆ¶ROIåŒºåŸŸ
        if bg_subtractor and hasattr(bg_subtractor, 'roi_manager'):
            # ç›´æ¥ä½¿ç”¨ROIç®¡ç†å™¨ä¸­çš„ROIåæ ‡ç»˜åˆ¶ç»¿è‰²çŸ©å½¢
            roi_manager = bg_subtractor.roi_manager
            for roi_name, points in roi_manager.rois.items():
                # ç»˜åˆ¶ç»¿è‰²çŸ©å½¢è¾¹æ¡†
                cv2.rectangle(frame_with_rois, points[0], points[1], (0, 255, 0), 2)
                
                # æ·»åŠ ROIæ ‡ç­¾ - ä¿®å¤æ–‡å­—ä½ç½®é—®é¢˜
                label = roi_name.replace('_', ' ').title()
                
                # è®¡ç®—æ–‡å­—ä½ç½®ï¼Œç¡®ä¿åœ¨å›¾åƒå†…
                text_x = points[0][0]
                text_y = points[0][1] - 10
                
                # å¦‚æœROIåœ¨å›¾åƒé¡¶éƒ¨ï¼Œå°†æ–‡å­—æ”¾åœ¨çŸ©å½¢å†…éƒ¨
                if text_y < 20:
                    text_y = points[0][1] + 25
                
                cv2.putText(frame_with_rois, label, 
                          (text_x, text_y),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        else:
            # å¦‚æœæ²¡æœ‰æä¾›bg_subtractorï¼Œä½¿ç”¨é»˜è®¤ç»˜åˆ¶æ–¹æ³•
            frame_with_rois = self._draw_rois_default(frame_with_rois, result)

        # æ·»åŠ çŠ¶æ€ä¿¡æ¯
        y_offset = 30
        status_info = [
            f"State: {events['current_state'].name}",
            f"Duration: {events['state_duration']:.1f}s",
            f"Entry: {events['entry_confidence']:.3f}",
            f"Exit: {events['exit_confidence']:.3f}"
        ]
        
        for text in status_info:
            cv2.putText(frame_with_rois, text, (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 25
        
        # æ·»åŠ äº‹ä»¶çŠ¶æ€
        if events['event_triggered']:
            event_text = f"Event: {events['event_type']}"
            cv2.putText(frame_with_rois, event_text, (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            y_offset += 30
        
        if events['in_cooldown']:
            cool_text = "COOLDOWN"
            cv2.putText(frame_with_rois, cool_text, (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        # æ ¹æ®çŠ¶æ€æ”¹å˜è¾¹æ¡†é¢œè‰²
        border_color = {
            TrainState.NO_TRAIN: (0, 0, 255),      # çº¢è‰²
            TrainState.ENTERING: (0, 255, 255),    # é»„è‰²
            TrainState.IN_STATION: (0, 255, 0),    # ç»¿è‰²
            TrainState.EXITING: (0, 165, 255)      # æ©™è‰²
        }[events['current_state']]
        
        # æ·»åŠ è¾¹æ¡†
        cv2.rectangle(frame_with_rois, (0, 0), 
                     (frame_with_rois.shape[1]-1, frame_with_rois.shape[0]-1),
                     border_color, 3)
        
        # æ˜¾ç¤ºåŸå›¾çª—å£
        cv2.imshow('Train Detection - State Machine', frame_with_rois)
        
        # æ˜¾ç¤ºå„ROIåŒºåŸŸçš„å‰æ™¯æ©ç 
        for roi_name, roi_data in result.items():
            if roi_name not in ['full_frame']:
                roi_mask = roi_data['mask']
                roi_ratio = roi_data['foreground_ratio']
                
                roi_display = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR)
                text = f"{roi_name}: {roi_ratio:.3f}"
                cv2.putText(roi_display, text, (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                cv2.imshow(f'ROI: {roi_name}', roi_display)
    
    def _draw_rois_default(self, frame: np.ndarray, result: dict) -> np.ndarray:
        """
        é»˜è®¤ROIç»˜åˆ¶æ–¹æ³•ï¼ˆå½“æ²¡æœ‰æä¾›bg_subtractoræ—¶ä½¿ç”¨ï¼‰
        
        Args:
            frame: è¾“å…¥å¸§
            result: åˆ†æç»“æœ
            
        Returns:
            ç»˜åˆ¶äº†ROIçš„å¸§
        """
        frame_with_rois = frame.copy()
        
        # ç®€å•çš„ROIç»˜åˆ¶é€»è¾‘
        for roi_name in result.keys():
            if roi_name not in ['full_frame']:
                # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ é»˜è®¤çš„ROIç»˜åˆ¶é€»è¾‘
                # ç¤ºä¾‹ï¼šåœ¨å·¦ä¸Šè§’æ˜¾ç¤ºROIåç§°
                cv2.putText(frame_with_rois, roi_name, (50, 50),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return frame_with_rois

    def process_video_with_detection(self, video_path: str, bg_subtractor: GMMBackgroundSubtractor,
                                     max_frames: int = 100, show_visualization: bool = False) -> Dict:
        """
        ä½¿ç”¨æ£€æµ‹å™¨å¤„ç†è§†é¢‘

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            bg_subtractor: èƒŒæ™¯å‡é™¤å™¨å®ä¾‹
            max_frames: æœ€å¤§å¤„ç†å¸§æ•°
            show_visualization: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        import time

        if not Path(video_path).exists():
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))

        frame_count = 0
        start_time = time.time()

        print(f"ğŸ¬ å¼€å§‹åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹: {video_path}")
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}FPS")

        while True:
            ret, frame = cap.read()
            if not ret or frame_count >= max_frames:
                break

            current_time = time.time()
            frame_timestamp = start_time + \
                (frame_count / fps) if fps > 0 else current_time

            # åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†æ
            bg_results = bg_subtractor.apply_with_roi_analysis(frame)

            # æ£€æµ‹åˆ—è½¦äº‹ä»¶
            events = self.detect_events(bg_results, frame_timestamp)

            # æ˜¾ç¤ºå¯è§†åŒ– - ä¿®å¤ï¼šä¼ é€’bg_subtractorå‚æ•°
            if show_visualization:
                self.visualize_detection(frame, bg_results, events, bg_subtractor)  # æ·»åŠ bg_subtractorå‚æ•°
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            frame_count += 1
            if frame_count % 50 == 0:
                status = self.state_manager.get_status()
                print(f"ğŸ“ˆ å¸§: {frame_count}, çŠ¶æ€: {status['current_state']}, "
                      f"è¿›ç«™: {status['entry_count']}, å‡ºç«™: {status['exit_count']}")

        cap.release()
        if show_visualization:
            cv2.destroyAllWindows()

        # è·å–æœ€ç»ˆçŠ¶æ€
        final_status = self.state_manager.get_status()

        stats = {
            'total_frames': frame_count,
            'entry_events': final_status['entry_count'],
            'exit_events': final_status['exit_count'],
            'final_state': final_status['current_state'],
            'event_history': self.event_history,
            'processing_time': time.time() - start_time
        }

        print(f"âœ… åˆ—è½¦è¿›å‡ºç«™æ£€æµ‹å®Œæˆ")
        print(f"ğŸ“Š å…±å¤„ç† {frame_count} å¸§")
        print(f"ğŸš‚ è¿›ç«™äº‹ä»¶: {final_status['entry_count']} æ¬¡")
        print(f"ğŸš‚ å‡ºç«™äº‹ä»¶: {final_status['exit_count']} æ¬¡")
        print(f"ğŸ æœ€ç»ˆçŠ¶æ€: {final_status['current_state']}")

        return stats

    def get_detection_status(self) -> dict:
        """è·å–å½“å‰æ£€æµ‹çŠ¶æ€"""
        return self.state_manager.get_status()

    def reset_detector(self):
        """é‡ç½®æ£€æµ‹å™¨"""
        self.state_manager.reset()
        self.event_history.clear()
        print("ğŸ”„ åˆ—è½¦æ£€æµ‹å™¨å·²é‡ç½®")

    def set_detection_thresholds(self, entry_threshold: float, exit_threshold: float):
        """è®¾ç½®æ£€æµ‹é˜ˆå€¼"""
        self.entry_threshold = entry_threshold
        self.exit_threshold = exit_threshold
        print(f"âš™ï¸ è®¾ç½®æ£€æµ‹é˜ˆå€¼ - è¿›ç«™: {entry_threshold}, å‡ºç«™: {exit_threshold}")
