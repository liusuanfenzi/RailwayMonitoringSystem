# """
# ç®€åŒ–çš„GMMèƒŒæ™¯å‡é™¤æ¨¡å‹
# """
from pathlib import Path
from typing import Optional, Dict
import cv2
import numpy as np
from typing import Optional
from utils.video.video_utils import ROIManager
from utils.state_manager_old import TrainState, TrainStateManager


class GMMBackgroundSubtractor:
    """ç®€åŒ–çš„GMMèƒŒæ™¯å‡é™¤å™¨ - æ”¯æŒå¤šä¸ªROIåŒºåŸŸ"""

    def __init__(self, algorithm: str = 'MOG2', **kwargs):
        """
        åˆå§‹åŒ–èƒŒæ™¯å‡é™¤å™¨

        Args:
            algorithm: 'MOG2' æˆ– 'KNN'
            **kwargs: ç®—æ³•å‚æ•°
        """
        self.algorithm = algorithm.upper()

        # åˆå§‹åŒ–ROIç®¡ç†å™¨
        self.roi_manager = ROIManager()

        if self.algorithm == 'MOG2':
            # MOG2å‚æ•°
            self.history = kwargs.get('history', 500)
            self.var_threshold = kwargs.get('var_threshold', 16)
            self.detect_shadows = kwargs.get('detect_shadows', False)

            self.back_sub = cv2.createBackgroundSubtractorMOG2(
                history=self.history,
                varThreshold=self.var_threshold,
                detectShadows=self.detect_shadows
            )
        elif self.algorithm == 'KNN':
            # KNNå‚æ•°
            self.history = kwargs.get('history', 500)
            self.dist2_threshold = kwargs.get('dist2_threshold', 400)
            self.detect_shadows = kwargs.get('detect_shadows', False)

            self.back_sub = cv2.createBackgroundSubtractorKNN(
                history=self.history,
                dist2Threshold=self.dist2_threshold,
                detectShadows=self.detect_shadows
            )
        else:
            raise ValueError("ç®—æ³•å¿…é¡»æ˜¯ 'MOG2' æˆ– 'KNN'")
        print(f"âœ… {self.algorithm}èƒŒæ™¯å‡é™¤å™¨åˆå§‹åŒ–æˆåŠŸ")

        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        from utils.state_manager_old import TrainStateManager
        self.state_manager = TrainStateManager(
            min_stay_duration=kwargs.get('min_stay_duration', 5.0),
            cooldown_duration=kwargs.get('cooldown_duration', 3.0),
            entering_timeout=kwargs.get('entering_timeout', 10.0),
            exiting_timeout=kwargs.get('exiting_timeout', 10.0)
        )
        self.event_history = []  # äº‹ä»¶å†å²è®°å½•

    def setup_track_rois(self, entry_roi: list, exit_roi: list):
        """
        è®¾ç½®è¿›å‡ºç«™ROIåŒºåŸŸ

        Args:
            entry_roi: è¿›ç«™æ£€æµ‹ROI [(x1,y1), (x2,y2)]
            exit_roi: å‡ºç«™æ£€æµ‹ROI [(x1,y1), (x2,y2)]
        """
        if len(entry_roi) != 2 or len(exit_roi) != 2:
            raise ValueError("ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")

        # è®¾ç½®è¿›ç«™ROI
        self.roi_manager.add_roi('entry_region', entry_roi)
        # è®¾ç½®å‡ºç«™ROI
        self.roi_manager.add_roi('exit_region', exit_roi)

        print(f"ğŸ¯ è®¾ç½®è¿›ç«™ROI: {entry_roi}")
        print(f"ğŸ¯ è®¾ç½®å‡ºç«™ROI: {exit_roi}")

    def setup_single_roi(self, points: list, roi_name: str = 'track_region'):
        """
        è®¾ç½®å•ä¸ªROIåŒºåŸŸï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰

        Args:
            points: çŸ©å½¢åŒºåŸŸç‚¹åˆ—è¡¨ [(x1,y1), (x2,y2)]
            roi_name: ROIåŒºåŸŸåç§°
        """
        if len(points) != 2:
            raise ValueError("ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")

        self.roi_manager.add_roi(roi_name, points)
        print(f"ğŸ¯ è®¾ç½®ROIåŒºåŸŸ {roi_name}: {points}")

    # å¢å¼ºæš—è‰²å‰æ™¯æ£€æµ‹
    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        ä¼˜åŒ–é¢„å¤„ç† - å¢å¼ºæš—è‰²å‰æ™¯æ£€æµ‹
        """
        if frame is None:
            raise ValueError("è¾“å…¥å¸§ä¸èƒ½ä¸ºNone")

        # Step 1: è½¬æ¢ä¸ºç°åº¦å›¾
        if len(frame.shape) == 3:
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray_frame = frame.copy()

        # Step 2: ç›´æ–¹å›¾å‡è¡¡åŒ– - å¢å¼ºå¯¹æ¯”åº¦ï¼Œç‰¹åˆ«æ˜¯æš—è‰²åŒºåŸŸ
        gray_frame = cv2.equalizeHist(gray_frame)

        # Step 3: åº”ç”¨CLAHEï¼ˆå¯¹æ¯”åº¦å—é™çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰- æ›´å¥½çš„æš—è‰²åŒºåŸŸå¢å¼º
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray_frame = clahe.apply(gray_frame)

        # Step 4: åº”ç”¨å¤šä¸ªROIæ©è†œ
        if self.roi_manager.rois:
            mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
            for points in self.roi_manager.rois.values():
                cv2.rectangle(mask, points[0], points[1], 255, -1)
            gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

        # Step 5: è½»åº¦é«˜æ–¯æ¨¡ç³Šé™å™ªï¼ˆé¿å…è¿‡åº¦æ¨¡ç³Šï¼‰
        blurred_frame = cv2.GaussianBlur(gray_frame, (3, 3), 0)

        return blurred_frame

    def _postprocess_mask(self, fg_mask: np.ndarray) -> np.ndarray:
        """
        ä¼˜åŒ–åå¤„ç† - æé«˜æš—è‰²å‰æ™¯æ£€æµ‹çµæ•åº¦
        """
        # Step 1: é™ä½äºŒå€¼åŒ–é˜ˆå€¼ï¼Œè®©æ›´å¤šæš—è‰²åŒºåŸŸè¢«æ£€æµ‹ä¸ºå‰æ™¯
        # å¯¹äºMOG2ï¼Œé™ä½é˜ˆå€¼å¯ä»¥æ£€æµ‹æ›´å¤šæš—è‰²ç‰©ä½“
        _, binary_mask = cv2.threshold(
            fg_mask, 100, 255, cv2.THRESH_BINARY)  # ä»200é™åˆ°100

        # Step 2: å½¢æ€å­¦é—­è¿ç®—å…ˆå¡«å……å­”æ´ï¼ˆæš—è‰²åŒºåŸŸå¯èƒ½ä¸è¿ç»­ï¼‰
        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        closed_mask = cv2.morphologyEx(
            binary_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)

        # Step 3: å½¢æ€å­¦å¼€è¿ç®—å»é™¤å°å™ªå£°
        kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        opened_mask = cv2.morphologyEx(
            closed_mask, cv2.MORPH_OPEN, kernel_open, iterations=1)

        # Step 4: ä¸­å€¼æ»¤æ³¢é™å™ª
        filtered_mask = cv2.medianBlur(opened_mask, 3)  # ä½¿ç”¨è¾ƒå°çš„æ ¸

        return filtered_mask

    def apply(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
        """
        åº”ç”¨èƒŒæ™¯å‡é™¤

        Args:
            frame: è¾“å…¥å¸§
            learning_rate: å­¦ä¹ ç‡

        Returns:
            å¤„ç†åçš„å‰æ™¯æ©ç 
        """
        # é¢„å¤„ç†
        preprocessed_frame = self._preprocess_frame(frame)

        # åº”ç”¨èƒŒæ™¯å‡é™¤
        fg_mask = self.back_sub.apply(
            preprocessed_frame, learningRate=learning_rate)

        # åå¤„ç†
        processed_mask = self._postprocess_mask(fg_mask)

        return processed_mask

    def apply_with_roi_analysis(self, frame: np.ndarray, learning_rate: float = 0.005) -> dict:
        """
        åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†ææ‰€æœ‰ROIåŒºåŸŸ

        Args:
            frame: è¾“å…¥å¸§
            learning_rate: å­¦ä¹ ç‡

        Returns:
            åŒ…å«æ‰€æœ‰ROIåŒºåŸŸç»“æœçš„å­—å…¸
        """
        # åº”ç”¨èƒŒæ™¯å‡é™¤
        fg_mask = self.apply(frame, learning_rate)

        # è®¡ç®—å®Œæ•´å¸§ç»Ÿè®¡
        full_foreground_pixels = np.sum(fg_mask > 0)
        full_foreground_ratio = full_foreground_pixels / fg_mask.size

        results = {
            'full_frame': {
                'mask': fg_mask,
                'foreground_pixels': full_foreground_pixels,
                'foreground_ratio': full_foreground_ratio
            }
        }

        # è®¡ç®—æ¯ä¸ªROIåŒºåŸŸçš„ç»Ÿè®¡
        for roi_name in self.roi_manager.rois.keys():
            try:
                roi_mask = self.roi_manager.crop_roi(fg_mask, roi_name)

                roi_size = roi_mask.shape[0] * roi_mask.shape[1]
                roi_foreground_pixels = np.sum(roi_mask > 0)
                roi_foreground_ratio = roi_foreground_pixels / roi_size if roi_size > 0 else 0

                results[roi_name] = {
                    'mask': roi_mask,
                    'foreground_pixels': roi_foreground_pixels,
                    'foreground_ratio': roi_foreground_ratio,
                    'roi_size': roi_size
                }
            except Exception as e:
                print(f"âš ï¸ ROIåˆ†æå¤±è´¥ {roi_name}: {e}")

        return results

    def detect_train_events_with_state(self, result: dict,
                                       entry_threshold: float = 0.05,
                                       exit_threshold: float = 0.05,
                                       frame_timestamp: float = None) -> dict:
        """
        åŸºäºçŠ¶æ€æœºçš„åˆ—è½¦äº‹ä»¶æ£€æµ‹

        Args:
            result: apply_with_roi_analysisè¿”å›çš„ç»“æœ
            entry_threshold: è¿›ç«™æ£€æµ‹é˜ˆå€¼
            exit_threshold: å‡ºç«™æ£€æµ‹é˜ˆå€¼
            frame_timestamp: å½“å‰å¸§æ—¶é—´æˆ³

        Returns:
            äº‹ä»¶æ£€æµ‹ç»“æœå’ŒçŠ¶æ€ä¿¡æ¯
        """
        if frame_timestamp is None:
            import time
            frame_timestamp = time.time()

        # æ£€æµ‹å„ROIåŒºåŸŸçš„æ´»åŠ¨
        entry_detected = False
        exit_detected = False
        entry_confidence = 0.0
        exit_confidence = 0.0

        # è®¡ç®—å„åŒºåŸŸå‰æ™¯æ¯”ä¾‹
        if 'entry_region' in result:
            entry_ratio = result['entry_region']['foreground_ratio']
            entry_confidence = entry_ratio
            entry_detected = entry_ratio > entry_threshold

        if 'exit_region' in result:
            exit_ratio = result['exit_region']['foreground_ratio']
            exit_confidence = exit_ratio
            exit_detected = exit_ratio > exit_threshold

        # æ›´æ–°çŠ¶æ€
        state_result = self.state_manager.update_state(
            entry_detected, exit_detected, frame_timestamp
        )

        # æ„å»ºå®Œæ•´ç»“æœ
        events = {
            'entry_detected': entry_detected,
            'exit_detected': exit_detected,
            'entry_confidence': entry_confidence,
            'exit_confidence': exit_confidence,
            'current_state': state_result['state'],
            'state_changed': state_result['state_changed'],
            'event_triggered': state_result['event_triggered'],
            'event_type': state_result['event_type'],
            'in_cooldown': state_result['in_cooldown'],
            'state_duration': state_result['state_duration']
        }

        # è®°å½•é‡è¦äº‹ä»¶
        if state_result['event_triggered'] and state_result['event_type'] in ['train_entered', 'train_exited']:
            event_record = {
                'timestamp': frame_timestamp,
                'event_type': state_result['event_type'],
                'state': state_result['new_state'].name if state_result['new_state'] else events['current_state'].name,
                'entry_confidence': entry_confidence,
                'exit_confidence': exit_confidence
            }
            self.event_history.append(event_record)
            print(f"ğŸ“ è®°å½•äº‹ä»¶: {event_record}")

        return events

    def visualize_comparison_with_state(self, frame: np.ndarray, result: dict, events: dict):
        """
        å¯è§†åŒ–æ˜¾ç¤ºï¼ŒåŒ…å«çŠ¶æ€ä¿¡æ¯

        Args:
            frame: åŸå§‹å¸§
            result: apply_with_roi_analysisè¿”å›çš„ç»“æœ
            events: äº‹ä»¶æ£€æµ‹ç»“æœ
        """
        # è·å–å‰æ™¯æ©ç 
        fg_mask = result['full_frame']['mask']

        # åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ‰€æœ‰ROIåŒºåŸŸ
        frame_with_rois = frame.copy()
        frame_with_rois = self.roi_manager.draw_rois(frame_with_rois)

        # æ·»åŠ çŠ¶æ€ä¿¡æ¯
        y_offset = 30
        status_info = [
            f"State: {events['current_state'].name}",
            f"Duration: {events['state_duration']:.1f}s",
            f"Entry: {events['entry_confidence']:.3f}",
            f"Exit: {events['exit_confidence']:.3f}"
        ]

        for text in status_info:
            cv2.putText(frame_with_rois, text, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 25

        # æ·»åŠ äº‹ä»¶çŠ¶æ€
        if events['event_triggered']:
            event_text = f"Event: {events['event_type']}"
            cv2.putText(frame_with_rois, event_text, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            y_offset += 30

        if events['in_cooldown']:
            cool_text = "COOLDOWN"
            cv2.putText(frame_with_rois, cool_text, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        # æ ¹æ®çŠ¶æ€æ”¹å˜è¾¹æ¡†é¢œè‰²
        border_color = {
            TrainState.NO_TRAIN: (0, 0, 255),      # çº¢è‰²
            TrainState.ENTERING: (0, 255, 255),    # é»„è‰²
            TrainState.IN_STATION: (0, 255, 0),    # ç»¿è‰²
            TrainState.EXITING: (0, 165, 255)      # æ©™è‰²
        }[events['current_state']]

        # æ·»åŠ è¾¹æ¡†
        cv2.rectangle(frame_with_rois, (0, 0),
                      (frame_with_rois.shape[1]-1, frame_with_rois.shape[0]-1),
                      border_color, 3)

        # æ˜¾ç¤ºåŸå›¾çª—å£
        cv2.imshow('Train Detection - State Machine', frame_with_rois)

        # æ˜¾ç¤ºå„ROIåŒºåŸŸçš„å‰æ™¯æ©ç 
        for roi_name, roi_data in result.items():
            if roi_name not in ['full_frame']:
                roi_mask = roi_data['mask']
                roi_ratio = roi_data['foreground_ratio']

                roi_display = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR)
                text = f"{roi_name}: {roi_ratio:.3f}"
                cv2.putText(roi_display, text, (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

                cv2.imshow(f'ROI: {roi_name}', roi_display)

    def process_video_with_state_machine(self, video_path: str, max_frames: int = 100,
                                         show_visualization: bool = False,
                                         entry_threshold: float = 0.05,
                                         exit_threshold: float = 0.05) -> Dict:
        """
        ä½¿ç”¨çŠ¶æ€æœºå¤„ç†è§†é¢‘

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            max_frames: æœ€å¤§å¤„ç†å¸§æ•°
            show_visualization: æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–
            entry_threshold: è¿›ç«™æ£€æµ‹é˜ˆå€¼
            exit_threshold: å‡ºç«™æ£€æµ‹é˜ˆå€¼

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        import time

        if not Path(video_path).exists():
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))

        frame_count = 0
        start_time = time.time()

        print(f"ğŸ¬ å¼€å§‹çŠ¶æ€æœºè§†é¢‘å¤„ç†: {video_path}")
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}FPS")

        while True:
            ret, frame = cap.read()
            if not ret or frame_count >= max_frames:
                break

            current_time = time.time()
            frame_timestamp = start_time + \
                (frame_count / fps) if fps > 0 else current_time

            # åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†æ
            result = self.apply_with_roi_analysis(frame)

            # åŸºäºçŠ¶æ€æœºæ£€æµ‹äº‹ä»¶
            events = self.detect_train_events_with_state(
                result, entry_threshold, exit_threshold, frame_timestamp
            )

            # æ˜¾ç¤ºå¯è§†åŒ–
            if show_visualization:
                self.visualize_comparison_with_state(frame, result, events)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            frame_count += 1
            if frame_count % 50 == 0:
                status = self.state_manager.get_status()
                print(f"ğŸ“ˆ å¸§: {frame_count}, çŠ¶æ€: {status['current_state']}, "
                      f"è¿›ç«™: {status['entry_count']}, å‡ºç«™: {status['exit_count']}")

        cap.release()
        if show_visualization:
            cv2.destroyAllWindows()

        # è·å–æœ€ç»ˆçŠ¶æ€
        final_status = self.state_manager.get_status()

        stats = {
            'total_frames': frame_count,
            'entry_events': final_status['entry_count'],
            'exit_events': final_status['exit_count'],
            'final_state': final_status['current_state'],
            'event_history': self.event_history,
            'processing_time': time.time() - start_time
        }

        print(f"âœ… çŠ¶æ€æœºå¤„ç†å®Œæˆ")
        print(f"ğŸ“Š å…±å¤„ç† {frame_count} å¸§")
        print(f"ğŸš‚ è¿›ç«™äº‹ä»¶: {final_status['entry_count']} æ¬¡")
        print(f"ğŸš‚ å‡ºç«™äº‹ä»¶: {final_status['exit_count']} æ¬¡")
        print(f"ğŸ æœ€ç»ˆçŠ¶æ€: {final_status['current_state']}")

        return stats

    def get_state_info(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        return self.state_manager.get_status()

    def reset_state(self):
        """é‡ç½®çŠ¶æ€æœº"""
        self.state_manager.reset()
        self.event_history.clear()
