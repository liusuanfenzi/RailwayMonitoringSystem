from typing import Literal
import cv2
import numpy as np
from utils.video.video_utils import ROIManager


class GMMBackgroundSubtractor:
    """GMMèƒŒæ™¯å‡é™¤å™¨ - ä¸“æ³¨äºå•ä¸ªROIåŒºåŸŸçš„èƒŒæ™¯å»ºæ¨¡å’Œå‰æ™¯æå–"""

    def __init__(self, algorithm: str = 'MOG2', preprocess_mode: str = 'basic', **kwargs):
        """
        åˆå§‹åŒ–èƒŒæ™¯å‡é™¤å™¨

        Args:
            algorithm: 'MOG2' æˆ– 'KNN'
            preprocess_mode: é¢„å¤„ç†æ¨¡å¼ - 'basic', 'enhance_dark', æˆ– 'none'
            **kwargs: ç®—æ³•å‚æ•°
        """
        self.algorithm = algorithm.upper()
        self.preprocess_mode = preprocess_mode
        self.roi_manager = ROIManager()

        # å™ªå£°æŠ‘åˆ¶çº§åˆ«
        self.noise_reduction_level = kwargs.get('noise_reduction', 'medium')

        if self.algorithm == 'MOG2':
            self.history = kwargs.get('history', 500)
            self.var_threshold = kwargs.get('var_threshold', 16)
            self.detect_shadows = kwargs.get('detect_shadows', False)

            self.back_sub = cv2.createBackgroundSubtractorMOG2(
                history=self.history,
                varThreshold=self.var_threshold,
                detectShadows=self.detect_shadows
            )
        elif self.algorithm == 'KNN':
            self.history = kwargs.get('history', 500)
            self.dist2_threshold = kwargs.get('dist2_threshold', 400)
            self.detect_shadows = kwargs.get('detect_shadows', False)

            self.back_sub = cv2.createBackgroundSubtractorKNN(
                history=self.history,
                dist2Threshold=self.dist2_threshold,
                detectShadows=self.detect_shadows
            )
        else:
            raise ValueError("ç®—æ³•å¿…é¡»æ˜¯ 'MOG2' æˆ– 'KNN'")

        print(f"âœ… {self.algorithm}èƒŒæ™¯å‡é™¤å™¨åˆå§‹åŒ–æˆåŠŸ - é¢„å¤„ç†æ¨¡å¼: {self.preprocess_mode}")

    def setup_single_roi(self, points: list, roi_name: str = 'detection_region'):
        """è®¾ç½®å•ä¸ªROIåŒºåŸŸ"""
        if len(points) != 2:
            raise ValueError("ROIç‚¹å¿…é¡»æ˜¯ä¸¤ä¸ªç‚¹ [(x1,y1), (x2,y2)]")
        self.roi_manager.add_roi(roi_name, points)
        print(f"ğŸ¯ è®¾ç½®å•ä¸ªROIåŒºåŸŸ {roi_name}: {points}")

    def _basic_preprocess(self, frame: np.ndarray) -> np.ndarray:
        """åŸºç¡€é¢„å¤„ç† - åªä¿ç•™ç°åº¦è½¬æ¢å’ŒROIæ©ç """
        if len(frame.shape) == 3:
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray_frame = frame.copy()

        if self.roi_manager.rois:
            mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
            for points in self.roi_manager.rois.values():
                cv2.rectangle(mask, points[0], points[1], 255, -1)
            gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

        return gray_frame

    def _enhance_dark_preprocess(self, frame: np.ndarray) -> np.ndarray:
        """å¢å¼ºæš—è‰²åŒºåŸŸçš„é¢„å¤„ç† - ä¸“é—¨é’ˆå¯¹åˆ—è½¦æš—è‰²åŒºåŸŸ"""
        if len(frame.shape) == 3:
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray_frame = frame.copy()

        # åº”ç”¨ROIæ©è†œ
        if self.roi_manager.rois:
            mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
            for points in self.roi_manager.rois.values():
                cv2.rectangle(mask, points[0], points[1], 255, -1)
            gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

        # å¢å¼ºæš—éƒ¨å¤„ç†é“¾
        equalized_frame = cv2.equalizeHist(gray_frame)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        clahe_frame = clahe.apply(equalized_frame)
        gamma_corrected = self._gamma_correction(clahe_frame, gamma=1.5)
        blurred_frame = cv2.GaussianBlur(gamma_corrected, (3, 3), 0)

        return blurred_frame

    def _gamma_correction(self, image: np.ndarray, gamma: float = 1.0) -> np.ndarray:
        """ä¼½é©¬æ ¡æ­£"""
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255
                         for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(image, table)

    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """æ ¹æ®é€‰æ‹©çš„é¢„å¤„ç†æ¨¡å¼å¤„ç†å¸§"""
        if frame is None:
            raise ValueError("è¾“å…¥å¸§ä¸èƒ½ä¸ºNone")

        if self.preprocess_mode == 'none':
            if len(frame.shape) == 3:
                return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            return frame.copy()
        elif self.preprocess_mode == 'basic':
            return self._basic_preprocess(frame)
        elif self.preprocess_mode == 'enhance_dark':
            return self._enhance_dark_preprocess(frame)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é¢„å¤„ç†æ¨¡å¼: {self.preprocess_mode}")

    def _postprocess_mask(self, fg_mask: np.ndarray, noise_reduction_level: str = None) -> np.ndarray:
        """
        å¢å¼ºçš„åå¤„ç†å‰æ™¯æ©ç  - å¤šçº§åˆ«å™ªå£°æŠ‘åˆ¶
        """
        if noise_reduction_level is None:
            noise_reduction_level = self.noise_reduction_level

        # è‡ªé€‚åº”äºŒå€¼åŒ–é˜ˆå€¼
        if self.preprocess_mode == 'enhance_dark':
            _, binary_mask = cv2.threshold(
                fg_mask, 150, 255, cv2.THRESH_BINARY)
        else:
            _, binary_mask = cv2.threshold(
                fg_mask, 100, 255, cv2.THRESH_BINARY)

        # å™ªå£°æŠ‘åˆ¶å‚æ•°é…ç½®
        if noise_reduction_level == 'light':
            kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
            median_kernel = 3
            area_threshold = 30
        elif noise_reduction_level == 'medium':
            kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            median_kernel = 5
            area_threshold = 100
        else:  # 'strong'
            kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            median_kernel = 7
            area_threshold = 200

        # å½¢æ€å­¦å¤„ç†æµç¨‹
        opened_mask = cv2.morphologyEx(
            binary_mask, cv2.MORPH_OPEN, kernel_open, iterations=1)
        closed_mask = cv2.morphologyEx(
            opened_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)
        final_mask = median_filtered = cv2.medianBlur(
            closed_mask, median_kernel)
        # final_mask = self._remove_small_components(median_filtered, area_threshold)

        return final_mask

    def set_preprocess_mode(self, mode: Literal['none', 'basic', 'enhance_dark']):
        """åŠ¨æ€è®¾ç½®é¢„å¤„ç†æ¨¡å¼"""
        self.preprocess_mode = mode
        print(f"ğŸ”„ é¢„å¤„ç†æ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode}")

    def set_noise_reduction_level(self, level: Literal['light', 'medium', 'strong']):
        """åŠ¨æ€è®¾ç½®å™ªå£°æŠ‘åˆ¶çº§åˆ«"""
        self.noise_reduction_level = level
        print(f"ğŸ”„ å™ªå£°æŠ‘åˆ¶çº§åˆ«å·²åˆ‡æ¢ä¸º: {level}")

    def apply(self, frame: np.ndarray, learning_rate: float = 0.005,
              noise_reduction_level: str = None) -> np.ndarray:
        """
        åº”ç”¨èƒŒæ™¯å‡é™¤

        Args:
            frame: è¾“å…¥å¸§
            learning_rate: å­¦ä¹ ç‡
            noise_reduction_level: å¯é€‰ï¼Œè¦†ç›–é»˜è®¤å™ªå£°æŠ‘åˆ¶çº§åˆ«
        """
        preprocessed_frame = self._preprocess_frame(frame)
        fg_mask = self.back_sub.apply(
            preprocessed_frame, learningRate=learning_rate)
        processed_mask = self._postprocess_mask(fg_mask, noise_reduction_level)
        return processed_mask

    def apply_with_roi_analysis(self, frame: np.ndarray, learning_rate: float = 0.005) -> dict:
        """
        åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†æROIåŒºåŸŸ

        Args:
            frame: è¾“å…¥å¸§
            learning_rate: å­¦ä¹ ç‡

        Returns:
            åŒ…å«ROIåŒºåŸŸç»“æœçš„å­—å…¸
        """
        fg_mask = self.apply(frame, learning_rate)

        # è®¡ç®—å®Œæ•´å¸§ç»Ÿè®¡
        full_foreground_pixels = np.sum(fg_mask > 0)
        full_foreground_ratio = full_foreground_pixels / fg_mask.size

        results = {
            'full_frame': {
                'mask': fg_mask,
                'foreground_pixels': full_foreground_pixels,
                'foreground_ratio': full_foreground_ratio,
                'preprocess_mode': self.preprocess_mode
            }
        }

        # è®¡ç®—ROIåŒºåŸŸçš„ç»Ÿè®¡
        if self.roi_manager.rois:
            roi_name = list(self.roi_manager.rois.keys())[0]  # è·å–å”¯ä¸€çš„ROIåç§°
            try:
                roi_mask = self.roi_manager.crop_roi(fg_mask, roi_name)

                roi_size = roi_mask.shape[0] * roi_mask.shape[1]
                roi_foreground_pixels = np.sum(roi_mask > 0)
                roi_foreground_ratio = roi_foreground_pixels / roi_size if roi_size > 0 else 0

                results[roi_name] = {
                    'mask': roi_mask,
                    'foreground_pixels': roi_foreground_pixels,
                    'foreground_ratio': roi_foreground_ratio,
                    'roi_size': roi_size
                }
            except Exception as e:
                print(f"âš ï¸ ROIåˆ†æå¤±è´¥ {roi_name}: {e}")

        return results

    def get_background_model(self) -> np.ndarray:
        """è·å–å½“å‰èƒŒæ™¯æ¨¡å‹"""
        return self.back_sub.getBackgroundImage()

    def reset_model(self):
        """é‡ç½®èƒŒæ™¯æ¨¡å‹"""
        if self.algorithm == 'MOG2':
            self.back_sub = cv2.createBackgroundSubtractorMOG2(
                history=self.history,
                varThreshold=self.var_threshold,
                detectShadows=self.detect_shadows
            )
        else:
            self.back_sub = cv2.createBackgroundSubtractorKNN(
                history=self.history,
                dist2Threshold=self.dist2_threshold,
                detectShadows=self.detect_shadows
            )
        print("ğŸ”„ èƒŒæ™¯æ¨¡å‹å·²é‡ç½®")
