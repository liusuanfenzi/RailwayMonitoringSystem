# models/jetson_gmm_model.py
import cv2
import numpy as np
from typing import Literal, Dict
from utils.utils import ROIManager, PerformanceMonitor

class GMMBackgroundSubtractor:
    """Jetsonä¼˜åŒ–çš„GMMèƒŒæ™¯å‡é™¤å™¨ - æ”¯æŒå¤šç§é¢„å¤„ç†æ¨¡å¼"""

    def __init__(self, algorithm: str = 'MOG2', preprocess_mode: str = 'basic', **kwargs):
        """
        Jetsonä¼˜åŒ–åˆå§‹åŒ–

        Args:
            algorithm: 'MOG2' æˆ– 'KNN'
            preprocess_mode: é¢„å¤„ç†æ¨¡å¼ - 'basic', 'enhance_dark'
            **kwargs: ç®—æ³•å‚æ•°
        """
        self.algorithm = algorithm.upper()
        self.preprocess_mode = preprocess_mode
        self.roi_manager = ROIManager()
        self.performance_monitor = PerformanceMonitor()
        
        # Jetsonä¼˜åŒ–å‚æ•°
        if self.algorithm == 'MOG2':
            self.history = kwargs.get('history', 200)
            self.var_threshold = kwargs.get('var_threshold', 16)
            self.detect_shadows = kwargs.get('detect_shadows', False)

            self.back_sub = cv2.createBackgroundSubtractorMOG2(
                history=self.history,
                varThreshold=self.var_threshold,
                detectShadows=self.detect_shadows
            )
        elif self.algorithm == 'KNN':
            self.history = kwargs.get('history', 200)
            self.dist2_threshold = kwargs.get('dist2_threshold', 400)
            self.detect_shadows = kwargs.get('detect_shadows', False)

            self.back_sub = cv2.createBackgroundSubtractorKNN(
                history=self.history,
                dist2Threshold=self.dist2_threshold,
                detectShadows=self.detect_shadows
            )
        else:
            raise ValueError("ç®—æ³•å¿…é¡»æ˜¯ 'MOG2' æˆ– 'KNN'")

        print(f"âœ… Jetson {self.algorithm}èƒŒæ™¯å‡é™¤å™¨åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: {self.preprocess_mode}")

    def setup_single_roi(self, points: list, roi_name: str = 'detection_region'):
        """è®¾ç½®å•ä¸ªROIåŒºåŸŸ"""
        self.roi_manager.add_roi(roi_name, points)

    def _basic_preprocess(self, frame: np.ndarray) -> np.ndarray:
        """
        åŸºç¡€é¢„å¤„ç† - ç°åº¦åŒ– + ROIæ©ç 
        æ€§èƒ½æœ€ä¼˜ï¼Œé€‚åˆæ˜äº®ç¯å¢ƒ
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(frame.shape) == 3:
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray_frame = frame.copy()

        # åº”ç”¨ROIæ©è†œ
        if self.roi_manager.rois:
            mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
            for points in self.roi_manager.rois.values():
                cv2.rectangle(mask, points[0], points[1], 255, -1)
            gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

        # è½»å¾®é«˜æ–¯æ¨¡ç³Šå‡å°‘å™ªå£°
        blurred_frame = cv2.GaussianBlur(gray_frame, (3, 3), 0)
        return blurred_frame

    def _enhance_dark_preprocess(self, frame: np.ndarray) -> np.ndarray:
        """
        å¢å¼ºæš—éƒ¨é¢„å¤„ç† - é’ˆå¯¹åˆ—è½¦æš—è‰²åŒºåŸŸä¼˜åŒ–
        å¹³è¡¡æ•ˆæœå’Œæ€§èƒ½ï¼Œé€‚åˆæš—å…‰ç¯å¢ƒ
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(frame.shape) == 3:
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray_frame = frame.copy()

        # åº”ç”¨ROIæ©è†œ
        if self.roi_manager.rois:
            mask = np.zeros(gray_frame.shape[:2], dtype=np.uint8)
            for points in self.roi_manager.rois.values():
                cv2.rectangle(mask, points[0], points[1], 255, -1)
            gray_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)

        # Jetsonä¼˜åŒ–çš„æš—éƒ¨å¢å¼ºå¤„ç†é“¾
        # 1. ç›´æ–¹å›¾å‡è¡¡åŒ– - å¢å¼ºå¯¹æ¯”åº¦
        equalized_frame = cv2.equalizeHist(gray_frame)
        
        # 2. é™åˆ¶å¯¹æ¯”åº¦çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ– - é’ˆå¯¹æš—éƒ¨ä¼˜åŒ–
        # ä½¿ç”¨è¾ƒå°çš„ç½‘æ ¼å’Œé€‚ä¸­çš„clipLimitä»¥å¹³è¡¡æ€§èƒ½
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        clahe_frame = clahe.apply(equalized_frame)
        
        # 3. ä¼½é©¬æ ¡æ­£ - å¢å¼ºæš—éƒ¨ç»†èŠ‚ (ä¼˜åŒ–ç‰ˆæœ¬)
        gamma_corrected = self._optimized_gamma_correction(clahe_frame, gamma=1.3)
        
        # 4. é«˜æ–¯æ¨¡ç³Šå‡å°‘å™ªå£°
        blurred_frame = cv2.GaussianBlur(gamma_corrected, (3, 3), 0)

        return blurred_frame

    def _optimized_gamma_correction(self, image: np.ndarray, gamma: float = 1.0) -> np.ndarray:
        """
        Jetsonä¼˜åŒ–çš„ä¼½é©¬æ ¡æ­£
        ä½¿ç”¨æŸ¥æ‰¾è¡¨é¿å…é‡å¤è®¡ç®—
        """
        # æ„å»ºä¼½é©¬æ ¡æ­£æŸ¥æ‰¾è¡¨
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255
                         for i in range(256)]).astype("uint8")
        
        # åº”ç”¨æŸ¥æ‰¾è¡¨
        return cv2.LUT(image, table)

    def _jetson_preprocess(self, frame: np.ndarray) -> np.ndarray:
        """
        Jetsonä¼˜åŒ–çš„é¢„å¤„ç† - æ”¯æŒå¤šç§æ¨¡å¼
        """
        if frame is None:
            raise ValueError("è¾“å…¥å¸§ä¸èƒ½ä¸ºNone")

        if self.preprocess_mode == 'basic':
            return self._basic_preprocess(frame)
        elif self.preprocess_mode == 'enhance_dark':
            return self._enhance_dark_preprocess(frame)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é¢„å¤„ç†æ¨¡å¼: {self.preprocess_mode}")

    def _jetson_postprocess(self, fg_mask: np.ndarray) -> np.ndarray:
        """
        Jetsonä¼˜åŒ–çš„åå¤„ç†
        æ ¹æ®é¢„å¤„ç†æ¨¡å¼è°ƒæ•´å‚æ•°
        """
        # è‡ªé€‚åº”äºŒå€¼åŒ–é˜ˆå€¼
        if self.preprocess_mode == 'enhance_dark':
            # å¢å¼ºæš—éƒ¨æ¨¡å¼ä¸‹ä½¿ç”¨æ›´é«˜é˜ˆå€¼
            _, binary_mask = cv2.threshold(fg_mask, 180, 255, cv2.THRESH_BINARY)
        else:
            _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)

        # Jetsonä¼˜åŒ–ï¼šæ ¹æ®æ¨¡å¼è°ƒæ•´å½¢æ€å­¦æ“ä½œå¼ºåº¦
        if self.preprocess_mode == 'enhance_dark':
            # å¢å¼ºæ¨¡å¼ä¸‹ä½¿ç”¨æ›´å¼ºçš„å™ªå£°æŠ‘åˆ¶
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        else:
            # åŸºç¡€æ¨¡å¼ä¸‹ä½¿ç”¨è¾ƒè½»çš„å™ªå£°æŠ‘åˆ¶
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
            kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))

        # å½¢æ€å­¦å¤„ç†
        opened_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_open, iterations=1)
        closed_mask = cv2.morphologyEx(opened_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)
        final_mask = cv2.medianBlur(closed_mask, 3)

        return final_mask

    def set_preprocess_mode(self, mode: Literal['basic', 'enhance_dark']):
        """åŠ¨æ€è®¾ç½®é¢„å¤„ç†æ¨¡å¼"""
        if mode not in ['basic', 'enhance_dark']:
            raise ValueError("é¢„å¤„ç†æ¨¡å¼å¿…é¡»æ˜¯ 'basic' æˆ– 'enhance_dark'")
        
        self.preprocess_mode = mode
        print(f"ğŸ”„ é¢„å¤„ç†æ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode}")

    def apply(self, frame: np.ndarray, learning_rate: float = 0.005) -> np.ndarray:
        """
        åº”ç”¨èƒŒæ™¯å‡é™¤ - Jetsonä¼˜åŒ–ç‰ˆæœ¬
        """
        start_time = self.performance_monitor.start_timing()
        
        preprocessed_frame = self._jetson_preprocess(frame)
        fg_mask = self.back_sub.apply(preprocessed_frame, learningRate=learning_rate)
        processed_mask = self._jetson_postprocess(fg_mask)
        
        self.performance_monitor.end_timing(start_time, f"èƒŒæ™¯å‡é™¤[{self.preprocess_mode}]")
        return processed_mask

    def apply_with_roi_analysis(self, frame: np.ndarray, learning_rate: float = 0.005) -> Dict:
        """
        åº”ç”¨èƒŒæ™¯å‡é™¤å¹¶åˆ†æROIåŒºåŸŸ - Jetsonä¼˜åŒ–ç‰ˆæœ¬
        """
        fg_mask = self.apply(frame, learning_rate)

        # è®¡ç®—å®Œæ•´å¸§ç»Ÿè®¡
        full_foreground_pixels = np.sum(fg_mask > 0)
        full_foreground_ratio = full_foreground_pixels / fg_mask.size

        results = {
            'full_frame': {
                'mask': fg_mask,
                'foreground_pixels': full_foreground_pixels,
                'foreground_ratio': full_foreground_ratio,
                'preprocess_mode': self.preprocess_mode
            }
        }

        # è®¡ç®—ROIåŒºåŸŸçš„ç»Ÿè®¡
        if self.roi_manager.rois:
            roi_name = list(self.roi_manager.rois.keys())[0]
            try:
                roi_mask = self.roi_manager.crop_roi(fg_mask, roi_name)
                roi_size = roi_mask.shape[0] * roi_mask.shape[1]
                roi_foreground_pixels = np.sum(roi_mask > 0)
                roi_foreground_ratio = roi_foreground_pixels / roi_size if roi_size > 0 else 0

                results[roi_name] = {
                    'mask': roi_mask,
                    'foreground_pixels': roi_foreground_pixels,
                    'foreground_ratio': roi_foreground_ratio,
                    'roi_size': roi_size
                }
            except Exception as e:
                print(f"âš ï¸ ROIåˆ†æå¤±è´¥ {roi_name}: {e}")

        return results

    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return self.performance_monitor.get_performance_stats()

    def reset_model(self):
        """é‡ç½®èƒŒæ™¯æ¨¡å‹"""
        if self.algorithm == 'MOG2':
            self.back_sub = cv2.createBackgroundSubtractorMOG2(
                history=self.history,
                varThreshold=self.var_threshold,
                detectShadows=self.detect_shadows
            )
        else:
            self.back_sub = cv2.createBackgroundSubtractorKNN(
                history=self.history,
                dist2Threshold=self.dist2_threshold,
                detectShadows=self.detect_shadows
            )
        print("ğŸ”„ èƒŒæ™¯æ¨¡å‹å·²é‡ç½®")