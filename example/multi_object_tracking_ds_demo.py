import time
import cv2
import numpy as np
from collections import defaultdict
from pathlib import Path
from models.detectors.yolo_detector import YOLODetector
from models.detectors.stay_detector import StayDetector
from models.trackers.multi_object_tracker import MultiObjectTracker
from utils.video.video_utils import ROIManager

class PersonVehicleStayDetection:
    """äººå‘˜è½¦è¾†è·Ÿè¸ªç³»ç»Ÿï¼ˆåŸºäºDeepSORTï¼‰- ROIåŒºåŸŸæ£€æµ‹æ¨¡å¼"""

    def __init__(self, model_path='yolov5su.pt', conf_threshold=0.5,
                 use_gpu=True, stay_threshold=8,skip_frame_mode=False,detection_interval=3):
        """
        åˆå§‹åŒ–è·Ÿè¸ªç³»ç»Ÿ
        
        Args:
            model_path: YOLOæ¨¡å‹è·¯å¾„
            conf_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            stay_threshold: åœç•™æ—¶é—´é˜ˆå€¼
        """
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.detector = YOLODetector(
            model_path=model_path,
            conf_threshold=conf_threshold,
            use_gpu=use_gpu
        )

        # ä½¿ç”¨DeepSORTè·Ÿè¸ªå™¨
        self.tracker = MultiObjectTracker(
            max_age=70,
            min_hits=3,
            iou_threshold=0.3,
            max_cosine_distance=0.3,
            use_gpu=use_gpu
        )

        self.roi_manager = ROIManager()

        # åœç•™æ£€æµ‹å™¨ä½¿ç”¨ROIç®¡ç†å™¨
        self.stay_detector = StayDetector(
            roi_manager=self.roi_manager,
            alert_dir="alerts",
            stay_threshold=stay_threshold,
            movement_threshold=5,
            min_frames=10
        )

        # æ€§èƒ½ç›‘æ§
        self.processing_times = []
        self.frame_counter = 0
        
        # è·³å¸§æ£€æµ‹æ¨¡å¼
        self.skip_frame_mode = skip_frame_mode
        self.detection_interval = detection_interval  # æ¯3å¸§æ£€æµ‹ä¸€æ¬¡
        self.last_detection_frame = 0
        
        # ç¼“å­˜ä¸Šä¸€å¸§çš„æ£€æµ‹ç»“æœ
        self.last_detections = np.empty((0, 6))

        print("âœ… äººå‘˜è½¦è¾†è·Ÿè¸ªç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ˆROIåŒºåŸŸæ£€æµ‹æ¨¡å¼ï¼‰")

    def set_detection_roi(self, points):
        """
        è®¾ç½®æ£€æµ‹å’Œè·Ÿè¸ªçš„ROIåŒºåŸŸ
        
        Args:
            points: ROIåŒºåŸŸåæ ‡ [(x1,y1), (x2,y2)]
        """
        # è®¾ç½®æ£€æµ‹å™¨ROI
        self.detector.set_roi(points)
        
        # è®¾ç½®è·Ÿè¸ªå™¨ROI
        self.tracker.set_roi(points)
        
        # åŒæ—¶æ·»åŠ åˆ°ROIç®¡ç†å™¨ç”¨äºåœç•™æ£€æµ‹
        self.roi_manager.add_roi("detection_roi", points)
        
        print(f"ğŸ¯ å·²è®¾ç½®æ£€æµ‹å’Œè·Ÿè¸ªROIåŒºåŸŸ: {points}")

    def disable_roi_detection(self):
        """ç¦ç”¨ROIæ£€æµ‹ï¼Œåˆ‡æ¢å›å…¨å›¾æ£€æµ‹"""
        self.detector.disable_roi()
        self.tracker.disable_roi()
        print("ğŸ”“ å·²ç¦ç”¨ROIæ£€æµ‹ï¼Œåˆ‡æ¢ä¸ºå…¨å›¾æ£€æµ‹æ¨¡å¼")
    
    def toggle_skip_frame_mode(self, interval=3):
        """
        åˆ‡æ¢è·³å¸§æ£€æµ‹æ¨¡å¼
        
        Args:
            interval: æ£€æµ‹é—´éš”å¸§æ•°
        """
        self.skip_frame_mode = not self.skip_frame_mode
        self.detection_interval = interval
        self.last_detection_frame = 0
        
        if self.skip_frame_mode:
            print(f"â© å¯ç”¨è·³å¸§æ£€æµ‹æ¨¡å¼ï¼Œæ¯ {interval} å¸§æ£€æµ‹ä¸€æ¬¡")
        else:
            print("ğŸ” ç¦ç”¨è·³å¸§æ£€æµ‹æ¨¡å¼ï¼Œæ¯å¸§éƒ½æ£€æµ‹")

    def process_frame(self, frame):
        """
        å¤„ç†å•å¸§å›¾åƒï¼ˆåœ¨ROIåŒºåŸŸå†…è¿›è¡Œæ£€æµ‹å’Œè·Ÿè¸ªï¼‰
        
        Args:
            frame: è¾“å…¥å›¾åƒ
            
        Returns:
            result_frame: å¤„ç†åçš„å›¾åƒ
            tracked_objects: è·Ÿè¸ªç»“æœ
        """
        start_time = time.time()
        self.frame_counter += 1

        try:
            # 1. ç›®æ ‡æ£€æµ‹ï¼ˆåœ¨ROIåŒºåŸŸå†…ï¼‰
            if self.skip_frame_mode:
                # è·³å¸§æ£€æµ‹æ¨¡å¼
                if (self.frame_counter - self.last_detection_frame) >= self.detection_interval:
                    # è¿›è¡Œæ£€æµ‹
                    detections = self.detector.detect(frame)
                    self.last_detections = detections
                    self.last_detection_frame = self.frame_counter
                    print(f"ğŸ” æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡ (è·³å¸§æ¨¡å¼)")
                else:
                    # ä½¿ç”¨ä¸Šä¸€å¸§çš„æ£€æµ‹ç»“æœ
                    detections = self.last_detections
                    print(f"â© è·³å¸§ï¼Œä½¿ç”¨ç¼“å­˜æ£€æµ‹ç»“æœ: {len(detections)} ä¸ªç›®æ ‡")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼Œæ¯å¸§éƒ½æ£€æµ‹
                detections = self.detector.detect(frame)
                print(f"ğŸ” æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")

            # 2. ç›®æ ‡è·Ÿè¸ªï¼ˆåœ¨ROIåŒºåŸŸå†…ï¼‰
            tracked_objects = self.tracker.update(detections, frame)
            print(f"ğŸ“ˆ è·Ÿè¸ª {len(tracked_objects)} ä¸ªå¯¹è±¡")

            # 3. åœç•™æ£€æµ‹
            current_time = float(self.frame_counter) / 30.0
            self.stay_detector.update(tracked_objects, current_time, frame)

            # 4. å¯è§†åŒ–è·Ÿè¸ªç»“æœ - ä½¿ç”¨å½“å‰åœç•™å’Œæ›¾ç»æŠ¥è­¦çš„å¯¹è±¡
            result_frame = self.tracker.visualize_tracking(
                frame,
                tracked_objects,
                self.stay_detector.get_staying_objects(),
                self.stay_detector.get_alerted_objects()
            )

            # 5. æ·»åŠ æ€§èƒ½ä¿¡æ¯
            result_frame = self._add_performance_info(result_frame, tracked_objects)

            # æ€§èƒ½ç»Ÿè®¡
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 60:
                self.processing_times.pop(0)

            return result_frame, tracked_objects

        except Exception as e:
            print(f"âŒ å¸§å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return frame, []

    def _add_performance_info(self, frame, tracked_objects):
        """æ·»åŠ æ€§èƒ½ä¿¡æ¯åˆ°å›¾åƒ"""
        if not self.processing_times:
            return frame

        avg_time = sum(self.processing_times) / len(self.processing_times)
        avg_fps = 1.0 / avg_time if avg_time > 0 else 0

        # æ£€æµ‹æ¨¡å¼æ˜¾ç¤º
        mode = "ROI_mode" if self.detector.roi_active else "full_frame_mode"
        skip_mode = f"skipx{self.detection_interval}" if self.skip_frame_mode else "normal_detection"

        # æ€§èƒ½ä¿¡æ¯æ˜¾ç¤º
        info_lines = [
            f'FPS: {avg_fps:.1f}',
            f'mode: {mode} | {skip_mode}',
            f'tracked_numbers: {len(tracked_objects)}',
            f'staying_numbers: {self.stay_detector.get_staying_count()}',
            f'alerted_numbers: {len(self.stay_detector.get_alerted_objects())}',
            f'algorithm: DeepSORT'
        ]

        for i, line in enumerate(info_lines):
            color = (0, 255, 0)
            if "staying" in line and self.stay_detector.get_staying_count() > 0:
                color = (0, 0, 255)
            elif "alerted" in line and len(self.stay_detector.get_alerted_objects()) > 0:
                color = (0, 0, 255)

            cv2.putText(frame, line, (10, 30 + i * 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        return frame

    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.processing_times:
            return "æš‚æ— æ€§èƒ½æ•°æ®"

        avg_time = sum(self.processing_times) / len(self.processing_times)
        avg_fps = 1.0 / avg_time if avg_time > 0 else 0
        
        mode = "ROIæ¨¡å¼" if self.detector.roi_active else "å…¨å›¾æ¨¡å¼"
        skip_mode = f"è·³å¸§x{self.detection_interval}" if self.skip_frame_mode else "æ­£å¸¸æ£€æµ‹"
        
        return f"æ¨¡å¼: {mode} | {skip_mode}, å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s, å¹³å‡FPS: {avg_fps:.1f}"

    def reset_stay_detection(self):
        """é‡ç½®åœç•™æ£€æµ‹"""
        self.stay_detector.reset()

    def add_roi(self, name, points):
        """æ·»åŠ ROIåŒºåŸŸï¼ˆä»…ç”¨äºåœç•™æ£€æµ‹ï¼‰"""
        self.roi_manager.add_roi(name, points)
        print(f"âœ… æ·»åŠ åœç•™æ£€æµ‹ROIåŒºåŸŸ: {name}, åæ ‡: {points}")


def main():
    """ä¸»å‡½æ•° - ROIåŒºåŸŸæ£€æµ‹æ¨¡å¼"""
    print("ğŸš€ å¯åŠ¨äººå‘˜è½¦è¾†åœç•™æ£€æµ‹ç³»ç»Ÿï¼ˆROIåŒºåŸŸæ£€æµ‹æ¨¡å¼ï¼‰")
    print("=" * 50)

    tracker = None

    try:
        # åˆå§‹åŒ–è·Ÿè¸ªç³»ç»Ÿ
        tracker = PersonVehicleStayDetection(
            model_path='yolov5su.pt',
            conf_threshold=0.8,
            use_gpu=True,
            stay_threshold=8,
            skip_frame_mode=True,
            detection_interval=3
        )

        # è®¾ç½®æ£€æµ‹å’Œè·Ÿè¸ªçš„ROIåŒºåŸŸ
        # detection_roi = [(350, 340), (750, 580)]
        # tracker.set_detection_roi(detection_roi)
        # video_source = "data/test_videos/callpose_test/callpose_test (online-video-cutter.com).mp4"

        # detection_roi = [(200, 200), (700, 600)]
        # tracker.set_detection_roi(detection_roi)
        # video_source = "data/test_videos/safe_gesture/1 (online-video-cutter.com).mp4"

        detection_roi = [(300, 300), (800, 700)]
        tracker.set_detection_roi(detection_roi)
        video_source = "data/test_videos/safe_gesture/gf1 (online-video-cutter.com).mp4"
        cap = cv2.VideoCapture(video_source)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_source}")
            return

        # è·å–è§†é¢‘ä¿¡æ¯
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {fps:.1f} FPS, æ€»å¸§æ•°: {total_frames}")

        print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        print("ğŸ¯ å·¥ä½œæ¨¡å¼: ROIåŒºåŸŸæ£€æµ‹å’Œè·Ÿè¸ª")
        print("ğŸ® æ§åˆ¶è¯´æ˜:")
        print("  - æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
        print("  - æŒ‰ 's' é”®ä¿å­˜å½“å‰å¸§")
        print("  - æŒ‰ 'r' é”®é‡ç½®åœç•™æ£€æµ‹")
        print("  - æŒ‰ 'd' é”®åˆ‡æ¢æ£€æµ‹æ¨¡å¼ï¼ˆROI/å…¨å›¾ï¼‰")
        # print("  - æŒ‰ 'f' é”®åˆ‡æ¢è·³å¸§æ£€æµ‹æ¨¡å¼")
        # print("  - æŒ‰ '1' é”®è®¾ç½®è·³å¸§é—´éš”ä¸º2")
        # print("  - æŒ‰ '2' é”®è®¾ç½®è·³å¸§é—´éš”ä¸º3")
        # print("  - æŒ‰ '3' é”®è®¾ç½®è·³å¸§é—´éš”ä¸º5")
        print("=" * 50)

        last_performance_log = 0
        current_mode = "ROI"
        skip_mode = "æ­£å¸¸æ£€æµ‹"

        while True:
            ret, frame = cap.read()
            if not ret:
                print("ğŸ“¹ è§†é¢‘æµç»“æŸ")
                break

            # å¤„ç†å¸§ - åœ¨ROIåŒºåŸŸå†…è¿›è¡Œæ£€æµ‹å’Œè·Ÿè¸ª
            result_frame, tracked_objects = tracker.process_frame(frame)

            # æ˜¾ç¤ºç»“æœ
            window_title = f'PersonVehicleDetectSystem - {current_mode}mode | {skip_mode}'
            cv2.imshow(window_title, result_frame)

            # é”®ç›˜æ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                cv2.imwrite(f"system_state_{timestamp}.jpg", result_frame)
                print(f"ğŸ’¾ ç³»ç»ŸçŠ¶æ€å·²ä¿å­˜: system_state_{timestamp}.jpg")
            elif key == ord('r'):
                tracker.reset_stay_detection()
            elif key == ord('d'):
                # åˆ‡æ¢æ£€æµ‹æ¨¡å¼
                if current_mode == "ROI":
                    tracker.disable_roi_detection()
                    current_mode = "å…¨å›¾"
                else:
                    detection_roi = [(350, 370), (750, 580)]
                    tracker.set_detection_roi(detection_roi)
                    current_mode = "ROI"
                print(f"ğŸ”„ åˆ‡æ¢åˆ°{current_mode}æ£€æµ‹æ¨¡å¼")
            # elif key == ord('f'):
            #     # åˆ‡æ¢è·³å¸§æ£€æµ‹æ¨¡å¼
            #     tracker.toggle_skip_frame_mode()
            #     skip_mode = f"è·³å¸§x{tracker.detection_interval}" if tracker.skip_frame_mode else "æ­£å¸¸æ£€æµ‹"
            #     print(f"ğŸ”„ åˆ‡æ¢è·³å¸§æ£€æµ‹æ¨¡å¼: {skip_mode}")
            # elif key == ord('1'):
            #     # è®¾ç½®è·³å¸§é—´éš”ä¸º2
            #     tracker.detection_interval = 2
            #     if tracker.skip_frame_mode:
            #         skip_mode = f"è·³å¸§x{tracker.detection_interval}"
            #         print(f"ğŸ”„ è®¾ç½®è·³å¸§é—´éš”ä¸º2å¸§")
            # elif key == ord('2'):
            #     # è®¾ç½®è·³å¸§é—´éš”ä¸º3
            #     tracker.detection_interval = 3
            #     if tracker.skip_frame_mode:
            #         skip_mode = f"è·³å¸§x{tracker.detection_interval}"
            #         print(f"ğŸ”„ è®¾ç½®è·³å¸§é—´éš”ä¸º3å¸§")
            # elif key == ord('3'):
            #     # è®¾ç½®è·³å¸§é—´éš”ä¸º5
            #     tracker.detection_interval = 5
            #     if tracker.skip_frame_mode:
            #         skip_mode = f"è·³å¸§x{tracker.detection_interval}"
            #         print(f"ğŸ”„ è®¾ç½®è·³å¸§é—´éš”ä¸º5å¸§")

            # å®šæœŸæ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
            current_time = time.time()
            if current_time - last_performance_log >= 5:
                stats = tracker.get_performance_stats()
                print(f"ğŸ“Š {stats} | è·Ÿè¸ªå¯¹è±¡: {len(tracked_objects)}")
                last_performance_log = current_time

    except KeyboardInterrupt:
        print("\nâ¹ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if 'cap' in locals():
            cap.release()
        cv2.destroyAllWindows()
        if tracker is not None:
            print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {tracker.get_performance_stats()}")
        print("ğŸ›‘ ç³»ç»Ÿå·²å…³é—­")


if __name__ == "__main__":
    main()

# def main():
#     """ä¸»å‡½æ•° - ROIåŒºåŸŸæ£€æµ‹æ¨¡å¼"""
#     print("ğŸš€ å¯åŠ¨äººå‘˜è½¦è¾†åœç•™æ£€æµ‹ç³»ç»Ÿï¼ˆROIåŒºåŸŸæ£€æµ‹æ¨¡å¼ï¼‰")
#     print("=" * 50)

#     tracker = None

#     try:
#         # åˆå§‹åŒ–è·Ÿè¸ªç³»ç»Ÿ
#         tracker = PersonVehicleStayDetection(
#             model_path='yolov5su.pt',
#             conf_threshold=0.8,
#             use_gpu=True,
#             stay_threshold=8
#         )

#         # è®¾ç½®æ£€æµ‹å’Œè·Ÿè¸ªçš„ROIåŒºåŸŸ

#         detection_roi = [(350, 340), (750, 580)]
#         tracker.set_detection_roi(detection_roi)
#         video_source = "data/test_videos/callpose_test/callpose_test (online-video-cutter.com).mp4"

#         # detection_roi = [(300, 300), (800, 700)]
#         # tracker.set_detection_roi(detection_roi)
#         # video_source = "data/test_videos/safe_gesture/gf1 (online-video-cutter.com).mp4"

#         # detection_roi = [(200, 200), (700, 600)]
#         # tracker.set_detection_roi(detection_roi)
#         # video_source = "data/test_videos/safe_gesture/1 (online-video-cutter.com).mp4"

#         cap = cv2.VideoCapture(video_source)
#         if not cap.isOpened():
#             print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_source}")
#             return

#         # è·å–è§†é¢‘ä¿¡æ¯
#         fps = cap.get(cv2.CAP_PROP_FPS)
#         total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#         print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {fps:.1f} FPS, æ€»å¸§æ•°: {total_frames}")

#         print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
#         print("ğŸ¯ å·¥ä½œæ¨¡å¼: ROIåŒºåŸŸæ£€æµ‹å’Œè·Ÿè¸ª")
#         print("ğŸ® æ§åˆ¶è¯´æ˜:")
#         print("  - æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
#         print("  - æŒ‰ 's' é”®ä¿å­˜å½“å‰å¸§")
#         print("  - æŒ‰ 'r' é”®é‡ç½®åœç•™æ£€æµ‹")
#         print("  - æŒ‰ 'd' é”®åˆ‡æ¢æ£€æµ‹æ¨¡å¼ï¼ˆROI/å…¨å›¾ï¼‰")
#         print("=" * 50)

#         last_performance_log = 0
#         current_mode = "ROI"

#         while True:
#             ret, frame = cap.read()
#             if not ret:
#                 print("ğŸ“¹ è§†é¢‘æµç»“æŸ")
#                 break

#             # å¤„ç†å¸§ - åœ¨ROIåŒºåŸŸå†…è¿›è¡Œæ£€æµ‹å’Œè·Ÿè¸ª
#             result_frame, tracked_objects = tracker.process_frame(frame)

#             # æ˜¾ç¤ºç»“æœ
#             cv2.imshow(f'äººè½¦åœç•™æ£€æµ‹ç³»ç»Ÿ - {current_mode}æ¨¡å¼', result_frame)

#             # é”®ç›˜æ§åˆ¶
#             key = cv2.waitKey(1) & 0xFF
#             if key == ord('q'):
#                 break
#             elif key == ord('s'):
#                 timestamp = time.strftime("%Y%m%d_%H%M%S")
#                 cv2.imwrite(f"system_state_{timestamp}.jpg", result_frame)
#                 print(f"ğŸ’¾ ç³»ç»ŸçŠ¶æ€å·²ä¿å­˜: system_state_{timestamp}.jpg")
#             elif key == ord('r'):
#                 tracker.reset_stay_detection()
#             elif key == ord('d'):
#                 # åˆ‡æ¢æ£€æµ‹æ¨¡å¼
#                 if current_mode == "ROI":
#                     tracker.disable_roi_detection()
#                     current_mode = "å…¨å›¾"
#                 else:
#                     detection_roi = [(350, 370), (750, 580)]
#                     tracker.set_detection_roi(detection_roi)
#                     current_mode = "ROI"
#                 print(f"ğŸ”„ åˆ‡æ¢åˆ°{current_mode}æ£€æµ‹æ¨¡å¼")

#             # å®šæœŸæ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
#             current_time = time.time()
#             if current_time - last_performance_log >= 5:
#                 stats = tracker.get_performance_stats()
#                 print(f"ğŸ“Š {stats} | è·Ÿè¸ªå¯¹è±¡: {len(tracked_objects)}")
#                 last_performance_log = current_time

#     except KeyboardInterrupt:
#         print("\nâ¹ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
#     except Exception as e:
#         print(f"âŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
#         import traceback
#         traceback.print_exc()
#     finally:
#         if 'cap' in locals():
#             cap.release()
#         cv2.destroyAllWindows()
#         if tracker is not None:
#             print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {tracker.get_performance_stats()}")
#         print("ğŸ›‘ ç³»ç»Ÿå·²å…³é—­")


# if __name__ == "__main__":
#     main()